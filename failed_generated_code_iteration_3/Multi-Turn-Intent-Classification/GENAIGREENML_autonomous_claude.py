# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import json
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import warnings
import os

warnings.filterwarnings("ignore")

# Load the JSON dataset
data_path = "data/input.json"

with open(data_path, "r", encoding="utf-8") as f:
    raw_data = json.load(f)

# Explore the structure of the JSON to determine how to extract features and labels
# The project context says this is multi-turn intent classification from WhatsApp-style conversations
# We need to robustly handle whatever JSON structure is present

records = []

if isinstance(raw_data, list):
    for item in raw_data:
        if isinstance(item, dict):
            records.append(item)
elif isinstance(raw_data, dict):
    # Could be a dict with a key containing a list
    for key, val in raw_data.items():
        if isinstance(val, list):
            for item in val:
                if isinstance(item, dict):
                    records.append(item)
            break
    if not records:
        records = [raw_data]

df = pd.DataFrame(records)

# Strip/normalize column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df.loc[:, ~df.columns.str.startswith('Unnamed')]

# Identify text and label columns
# From context: conversations with intent labels
# Common patterns: 'conversation', 'message', 'text', 'turns' for text; 'intent', 'label', 'prediction' for target

text_col = None
label_col = None

col_lower_map = {c.lower(): c for c in df.columns}

# Try to find text column
text_candidates = ['conversation', 'conversations', 'message', 'messages', 'text', 'turns', 'input', 'query', 'utterance']
for tc in text_candidates:
    if tc in col_lower_map:
        text_col = col_lower_map[tc]
        break

# Try to find label column
label_candidates = ['intent', 'label', 'prediction', 'category', 'class', 'target', 'predicted_intent']
for lc in label_candidates:
    if lc in col_lower_map:
        label_col = col_lower_map[lc]
        break

# If we couldn't find them by name, use heuristics
if text_col is None or label_col is None:
    # Inspect all columns
    string_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    if text_col is None:
        # The text column likely has the longest average string length or contains lists (turns)
        best_text_col = None
        best_avg_len = 0
        for col in string_cols:
            if col == label_col:
                continue
            sample = df[col].dropna().head(50)
            if len(sample) == 0:
                continue
            # Check if values are lists (multi-turn)
            if isinstance(sample.iloc[0], list):
                best_text_col = col
                break
            avg_len = sample.astype(str).str.len().mean()
            if avg_len > best_avg_len:
                best_avg_len = avg_len
                best_text_col = col
        text_col = best_text_col
    
    if label_col is None:
        # The label column has fewer unique values relative to total rows
        best_label_col = None
        best_ratio = 1.0
        for col in string_cols:
            if col == text_col:
                continue
            nunique = df[col].nunique()
            ratio = nunique / max(len(df), 1)
            if nunique >= 2