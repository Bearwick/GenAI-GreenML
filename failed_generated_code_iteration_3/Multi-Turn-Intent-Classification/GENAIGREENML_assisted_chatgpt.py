# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import json
import csv
import random
from typing import List, Dict, Any, Optional

import numpy as np
import torch
from transformers import pipeline


SEED = 42


def set_reproducibility(seed: int = SEED) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    try:
        torch.use_deterministic_algorithms(False)
    except Exception:
        pass
    try:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    except Exception:
        pass


class IntentDetector:
    def __init__(self, device: int = -1):
        self.intent_options = [
            "Book Appointment",
            "Product Inquiry",
            "Pricing Negotiation",
            "Support Request",
            "Follow-Up",
        ]
        self.intent_pipeline = pipeline(
            task="zero-shot-classification",
            model="cross-encoder/nli-distilroberta-base",
            device=device,
        )

    def classify_intent(self, dialogue: str) -> Dict[str, str]:
        classification = self.intent_pipeline(dialogue, self.intent_options)
        top_intent = classification["labels"][0]
        return {
            "predicted_intent": top_intent,
            "rationale": f"Based on the conversation, the customer is likely interested in '{top_intent.lower()}'.",
        }


def create_conversation(messages: List[dict], max_messages: Optional[int] = None) -> str:
    if not messages:
        return ""
    if max_messages is not None:
        messages = messages[-max_messages:]

    lines = []
    append = lines.append
    for m in messages:
        sender = (m.get("sender") or "").capitalize()
        text = m.get("text") or ""
        append(f"{sender}: {text}")
    return "\n".join(lines)


def load_json(path: str) -> Any:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def write_json(path: str, obj: Any) -> None:
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, indent=2, ensure_ascii=False)


def write_csv(path: str, rows: List[Dict[str, Any]]) -> None:
    with open(path, "w", newline="", encoding="utf-8") as f:
        fieldnames = ["conversation_id", "predicted_intent", "rationale"]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)


def predict_intents(input_file: str, json_output: str, csv_output: str, model: IntentDetector) -> None:
    conversations = load_json(input_file)

    output_data = []
    append_out = output_data.append

    for entry in conversations:
        conv_id = entry.get("conversation_id")
        formatted_text = create_conversation(entry.get("messages") or [])
        intent_result = model.classify_intent(formatted_text)
        append_out(
            {
                "conversation_id": conv_id,
                "predicted_intent": intent_result["predicted_intent"],
                "rationale": intent_result["rationale"],
            }
        )

    write_json(json_output, output_data)
    write_csv(csv_output, output_data)


def compute_accuracy_from_input(conversations: List[dict], predictions: List[Dict[str, Any]]) -> float:
    id_to_pred = {p.get("conversation_id"): p.get("predicted_intent") for p in predictions}
    correct = 0
    total = 0
    for entry in conversations:
        true_label = entry.get("intent") or entry.get("label") or entry.get("true_intent") or entry.get("ground_truth")
        if true_label is None:
            continue
        total += 1
        if id_to_pred.get(entry.get("conversation_id")) == true_label:
            correct += 1
    return (correct / total) if total else 0.0


def main() -> None:
    set_reproducibility(SEED)

    os.makedirs("data/output", exist_ok=True)

    device = 0 if torch.cuda.is_available() else -1
    intent_model = IntentDetector(device=device)

    input_path = "data/input.json"
    json_output = "data/output/predictions.json"
    csv_output = "data/output/predictions.csv"

    conversations = load_json(input_path)
    output_data = []
    append_out = output_data.append

    for entry in conversations:
        conv_id = entry.get("conversation_id")
        formatted_text = create_conversation(entry.get("messages") or [])
        intent_result = intent_model.classify_intent(formatted_text)
        append_out(
            {
                "conversation_id": conv_id,
                "predicted_intent": intent_result["predicted_intent"],
                "rationale": intent_result["rationale"],
            }
        )

    write_json(json_output, output_data)
    write_csv(csv_output, output_data)

    accuracy = compute_accuracy_from_input(conversations, output_data)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused imports and unused text-cleaning steps to reduce CPU work and dependencies (kept exact prediction behavior).
# - Avoided redundant object creation by initializing the transformer pipeline once and reusing it for all conversations.
# - Reduced intermediate allocations in create_conversation by using a single list with local append binding.
# - Ensured deterministic/stable execution by setting fixed random seeds for Python/NumPy/PyTorch and disabling cuDNN autotuning.
# - Minimized data movement by streaming JSON load once and writing outputs once, while building output records in a single pass.
# - Added an accuracy computation that uses labels only if present in input; otherwise returns 0.0 to keep end-to-end execution stable.