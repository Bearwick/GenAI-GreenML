# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score
import os
import glob

# Step 1: Find the actual dataset file
# The DATASET_PATH points to requirements.txt which is not the data file.
# We need to search for a CSV file related to the Iris dataset.

dataset_path = None
search_dirs = [
    os.path.dirname(os.path.abspath(__file__)) if '__file__' in dir() else '.',
    '.',
    '..',
    os.path.expanduser('~/Documents/NTNU/Master/Master Thesis/GenAI-GreenML/repos/Iris-Classification-ML-problem'),
]

for search_dir in search_dirs:
    if not os.path.isdir(search_dir):
        continue
    for pattern in ['*.csv', '**/*.csv']:
        found = glob.glob(os.path.join(search_dir, pattern), recursive=True)
        for f in found:
            if 'iris' in f.lower() or 'data' in f.lower():
                dataset_path = f
                break
            if dataset_path is None and f.endswith('.csv'):
                dataset_path = f
        if dataset_path:
            break
    if dataset_path:
        break

# If no CSV found, try common iris dataset locations or fall back to sklearn's iris
if dataset_path is None:
    # Try to find any CSV in the project directory
    for search_dir in search_dirs:
        if not os.path.isdir(search_dir):
            continue
        csvs = glob.glob(os.path.join(search_dir, '**/*.csv'), recursive=True)
        if csvs:
            dataset_path = csvs[0]
            break

df = None

if dataset_path is not None and os.path.isfile(dataset_path):
    # Robust CSV parsing
    try:
        df = pd.read_csv(dataset_path)
        # Check if parsing looks wrong (e.g., single column with many rows)
        if df.shape[1] <= 1:
            df = pd.read_csv(dataset_path, sep=';', decimal=',')
    except Exception:
        try:
            df = pd.read_csv(dataset_path, sep=';', decimal=',')
        except Exception:
            df = None

# Fallback: use sklearn's built-in iris dataset
if df is None or df.empty:
    from sklearn.datasets import load_iris
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['target'] = iris.target

# Step 2: Clean column names
df.columns = df.columns.str.strip()
df.columns = df.columns.str.replace(r'\s+', ' ', regex=True)
# Drop unnamed columns
df = df[[c for c in df.columns if not c.lower().startswith('unnamed')]]

assert not df.empty, "Dataset is empty after initial cleaning"

# Step 3: Identify target and features
# For Iris, the target is typically the last column (species/class/target)
# Detect: prefer a non-numeric or low-cardinality column as target

target_col = None
candidate_targets = []

for col in df.columns:
    if df[col].dtype == object or str(df[col].dtype) == 'category':
        candidate_targets.append((col, df[col].nunique()))
    elif col.lower() in ('target', 'class', 'species', 'label', 'variety', 'type'):
        candidate_targets.append((col, df[col].nunique()))

if candidate_targets:
    # Prefer columns with names suggesting target
    preferred = [c for c in candidate_targets if c[0].lower() in ('target', 'class', 'species', 'label', 'variety', 'type')]
    if