# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# Step 1: Load the ARFF file with robust fallback
def load_arff_as_dataframe(path):
    # Try using scipy's arff loader first
    try:
        from scipy.io import arff
        data, meta = arff.loadarff(path)
        df = pd.DataFrame(data)
        # Decode bytes columns if needed
        for col in df.columns:
            if df[col].dtype == object:
                try:
                    df[col] = df[col].str.decode('utf-8')
                except (AttributeError, UnicodeDecodeError):
                    pass
        return df
    except Exception:
        pass

    # Fallback: parse ARFF manually
    try:
        columns = []
        data_started = False
        rows = []
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped = line.strip()
                if stripped.lower().startswith('@attribute'):
                    parts = stripped.split()
                    col_name = parts[1].strip("'\"")
                    columns.append(col_name)
                elif stripped.lower().startswith('@data'):
                    data_started = True
                elif data_started and stripped and not stripped.startswith('%'):
                    # Handle quoted commas
                    values = []
                    in_quote = False
                    current = []
                    for ch in stripped:
                        if ch in ("'", '"'):
                            in_quote = not in_quote
                        elif ch == ',' and not in_quote:
                            values.append(''.join(current).strip())
                            current = []
                        else:
                            current.append(ch)
                    values.append(''.join(current).strip())
                    rows.append(values)
        df = pd.DataFrame(rows, columns=columns)
        # Replace '?' with NaN
        df.replace('?', np.nan, inplace=True)
        return df
    except Exception:
        pass

    # Last fallback: try CSV
    try:
        df = pd.read_csv(path)
        if df.shape[1] <= 1:
            df = pd.read_csv(path, sep=';', decimal=',')
        return df
    except Exception:
        return pd.DataFrame()

df = load_arff_as_dataframe("dataset_adult.arff")

# Step 2: Clean column names
df.columns = [str(c).strip().replace("'", "").replace('"', '') for c in df.columns]
df.columns = [' '.join(c.split()) for c in df.columns]
# Drop unnamed columns
df = df[[c for c in df.columns if not c.lower().startswith('unnamed')]]

assert df.shape[0] > 0, "Dataset is empty after loading"

# Step 3: Identify target column
# For the adult dataset, the target is typically 'class' or 'income' or the last column
target_col = None
candidate_targets = ['class', 'income', 'target', 'label']
for ct in candidate_targets:
    matches = [c for c in df.columns if c.lower() == ct.lower()]
    if matches:
        target_col = matches[0]
        break

if target_col is None:
    # Use last column as target
    target_col = df.columns[-1]

# Step 4: Clean target
df[target_col] = df[target_col].astype(str).str.strip().str.strip("'\".")
unique_targets = df[target_col].dropna().unique()

# Check if classification is feasible
if len(unique_targets) < 2:
    #