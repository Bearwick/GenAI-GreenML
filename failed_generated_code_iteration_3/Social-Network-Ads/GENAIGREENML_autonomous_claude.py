# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# --- Robust CSV Loading ---
DATASET_PATH = "Social_Network_Ads.csv"

try:
    df = pd.read_csv(DATASET_PATH)
    if df.shape[1] < 2:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')
except Exception:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')

# --- Column name normalization ---
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df.loc[:, ~df.columns.str.startswith('Unnamed')]

# --- Identify target and features ---
target_col = None
expected_target = 'Purchased'
if expected_target in df.columns:
    target_col = expected_target
else:
    for c in df.columns:
        if c.lower() == 'purchased':
            target_col = c
            break

if target_col is None:
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    for c in numeric_cols:
        if df[c].nunique() >= 2:
            target_col = c
            break
    if target_col is None and len(numeric_cols) > 0:
        target_col = numeric_cols[-1]

assert target_col is not None, "No suitable target column found."

# --- Drop User ID if present (not predictive) ---
drop_cols = [target_col]
for c in df.columns:
    if c.lower().replace(' ', '') in ['userid', 'user_id', 'id']:
        drop_cols.append(c)

feature_cols = [c for c in df.columns if c not in drop_cols]

# --- Encode categorical features ---
label_encoders = {}
for c in feature_cols:
    if df[c].dtype == object:
        le = LabelEncoder()
        df[c] = le.fit_transform(df[c].astype(str))
        label_encoders[c] = le

# --- Coerce numeric and handle NaN/inf ---
for c in feature_cols:
    df[c] = pd.to_numeric(df[c], errors='coerce')

df[target_col] = pd.to_numeric(df[target_col], errors='coerce')
df = df.replace([np.inf, -np.inf], np.nan)
df = df.dropna(subset=[target_col] + feature_cols)

assert len(df) > 0, "Dataset is empty after preprocessing."

X = df[list(feature_cols)].values
y = df[target_col].values

# --- Determine if classification or regression ---
n_classes = len(np.unique(y))
is_classification = n_classes >= 2 and n_classes <= 20

if is_classification:
    y = y.astype(int)

# --- Train/test split ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y if is_classification else None
)

assert len(X_train) > 0 and len(X_test) > 0, "Train or test set is empty."

# --- Build pipeline: StandardScaler + LogisticRegression (lightweight, energy-efficient) ---
if is_classification:
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('clf', LogisticRegression(max_iter=300, solver='lbfgs', random_state=42))
    ])
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)
    accuracy = accuracy_score(y_test, y_