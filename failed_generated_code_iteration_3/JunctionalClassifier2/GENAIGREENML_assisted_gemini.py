# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle
import os

def load_data(path):
    if not os.path.exists(path):
        return None, None
    try:
        df = pd.read_csv(path, sep=',', engine='c', low_memory=False)
        if df.shape[1] <= 1:
            df = pd.read_csv(path, sep=';', decimal=',', engine='c', low_memory=False)
    except:
        try:
            df = pd.read_csv(path, sep=None, engine='python')
        except:
            try:
                with open(path, 'rb') as f:
                    data = pickle.load(f)
                if isinstance(data, pd.DataFrame):
                    df = data
                elif isinstance(data, dict):
                    X = np.asarray(data.get('features', []), dtype=np.float32)
                    y_raw = np.asarray(data.get('labels', []), dtype=np.float32)
                    if len(X) == 0: return None, None
                    return X, np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0))
                else: return None, None
            except: return None, None
    if df.empty: return None, None
    if df.iloc[:, -1].astype(str).str.strip().eq('').all() or df.iloc[:, -1].isnull().all():
        df = df.iloc[:, :-1]
    X = df.iloc[:, :-1].values.astype(np.float32)
    y_raw = pd.to_numeric(df.iloc[:, -1], errors='coerce').fillna(0).values
    y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0))
    return X, y

def run():
    dataset_path = 'dict.pickle'
    X, y = load_data(dataset_path)
    if X is not None and len(X) > 0:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        clf = KNeighborsClassifier(n_neighbors=4)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run()

# Optimization Summary
# 1. Replaced manual, line-by-line CSV parsing with vectorized pandas.read_csv, reducing CPU cycles and runtime.
# 2. Used float32 numerical types for features to halve the memory footprint compared to the original double (float64).
# 3. Streamlined data preprocessing by using NumPy's vectorized np.where logic instead of manual conditional loops for label binarization.
# 4. Eliminated redundant data structures by avoiding the conversion of arrays to lists and back.
# 5. Removed expensive disk I/O operations such as unnecessary pickle saves and loads in the prediction cycle.
# 6. Implemented a robust, single-pass data loader that handles multiple delimiters and file formats efficiently.
# 7. Set a fixed random seed in data partitioning to ensure reproducibility and avoid unnecessary repeated computations for stability.
# 8. Removed global variables and modularized the execution flow to improve memory management and data locality.