# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# Load the pickle file
DATASET_PATH = "dict.pickle"

with open(DATASET_PATH, "rb") as f:
    data = pickle.load(f, encoding="latin1")

# Inspect what we loaded
# The pickle could be a dict, a DataFrame, or something else
df = None

if isinstance(data, pd.DataFrame):
    df = data
elif isinstance(data, dict):
    # Try to figure out structure
    # Could be {features: array, labels: array} or similar
    # Or could be a dict of columns
    keys = list(data.keys())
    
    # Check if values are arrays/lists of same length -> treat as columns
    lengths = {}
    for k, v in data.items():
        if isinstance(v, (list, np.ndarray)):
            lengths[k] = len(v) if hasattr(v, '__len__') else 1
        elif isinstance(v, pd.Series):
            lengths[k] = len(v)
    
    if len(lengths) > 0:
        # Check if all same length -> DataFrame from dict
        unique_lengths = set(lengths.values())
        if len(unique_lengths) == 1:
            df = pd.DataFrame(data)
        else:
            # Maybe it has X/y style keys
            # Common patterns: 'data'/'target', 'X'/'y', 'features'/'labels'
            X_keys = [k for k in keys if k.lower() in ('data', 'x', 'features', 'train_data', 'x_train')]
            y_keys = [k for k in keys if k.lower() in ('target', 'y', 'labels', 'train_labels', 'y_train', 'label', 'class')]
            
            if X_keys and y_keys:
                X_data = data[X_keys[0]]
                y_data = data[y_keys[0]]
                if isinstance(X_data, np.ndarray) and X_data.ndim == 2:
                    df = pd.DataFrame(X_data, columns=[f"feature_{i}" for i in range(X_data.shape[1])])
                    df["target"] = y_data
                elif isinstance(X_data, pd.DataFrame):
                    df = X_data.copy()
                    df["target"] = y_data
                else:
                    # Try converting
                    X_arr = np.array(X_data)
                    if X_arr.ndim == 2:
                        df = pd.DataFrame(X_arr, columns=[f"feature_{i}" for i in range(X_arr.shape[1])])
                        df["target"] = np.array(y_data)
            
            if df is None:
                # Try to build from whatever arrays we have, picking longest as features
                sorted_keys = sorted(lengths.keys(), key=lambda k: lengths[k], reverse=True)
                # Just try to make a DataFrame from the dict, ignoring mismatched
                try:
                    # Attempt: maybe some keys hold 2D arrays
                    for k in keys:
                        v = data[k]
                        if isinstance(v, np.ndarray) and v.ndim == 2 and v.shape[0] > 10:
                            df = pd.DataFrame(v, columns=[f"feature_{i}" for i in range(v.shape[1])])
                            # Look for a matching-length 1D array as target
                            for k2 in keys:
                                if k2 != k:
                                    v2 = np.array(data[k2]).flatten()
                                    if len(v2) == v.shape[0]:
                                        df["