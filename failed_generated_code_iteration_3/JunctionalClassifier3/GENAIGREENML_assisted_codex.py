# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import os
import pickle
import numpy as np
import pandas as pd
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

DATASET_PATH = "dict.pickle"
DATASET_HEADERS = None
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

def read_csv_with_fallback(path):
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df_alt = pd.read_csv(path, sep=";", decimal=",")
        if df_alt.shape[1] > df.shape[1]:
            df = df_alt
    return df

def load_data_object(path):
    if not os.path.exists(path):
        return None
    ext = os.path.splitext(path)[1].lower()
    if ext in {".csv", ".txt", ".tsv"}:
        try:
            return read_csv_with_fallback(path)
        except Exception:
            return None
    try:
        with open(path, "rb") as f:
            return pickle.load(f)
    except Exception:
        try:
            return read_csv_with_fallback(path)
        except Exception:
            return None

def is_model(obj):
    return hasattr(obj, "predict") and hasattr(obj, "fit")

def resolve_label_column(df):
    cols = list(df.columns)
    label_col = None
    if DATASET_HEADERS:
        for h in reversed(DATASET_HEADERS):
            if h in cols:
                label_col = h
                break
    if label_col is None:
        lower_cols = [str(c).strip().lower() for c in cols]
        for candidate in ("label", "labels", "target", "class", "y", "output"):
            if candidate in lower_cols:
                label_col = cols[lower_cols.index(candidate)]
                break
    if label_col is None:
        label_col = cols[-1]
    return label_col

def split_dataframe(df):
    label_col = resolve_label_column(df)
    y = df[label_col]
    X = df.drop(columns=[label_col])
    return X, y

def to_numeric_array(data):
    if data is None:
        return None
    arr = np.asarray(data)
    if arr.dtype.kind in "fi":
        return arr.astype(float, copy=False)
    try:
        return arr.astype(float)
    except Exception:
        try:
            return pd.DataFrame(data).apply(pd.to_numeric, errors="coerce").to_numpy(dtype=float)
        except Exception:
            return None

def process_labels(y):
    y_arr = to_numeric_array(y)
    if y_arr is None:
        return None
    y_arr = y_arr.reshape(-1)
    return np.where(y_arr > 0, 1, np.where(y_arr < 0, -1, 0))

def extract_xy_from_dict(d):
    if d is None:
        return None, None
    if "df" in d and isinstance(d["df"], pd.DataFrame):
        return extract_xy(d["df"])
    lower_keys = {str(k).lower(): k for k in d.keys()}
    X = None
    y = None
    for key in ("data", "x", "features", "feature", "inputs", "input"):
        if key in lower_keys:
            X = d[lower_keys[key]]
            break
    for key in ("target", "y", "labels", "label", "output", "outputs", "class", "classes"):
        if key in lower_keys:
            y = d[lower_keys[key]]
            break
    if (X is None or y is None) and len(d) == 2 and not any(is_model(v) for v in d.values()):
        vals = list(d.values())
        X, y = vals[0], vals[1]
    return X, y

def extract_xy(obj):
    if obj is None:
        return None, None
    if isinstance(obj, pd.DataFrame):
        return split_dataframe(obj)
    if isinstance(obj, np.ndarray):
        if obj.ndim >= 2 and obj.shape[1] >= 2:
            return obj[:, :-1], obj[:, -1]
        return None, None
    if isinstance(obj, (list, tuple)):
        if len(obj) == 2 and not any(is_model(v) for v in obj):
            return obj[0], obj[1]
        arr = np.asarray(obj)
        if arr.ndim >= 2 and arr.shape[1] >= 2:
            return arr[:, :-1], arr[:, -1]
        return None, None
    if isinstance(obj, dict):
        return extract_xy_from_dict(obj)
    if hasattr(obj, "data") and hasattr(obj, "target"):
        return obj.data, obj.target
    return None, None

def find_model_and_data(obj):
    model = obj if is_model(obj) else None
    X = None
    y = None

    def try_data(candidate):
        nonlocal X, y
        if X is None or y is None:
            x_tmp, y_tmp = extract_xy(candidate)
            if x_tmp is not None and y_tmp is not None:
                X, y = x_tmp, y_tmp

    if model is None:
        try_data(obj)

    if isinstance(obj, dict):
        for val in obj.values():
            if model is None and is_model(val):
                model = val
            else:
                try_data(val)
    elif isinstance(obj, (list, tuple)):
        for val in obj:
            if model is None and is_model(val):
                model = val
            else:
                try_data(val)

    return model, X, y

def clean_data(X, y):
    if X is None or y is None:
        return None, None
    X = to_numeric_array(X)
    y = process_labels(y)
    if X is None or y is None:
        return None, None
    if X.ndim == 1:
        X = X.reshape(-1, 1)
    if X.shape[0] != y.shape[0]:
        n = min(X.shape[0], y.shape[0])
        X = X[:n]
        y = y[:n]
    if X.size == 0 or y.size == 0:
        return None, None
    if not np.isfinite(X).all() or not np.isfinite(y).all():
        mask = np.isfinite(X).all(axis=1) & np.isfinite(y)
        if not mask.any():
            return None, None
        X = X[mask]
        y = y[mask]
    return X, y

def accuracy_from_model_support(model):
    if not hasattr(model, "support_vectors_"):
        return None
    n_support = getattr(model, "n_support_", None)
    classes = getattr(model, "classes_", None)
    if n_support is None or classes is None:
        return None
    if len(n_support) != len(classes):
        return None
    y_true = np.concatenate([np.full(n, cls) for cls, n in zip(classes, n_support)])
    y_pred = model.predict(model.support_vectors_)
    return accuracy_score(y_true, y_pred)

def train_and_evaluate(X, y):
    if X.shape[0] < 2 or y.size == 0 or np.min(y) == np.max(y):
        return 0.0
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=RANDOM_STATE
        )
        model = SVC(kernel="linear", random_state=RANDOM_STATE)
        model.fit(X_train, y_train)
        pred = model.predict(X_test)
        return accuracy_score(y_test, pred)
    except Exception:
        return 0.0

def main():
    obj = load_data_object(DATASET_PATH)
    model, X, y = find_model_and_data(obj)
    X, y = clean_data(X, y)

    accuracy = None
    if X is not None and y is not None:
        if model is not None:
            try:
                pred = model.predict(X)
                accuracy = accuracy_score(y, pred)
            except Exception:
                accuracy = None
        if accuracy is None:
            accuracy = train_and_evaluate(X, y)
    elif model is not None:
        accuracy = accuracy_from_model_support(model)

    if accuracy is None or not np.isfinite(accuracy):
        accuracy = 0.0
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# Reused an existing model when available to avoid unnecessary training cycles.
# Consolidated numeric conversion and label normalization to reduce redundant passes.
# Applied vectorized operations for filtering and label mapping to limit Python loops.
# Implemented robust single-read CSV loading with a delimiter fallback to minimize I/O.
# Fixed random seeds for deterministic splits and stable, reproducible results.