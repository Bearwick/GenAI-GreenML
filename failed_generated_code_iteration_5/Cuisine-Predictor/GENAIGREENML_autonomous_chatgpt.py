# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: autonomous

import json
import re
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.metrics import accuracy_score


RANDOM_STATE = 42
DATASET_PATH = "train.json"


def _normalize_columns(cols):
    out = []
    for c in cols:
        c = str(c)
        c = re.sub(r"\s+", " ", c.strip())
        out.append(c)
    return out


def _drop_unnamed(df):
    drop_cols = [c for c in df.columns if re.match(r"^Unnamed:\s*\d+$", str(c))]
    if drop_cols:
        df = df.drop(columns=drop_cols, errors="ignore")
    return df


def _safe_read_json(path):
    # Primary: pandas JSON reader (handles JSON array/lines in many cases)
    try:
        df = pd.read_json(path)
        if isinstance(df, pd.DataFrame) and len(df) > 0:
            return df
    except Exception:
        pass

    # Fallback: load JSON via stdlib and normalize
    with open(path, "r", encoding="utf-8") as f:
        raw = json.load(f)
    df = pd.json_normalize(raw)
    return df


def _choose_target(df):
    # Prefer common names if present, but never assume they exist
    cols_lower = {c.lower(): c for c in df.columns}
    for cand in ["cuisine", "target", "label", "y", "class"]:
        if cand in cols_lower:
            return cols_lower[cand]

    # Otherwise choose a non-constant object/categorical column with reasonable cardinality
    best = None
    best_score = -1
    for c in df.columns:
        s = df[c]
        if s.dtype == "O" or str(s.dtype).startswith("string"):
            nunique = s.nunique(dropna=True)
            if nunique >= 2:
                # prefer moderate number of classes for baseline
                score = 1.0 / (1.0 + abs(nunique - 10))
                if score > best_score:
                    best_score = score
                    best = c
    if best is not None:
        return best

    # Else choose numeric non-constant column
    for c in df.columns:
        s = pd.to_numeric(df[c], errors="coerce")
        nunique = s.nunique(dropna=True)
        if nunique >= 2:
            return c

    # As last resort: first column
    return df.columns[0]


def _is_text_like_series(s):
    if s.dtype != "O" and not str(s.dtype).startswith("string"):
        return False
    sample = s.dropna().astype(str).head(50)
    if len(sample) == 0:
        return False
    avg_len = sample.map(len).mean()
    # Heuristic: text columns tend to have longer average length
    return avg_len >= 15


def _make_text_column(df):
    # Combine list-like columns (e.g., ingredients) or any object columns that look list-like into one text column
    text_parts = []
    for c in df.columns:
        s = df[c]
        if s.dtype == "O" or str(s.dtype).startswith("string"):
            # Detect list-like rows: list/tuple/set, or string that resembles JSON-ish lists
            sample = s.dropna().head(20)
            list_like = False
            for v in sample:
                if isinstance(v, (list, tuple, set)):
                    list_like = True
                    break
                if isinstance(v, str) and (v.strip().startswith("[") and v.strip().endswith("]")):
                    list_like = True
                    break
            if list_like:
                def to_text(v):
                    if isinstance(v, (list, tuple, set)):
                        return " ".join(map(str, v))
                    if isinstance(v, str):
                        t = v.strip()
                        if t.startswith("[") and t.endswith("]"):
                            t = t[1:-1]
                        t = t.replace(",", " ")
                        return t
                    return ""
                text_parts.append(s.map(to_text).fillna(""))
    if not text_parts:
        return None

    combined = text_parts[0].astype(str)
    for p in text_parts[1:]:
        combined = combined + " " + p.astype(str)
    return combined.str.replace(r"\s+", " ", regex=True).str.strip()


def _build_and_eval(df, target_col):
    df = df.copy()

    # Normalize columns
    df.columns = _normalize_columns(df.columns)
    df = _drop_unnamed(df)

    # Ensure target exists
    if target_col not in df.columns:
        target_col = _choose_target(df)

    y_raw = df[target_col]
    X_raw = df.drop(columns=[target_col], errors="ignore")

    # Assert not empty
    assert len(df) > 0 and len(X_raw) > 0, "Empty dataset or no features after preprocessing."

    # Try to synthesize a robust text feature if list-like columns exist
    synthesized_text = _make_text_column(X_raw)

    # Decide task: classification if y has >=2 classes and not purely numeric regression-like
    y_is_numeric = False
    y_num = pd.to_numeric(y_raw, errors="coerce")
    if y_num.notna().mean() > 0.95:
        y_is_numeric = True

    classification = True
    if y_is_numeric:
        nunique_num = y_num.nunique(dropna=True)
        # If many unique numeric values, treat as regression; else could still be class IDs
        if nunique_num > 20:
            classification = False
        else:
            # keep classification if integer-ish and limited classes
            classification = True

    if classification:
        y = y_raw.astype(str).fillna("NA")
        if y.nunique(dropna=True) < 2:
            classification = False
    if not classification:
        y = pd.to_numeric(y_raw, errors="coerce")

    # Build features: prefer text vectorization if synthesized_text exists; else tabular OHE
    if synthesized_text is not None and synthesized_text.astype(str).str.len().mean() > 0:
        X = synthesized_text.fillna("").astype(str)

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y if classification else None
        )
        assert len(X_train) > 0 and len(X_test) > 0, "Train/test split failed."

        if classification:
            model = Pipeline(
                steps=[
                    ("tfidf", TfidfVectorizer(lowercase=True, ngram_range=(1, 2), min_df=2, max_features=50000)),
                    ("clf", MultinomialNB(alpha=0.5)),
                ]
            )
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
            accuracy = float(accuracy_score(y_test, pred))
            return accuracy
        else:
            # Regression with TF-IDF can be heavy; use hashing-free TF-IDF but cap features
            model = Pipeline(
                steps=[
                    ("tfidf", TfidfVectorizer(lowercase=True, ngram_range=(1, 2), min_df=2, max_features=20000)),
                    ("reg", Ridge(alpha=1.0, random_state=RANDOM_STATE)),
                ]
            )
            y_train_num = pd.to_numeric(y_train, errors="coerce")
            y_test_num = pd.to_numeric(y_test, errors="coerce")
            # Drop NaNs produced by coercion
            train_mask = y_train_num.notna()
            test_mask = y_test_num.notna()
            X_train2 = X_train[train_mask]
            y_train2 = y_train_num[train_mask]
            X_test2 = X_test[test_mask]
            y_test2 = y_test_num[test_mask]
            if len(X_train2) == 0 or len(X_test2) == 0:
                # Trivial fallback
                accuracy = 0.0
                return accuracy
            model.fit(X_train2, y_train2)
            pred = model.predict(X_test2)
            ss_res = float(np.sum((y_test2.to_numpy() - pred) ** 2))
            ss_tot = float(np.sum((y_test2.to_numpy() - float(np.mean(y_test2.to_numpy()))) ** 2))
            r2 = 0.0 if ss_tot <= 0 else (1.0 - ss_res / ss_tot)
            accuracy = float(np.clip((r2 + 1.0) / 2.0, 0.0, 1.0))
            return accuracy

    # Tabular path (no reliable text/list feature found)
    X_df = X_raw.copy()

    # Normalize column types with safe coercion
    X_df.columns = _normalize_columns(X_df.columns)
    X_df = _drop_unnamed(X_df)

    # Identify numeric/categorical columns
    num_cols = []
    cat_cols = []
    for c in X_df.columns:
        s = X_df[c]
        s_num = pd.to_numeric(s, errors="coerce")
        if s_num.notna().mean() > 0.8:
            num_cols.append(c)
        else:
            cat_cols.append(c)

    # Ensure at least one feature
    if len(num_cols) == 0 and len(cat_cols) == 0:
        # Create a constant feature to keep pipeline valid
        X_df["_const"] = 1.0
        num_cols = ["_const"]

    numeric_transformer = Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="median")),
        ]
    )
    categorical_transformer = Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=True)),
        ]
    )

    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, num_cols),
            ("cat", categorical_transformer, cat_cols),
        ],
        remainder="drop",
        sparse_threshold=0.3,
    )

    X_train, X_test, y_train, y_test = train_test_split(
        X_df, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y if classification else None
    )
    assert len(X_train) > 0 and len(X_test) > 0, "Train/test split failed."

    if classification:
        # Keep solver simple and CPU-friendly; limit iterations
        clf = LogisticRegression(max_iter=200, n_jobs=1, solver="liblinear")
        model = Pipeline(steps=[("pre", preprocessor), ("clf", clf)])
        model.fit(X_train, y_train)
        pred = model.predict(X_test)
        accuracy = float(accuracy_score(y_test, pred))
        return accuracy
    else:
        reg = Ridge(alpha=1.0, random_state=RANDOM_STATE)
        model = Pipeline(steps=[("pre", preprocessor), ("reg", reg)])
        y_train_num = pd.to_numeric(y_train, errors="coerce")
        y_test_num = pd.to_numeric(y_test, errors="coerce")
        train_mask = y_train_num.notna()
        test_mask = y_test_num.notna()
        if train_mask.sum() == 0 or test_mask.sum() == 0:
            accuracy = 0.0
            return accuracy
        model.fit(X_train.loc[train_mask], y_train_num.loc[train_mask])
        pred = model.predict(X_test.loc[test_mask])
        y_true = y_test_num.loc[test_mask].to_numpy()
        ss_res = float(np.sum((y_true - pred) ** 2))
        ss_tot = float(np.sum((y_true - float(np.mean(y_true))) ** 2))
        r2 = 0.0 if ss_tot <= 0 else (1.0 - ss_res / ss_tot)
        accuracy = float(np.clip((r2 + 1.0) / 2.0, 0.0, 1.0))
        return accuracy


def main():
    df = _safe_read_json(DATASET_PATH)
    assert isinstance(df, pd.DataFrame), "Failed to load dataset as DataFrame."
    assert len(df) > 0, "Dataset is empty."

    df.columns = _normalize_columns(df.columns)
    df = _drop_unnamed(df)
    assert len(df.columns) > 0, "No columns found in dataset."

    target_col = _choose_target(df)
    accuracy = _build_and_eval(df, target_col)

    # Final required output
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Uses a lightweight, CPU-friendly baseline: TF-IDF + MultinomialNB for text/list-like ingredient data; else OHE + LogisticRegression.
# - Avoids deep learning/large ensembles; limits iterations/features (max_features) to keep compute and energy use low.
# - Robust schema handling: normalizes column names, drops Unnamed columns, infers target when unknown, and synthesizes text from list-like columns.
# - Reproducibility: fixed random_state; sklearn Pipelines/ColumnTransformer ensure consistent preprocessing without redundant passes.
# - Safe numeric handling: pd.to_numeric(errors='coerce'), imputers for missing values, and regression fallback with bounded accuracy proxy = clip((R2+1)/2, 0..1).