# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

# Load the dataset
df = None
try:
    df = pd.read_json("train.json")
except Exception:
    try:
        df = pd.read_json("train.json", lines=True)
    except Exception:
        df = pd.read_csv("train.json")

assert df is not None and len(df) > 0, "Dataset is empty after loading"

# Normalize column names
df.columns = [str(c).strip() for c in df.columns]
df = df[[c for c in df.columns if not c.startswith("Unnamed")]]

# Identify target and feature columns based on the "What's Cooking" dataset structure
# Expected columns: id, cuisine, ingredients
target_col = None
ingredients_col = None

for c in df.columns:
    cl = c.lower()
    if cl == "cuisine":
        target_col = c
    elif cl == "ingredients":
        ingredients_col = c

# Fallback: if columns not found by name, try to detect them
if target_col is None:
    # Look for a string column with multiple categories (not ingredients)
    for c in df.columns:
        if df[c].dtype == object and c.lower() != "id":
            nunique = df[c].nunique()
            if 2 <= nunique <= 100:
                target_col = c
                break

if ingredients_col is None:
    # Look for a column containing lists
    for c in df.columns:
        if c == target_col:
            continue
        sample = df[c].dropna().iloc[0] if len(df[c].dropna()) > 0 else None
        if isinstance(sample, list):
            ingredients_col = c
            break

assert target_col is not None, "Could not identify target column"
assert ingredients_col is not None, "Could not identify ingredients column"

# Drop rows with missing target or ingredients
df = df.dropna(subset=[target_col, ingredients_col])
assert len(df) > 0, "Dataset empty after dropping NaN"

# Convert ingredient lists to space-separated strings for TF-IDF
def ingredients_to_text(ing):
    if isinstance(ing, list):
        return " ".join([str(i).lower().strip() for i in ing])
    return str(ing).lower().strip()

df["ingredients_text"] = df[ingredients_col].apply(ingredients_to_text)

# Encode target
le = LabelEncoder()
df["target_encoded"] = le.fit_transform(df[target_col])

n_classes = df["target_encoded"].nunique()
assert n_classes >= 2, "Need at least 2 classes for classification"

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    df["ingredients_text"],
    df["target_encoded"],
    test_size=0.2,
    random_state=42,
    stratify=df["target_encoded"]
)

assert len(X_train) > 0 and len(X_test) > 0, "Train or test split is empty"

# TF-IDF vectorization - energy efficient with limited features
# Using max_features to keep dimensionality manageable on CPU
tfidf = TfidfVectorizer(
    max_features=5000,
    sublinear_tf=True,
    ngram_range=(1, 1),
    strip_accents="unicode",
    token_pattern=r"(?u)\b\w+\b"
)

X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# Logistic Regression - lightweight, efficient, good for text classification
# saga solver is efficient for larger datasets; lbfgs for moderate