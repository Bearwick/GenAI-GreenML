# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import os
import pickle
import random
import numpy as np
import pandas as pd
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

SEED = 42
random.seed(SEED)
np.random.seed(SEED)

DATASET_PATH = "dict.pickle"


def read_csv_robust(path):
    try:
        df = pd.read_csv(path)
    except Exception:
        df = pd.read_csv(path, sep=";", decimal=",")
        return df
    if df.shape[1] == 1:
        try:
            df_alt = pd.read_csv(path, sep=";", decimal=",")
            if df_alt.shape[1] > 1:
                df = df_alt
        except Exception:
            pass
    return df


def load_object(path):
    if not os.path.exists(path):
        return None
    ext = os.path.splitext(path)[1].lower()
    if ext in (".csv", ".txt", ".tsv"):
        try:
            return read_csv_robust(path)
        except Exception:
            return None
    try:
        with open(path, "rb") as f:
            return pickle.load(f)
    except Exception:
        try:
            return read_csv_robust(path)
        except Exception:
            return None


def get_dataset_headers():
    headers = globals().get("DATASET_HEADERS", None)
    if headers is None:
        env_headers = os.environ.get("DATASET_HEADERS")
        if env_headers:
            headers = env_headers
    if isinstance(headers, str):
        try:
            import ast
            parsed = ast.literal_eval(headers)
            if isinstance(parsed, (list, tuple)):
                headers = list(parsed)
            else:
                headers = [h.strip() for h in headers.split(",") if h.strip()]
        except Exception:
            headers = [h.strip() for h in headers.split(",") if h.strip()]
    if isinstance(headers, (list, tuple)):
        return list(headers)
    return None


def resolve_headers(df):
    headers = get_dataset_headers()
    if not headers:
        return df
    col_map = {str(c).lower(): c for c in df.columns}
    mapped = []
    for h in headers:
        key = str(h).lower()
        if key in col_map:
            mapped.append(col_map[key])
        else:
            mapped = None
            break
    if mapped:
        return df[mapped]
    return df


def to_numeric_array(obj):
    if isinstance(obj, (pd.DataFrame, pd.Series)):
        try:
            arr = obj.to_numpy(dtype=float)
        except Exception:
            arr = obj.apply(pd.to_numeric, errors="coerce").to_numpy(dtype=float)
    else:
        arr = np.asarray(obj, dtype=float)
    return np.nan_to_num(arr)


def extract_from_df(df):
    df = resolve_headers(df)
    cols_lower = {str(c).lower(): c for c in df.columns}
    label_col = None
    for key in ("label", "labels", "target", "class", "y"):
        if key in cols_lower:
            label_col = cols_lower[key]
            break
    if label_col is None:
        label_col = df.columns[-1]
    y = to_numeric_array(df[label_col]).reshape(-1)
    X = to_numeric_array(df.drop(columns=[label_col]))
    return X, y


def extract_from_mapping(m):
    key_pairs = (
        ("data", "target"),
        ("features", "labels"),
        ("X", "y"),
        ("x", "y"),
        ("inputs", "outputs"),
        ("inputs", "labels"),
        ("features", "target"),
        ("data", "labels"),
    )
    for kx, ky in key_pairs:
        if kx in m and ky in m:
            return np.asarray(m[kx]), np.asarray(m[ky])
    X = None
    for kx in ("data", "X", "x", "features", "inputs"):
        if kx in m:
            X = np.asarray(m[kx])
            break
    y = None
    for ky in ("target", "y", "labels", "label", "outputs"):
        if ky in m:
            y = np.asarray(m[ky])
            break
    if X is not None:
        if y is None and X.ndim == 2 and X.shape[1] >= 2:
            return X[:, :-1], X[:, -1]
        return X, y
    return None, None


def extract_xy(obj):
    if isinstance(obj, pd.DataFrame):
        return extract_from_df(obj)
    if isinstance(obj, dict):
        X, y = extract_from_mapping(obj)
        if X is not None:
            return X, y
    if hasattr(obj, "data") and hasattr(obj, "target"):
        return np.asarray(obj.data), np.asarray(obj.target)
    if isinstance(obj, (list, tuple)):
        if len(obj) >= 2 and isinstance(obj[0], (np.ndarray, list, pd.DataFrame)) and isinstance(obj[1], (np.ndarray, list, pd.Series)):
            return np.asarray(obj[0]), np.asarray(obj[1])
    try:
        arr = np.asarray(obj)
    except Exception:
        return None, None
    if arr.ndim == 0:
        return None, None
    if arr.ndim == 1:
        if arr.size < 2:
            return None, None
        return arr.reshape(-1, 1), None
    if arr.ndim >= 2 and arr.shape[1] >= 2:
        return arr[:, :-1], arr[:, -1]
    return arr, None


def is_estimator(obj):
    return hasattr(obj, "predict") and hasattr(obj, "fit") and not isinstance(obj, (pd.DataFrame, np.ndarray, dict, list, tuple))


def extract_from_estimator(est):
    X = None
    for attr in ("X_", "x_", "data_", "training_data_", "support_vectors_"):
        if hasattr(est, attr):
            X = getattr(est, attr)
            break
    y = None
    for attr in ("y_", "labels_", "target_", "_y"):
        if hasattr(est, attr):
            y = getattr(est, attr)
            break
    if X is None:
        return None, None
    X = np.asarray(X)
    if y is not None:
        y = np.asarray(y).reshape(-1)
    return X, y


def prepare_labels(y):
    if y is None:
        return None
    y_arr = np.nan_to_num(np.asarray(y, dtype=float).reshape(-1))
    return np.sign(y_arr).astype(int)


def align_xy(X, y):
    if X is None:
        return None, None
    X_arr = np.nan_to_num(np.asarray(X, dtype=float))
    if X_arr.ndim == 1:
        X_arr = X_arr.reshape(-1, 1)
    if y is None:
        return X_arr, None
    y_arr = np.asarray(y)
    if y_arr.ndim > 1:
        y_arr = y_arr.reshape(-1)
    if len(y_arr) != len(X_arr):
        n = min(len(y_arr), len(X_arr))
        X_arr = X_arr[:n]
        y_arr = y_arr[:n]
    return X_arr, y_arr


def load_features_labels(path):
    obj = load_object(path)
    if obj is None:
        return None, None, None
    X, y = extract_xy(obj)
    model = None
    if (X is None or y is None) and is_estimator(obj):
        model = obj
        X_est, y_est = extract_from_estimator(obj)
        if X is None:
            X = X_est
        if y is None:
            y = y_est
    if (X is None or y is None) and os.path.exists("input.csv"):
        X_in, y_in = extract_xy(read_csv_robust("input.csv"))
        if X is None:
            X = X_in
        if y is None:
            y = y_in
    return X, y, model


def train_and_evaluate(X, y):
    if y is None or X is None or len(X) == 0 or np.unique(y).size < 2:
        return 0.0
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)
    clf = SVC(kernel="linear", random_state=SEED)
    clf.fit(X_train, y_train)
    pred = clf.predict(X_test)
    return accuracy_score(y_test, pred)


def evaluate_model(model, X, y):
    if y is None or X is None:
        return 0.0
    pred = model.predict(X)
    return accuracy_score(y, pred)


def main():
    X, y, model = load_features_labels(DATASET_PATH)
    if X is None:
        accuracy = 0.0
    else:
        X, y = align_xy(X, y)
        if y is None:
            accuracy = 0.0
        else:
            y = prepare_labels(y)
            if model is not None:
                accuracy = evaluate_model(model, X, y)
            else:
                accuracy = train_and_evaluate(X, y)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Consolidated robust data loading to avoid repeated parsing and unnecessary I/O.
# - Replaced per-row loops with vectorized NumPy conversions and label mapping.
# - Removed global mutable state and model persistence to reduce memory and disk overhead.
# - Added deterministic seeds and fixed split configuration for reproducible results.
# - Minimized data copies by converting to NumPy arrays once and aligning shapes in a single pass.