# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# Load the pickle file
DATASET_PATH = "dict.pickle"

with open(DATASET_PATH, "rb") as f:
    data = pickle.load(f, encoding="latin1")

# Inspect what we got
if isinstance(data, dict):
    # Try to construct a DataFrame from the dict
    # The dict might have arrays or lists as values
    # Check if it looks like {column_name: array_of_values}
    # or if it's a nested structure
    keys = list(data.keys())

    # Check if values are array-like (could be a table)
    is_tabular = True
    lengths = []
    for k in keys:
        v = data[k]
        if hasattr(v, '__len__') and not isinstance(v, str):
            lengths.append(len(v))
        else:
            is_tabular = False
            break

    if is_tabular and len(set(lengths)) == 1 and len(lengths) > 0:
        df = pd.DataFrame(data)
    elif is_tabular and len(set(lengths)) > 1:
        # Different lengths - maybe some keys are metadata
        # Try to find the most common length
        from collections import Counter
        length_counts = Counter(lengths)
        most_common_len = length_counts.most_common(1)[0][0]
        filtered = {k: data[k] for k in keys if hasattr(data[k], '__len__') and not isinstance(data[k], str) and len(data[k]) == most_common_len}
        df = pd.DataFrame(filtered)
    else:
        # Maybe it's a dict with 'data', 'target', 'feature_names' etc (sklearn-like)
        if 'data' in data and 'target' in data:
            X_raw = np.array(data['data'])
            y_raw = np.array(data['target'])
            if 'feature_names' in data:
                feature_names = list(data['feature_names'])
            else:
                feature_names = [f"f{i}" for i in range(X_raw.shape[1])]
            df = pd.DataFrame(X_raw, columns=feature_names)
            df['target'] = y_raw
        else:
            # Last resort: try to make a single-row DataFrame or raise
            # Or maybe it's a dict of dicts
            try:
                df = pd.DataFrame(data)
            except Exception:
                # Try from dict of dicts
                try:
                    df = pd.DataFrame.from_dict(data, orient='index')
                except Exception:
                    # Create dummy
                    df = pd.DataFrame({'value': list(data.values())}, index=list(data.keys()))
elif isinstance(data, (pd.DataFrame,)):
    df = data
elif isinstance(data, (list, np.ndarray)):
    df = pd.DataFrame(data)
else:
    # Try converting
    df = pd.DataFrame(data)

# Normalize column names
df.columns = [str(c).strip() for c in df.columns]
df.columns = [' '.join(c.split()) for c in df.columns]
# Drop 'Unnamed' columns
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# Identify target column
# Based on README context: classification of junctional features
# Target likely encodes -1 (remodelling), 0 (mixed), 1 (inactive)
# Look for a column that could be the target

target_col = None

# Heuristic: look for columns named 'target', 'label', 'class', 'category', 'y', 'output'
target_candidates = ['