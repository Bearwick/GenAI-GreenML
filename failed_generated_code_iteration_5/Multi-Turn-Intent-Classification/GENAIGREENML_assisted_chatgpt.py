# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import json
import csv
import random
from typing import List, Dict, Any, Optional

import numpy as np
import torch
from transformers import pipeline


SEED = 42


def set_reproducible_seed(seed: int = SEED) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    try:
        torch.use_deterministic_algorithms(True)
    except Exception:
        pass
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True


class IntentDetector:
    def __init__(self, device: int):
        self.intent_options = [
            "Book Appointment",
            "Product Inquiry",
            "Pricing Negotiation",
            "Support Request",
            "Follow-Up",
        ]
        self.intent_pipeline = pipeline(
            task="zero-shot-classification",
            model="cross-encoder/nli-distilroberta-base",
            device=device,
        )

    def classify_intent(self, dialogue: str) -> Dict[str, str]:
        classification = self.intent_pipeline(dialogue, self.intent_options)
        top_intent = classification["labels"][0]
        rationale = f"Based on the conversation, the customer is likely interested in '{top_intent.lower()}'."
        return {"predicted_intent": top_intent, "rationale": rationale}


def create_conversation(messages: List[Dict[str, Any]], max_messages: Optional[int] = None) -> str:
    if not messages:
        return ""
    if max_messages is not None:
        messages = messages[-max_messages:]
    return "\n".join(
        f"{(m.get('sender') or '').capitalize()}: {m.get('text') or ''}"
        for m in messages
    )


def load_conversations_json(path: str) -> List[Dict[str, Any]]:
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if isinstance(data, list):
        return data
    if isinstance(data, dict):
        for key in ("conversations", "data", "items"):
            if key in data and isinstance(data[key], list):
                return data[key]
    return []


def predict_intents(
    input_file: str,
    json_output: str,
    csv_output: str,
    detector: IntentDetector,
) -> List[Dict[str, Any]]:
    conversations = load_conversations_json(input_file)
    output_data: List[Dict[str, Any]] = []

    append = output_data.append
    for entry in conversations:
        formatted_text = create_conversation(entry.get("messages") or [])
        intent_result = detector.classify_intent(formatted_text)
        append(
            {
                "conversation_id": entry.get("conversation_id"),
                "predicted_intent": intent_result["predicted_intent"],
                "rationale": intent_result["rationale"],
            }
        )

    with open(json_output, "w", encoding="utf-8") as jf:
        json.dump(output_data, jf, ensure_ascii=False, indent=2)

    with open(csv_output, "w", newline="", encoding="utf-8") as cf:
        writer = csv.DictWriter(cf, fieldnames=["conversation_id", "predicted_intent", "rationale"])
        writer.writeheader()
        writer.writerows(output_data)

    return output_data


def compute_accuracy(output_data: List[Dict[str, Any]], input_file: str) -> float:
    if not output_data:
        return 0.0

    conversations = load_conversations_json(input_file)
    id_to_true: Dict[Any, Any] = {}
    for entry in conversations:
        cid = entry.get("conversation_id")
        if cid is None:
            continue
        true_label = entry.get("intent") if "intent" in entry else entry.get("true_intent")
        if true_label is not None:
            id_to_true[cid] = true_label

    correct = 0
    total = 0
    for rec in output_data:
        cid = rec.get("conversation_id")
        if cid in id_to_true:
            total += 1
            if rec.get("predicted_intent") == id_to_true[cid]:
                correct += 1

    return (correct / total) if total else 0.0


def main() -> None:
    set_reproducible_seed(SEED)

    device = 0 if torch.cuda.is_available() else -1
    detector = IntentDetector(device=device)

    os.makedirs("data/output", exist_ok=True)
    input_path = "data/input.json"
    json_out = "data/output/predictions.json"
    csv_out = "data/output/predictions.csv"

    output_data = predict_intents(
        input_file=input_path,
        json_output=json_out,
        csv_output=csv_out,
        detector=detector,
    )

    accuracy = compute_accuracy(output_data, input_path)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused preprocessing (emoji/punctuation cleaning) to avoid redundant computation and preserve the original pipeline behavior.
# - Centralized seeding and enabled deterministic settings to ensure reproducible results without repeated configuration.
# - Selected device once (CPU/GPU) and passed it to the pipeline to avoid implicit device transfers and reduce overhead.
# - Avoided extra intermediate structures by using a generator-based join in create_conversation and caching list.append locally in the main loop.
# - Implemented robust JSON loading that tolerates common wrapper schemas while keeping parsing minimal.
# - Kept file I/O to the required outputs only and removed all non-required prints/logging, adding only the mandated accuracy print.