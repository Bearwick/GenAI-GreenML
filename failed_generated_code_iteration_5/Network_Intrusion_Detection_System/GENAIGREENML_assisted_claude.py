# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

COLUMN_NAMES = [
    "duration", "protocol_type", "service", "flag", "src_bytes", "dst_bytes",
    "land", "wrong_fragment", "urgent", "hot", "num_failed_logins", "logged_in",
    "num_compromised", "root_shell", "su_attempted", "num_root",
    "num_file_creations", "num_shells", "num_access_files", "num_outbound_cmds",
    "is_host_login", "is_guest_login", "count", "srv_count", "serror_rate",
    "srv_serror_rate", "rerror_rate", "srv_rerror_rate", "same_srv_rate",
    "diff_srv_rate", "srv_diff_host_rate", "dst_host_count", "dst_host_srv_count",
    "dst_host_same_srv_rate", "dst_host_diff_srv_rate", "dst_host_same_src_port_rate",
    "dst_host_srv_diff_host_rate", "dst_host_serror_rate", "dst_host_srv_serror_rate",
    "dst_host_rerror_rate", "dst_host_srv_rerror_rate", "attack_type", "difficulty_level"
]

CATEGORICAL_COLS = ["protocol_type", "service", "flag"]


def load_data(path):
    try:
        df = pd.read_csv(path, header=None)
        if df.shape[1] == 1:
            df = pd.read_csv(path, header=None, sep=';', decimal=',')
    except Exception:
        df = pd.read_csv(path, header=None, sep=';', decimal=',')
    if df.shape[1] == len(COLUMN_NAMES):
        df.columns = COLUMN_NAMES
    elif df.shape[1] == len(COLUMN_NAMES) - 1:
        df.columns = COLUMN_NAMES[:-1]
    return df


def preprocess(df, label_encoders=None, scaler=None, fit=True):
    df = df.copy()

    if "difficulty_level" in df.columns:
        df.drop("difficulty_level", axis=1, inplace=True)

    y = (df["attack_type"] != "normal").astype(np.int8)
    df.drop("attack_type", axis=1, inplace=True)

    if fit:
        label_encoders = {}
        for col in CATEGORICAL_COLS:
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col].astype(str))
            label_encoders[col] = le
    else:
        for col in CATEGORICAL_COLS:
            le = label_encoders[col]
            df[col] = df[col].astype(str).map(
                lambda x, _le=le: _le.transform([x])[0] if x in _le.classes_ else -1
            )

    if fit:
        scaler = StandardScaler()
        X = scaler.fit_transform(df.values.astype(np.float32))
    else:
        X = scaler.transform(df.values.astype(np.float32))

    return X, y.values, label_encoders, scaler


train_df = load_data("data/raw/Train.txt")

X_all, y_all, label_encoders, scaler = preprocess(train_df, fit=True)

n_train = int(len(y_all) * 0.8)
indices = np.random.RandomState(RANDOM_SEED).permutation(len(y_all))
train_idx, test_