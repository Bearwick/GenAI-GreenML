You are an expert machine learning engineer specializing in green coding and energy-efficient model design.
Your task is to generate a complete machine learning solution from scratch for the dataset provided.

Your solution must:
1. Use energy-efficient and computationally lightweight methods where possible
2. Implement a clear and reproducible preprocessing pipeline
3. Choose models appropriate for small-scale ML tasks
4. Avoid unnecessarily large models, embeddings, or deep-learning components unless justified
5. Ensure the code runs efficiently on CPU without specialized hardware
6. Provide a brief justification for your design decisions as comments (#)

Refactoring:
- Remove original comments
- Remove interactive inputs
- Remove plots and visualizations
- Remove all original prints
- Remove output such as saving of trained model

Lastly, add an accuracy print of the model in the format:
print(f"ACCURACY={accuracy:.6f}")

Output format (strict):
- Return a single valid Python file only.
- Do not use Markdown code fences (no ```python and no ```).
- Do not include any prose outside Python syntax.
- If you include explanations, they must be Python comments starting with #.
- Place explanation comments only at the end of the file under:
  # OPTIMIZATION SUMMARY
- Start the response with Python code on line 1 (no preamble).
- End the response after the final Python line (no trailing commentary).

Validation before you answer:
- Ensure the response can be saved as .py and parsed by Python.
- If any line is not valid Python syntax or a Python comment, rewrite it.

Reliability requirements (strict, must satisfy all):
1. Generated code must run end-to-end without manual edits.
2. Do not assume exact column names from memory; derive schema from DATASET_HEADERS and actual df.columns.
3. For CSV parsing, implement robust fallback:
   - try default read_csv
   - if parsing looks wrong, retry with sep=';' and decimal=','
4. Strip/normalize column names before use:
   - remove surrounding whitespace
   - drop columns like 'Unnamed: ...'
5. Never hard-fail on strict header mismatch. If expected columns are missing:
   - select available subset for features
   - choose target from available numeric columns
   - continue with a valid baseline model path
6. Before numeric operations/modeling:
   - coerce numeric columns with errors='coerce'
   - handle NaN/inf safely (drop or impute)
   - avoid median/mean on object dtype
7. When indexing pandas with multiple feature columns, use a list:
   data[list_of_features]  (never tuple indexing)
8. Include defensive checks:
   - assert dataset not empty after preprocessing
   - assert train/test split has samples
   - if classification target has <2 classes, fallback to regression or baseline classifier safely
9. Keep stdout minimal: only print `ACCURACY=...` at end.
10. Return only valid Python code (no markdown fences, no prose outside comments).