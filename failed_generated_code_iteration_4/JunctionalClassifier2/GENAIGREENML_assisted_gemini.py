# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import os

def robust_load(path):
    if not os.path.exists(path):
        return None
    try:
        df = pd.read_csv(path)
        if df.shape[1] <= 1:
            df = pd.read_csv(path, sep=';', decimal=',')
        df = df.dropna(axis=1, how='all')
        df = df.apply(pd.to_numeric, errors='coerce').dropna()
        return df
    except:
        try:
            data = pd.read_pickle(path)
            if isinstance(data, pd.DataFrame):
                return data
            if isinstance(data, np.ndarray):
                return pd.DataFrame(data)
        except:
            return None
    return None

def main():
    target_file = None
    for f in ['14k.csv', 'input.csv', 'dict.pickle']:
        if os.path.exists(f):
            target_file = f
            break
    
    df = robust_load(target_file) if target_file else None
    
    if df is not None and not df.empty:
        data = df.values
        X = data[:, :-1]
        y_raw = data[:, -1]
        
        y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0))
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        
        clf = KNeighborsClassifier(n_neighbors=4)
        clf.fit(X_train, y_train)
        
        y_pred = clf.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# 1. Replaced inefficient manual CSV parsing loops with vectorized pandas.read_csv for faster I/O and lower CPU overhead.
# 2. Implemented a robust data loading utility with fallback mechanisms for different separators and file formats (CSV/Pickle).
# 3. Replaced high-memory Python list-of-lists structures with memory-efficient NumPy arrays.
# 4. Vectorized label transformation using np.where, eliminating redundant conditional logic and loops.
# 5. Removed redundant model serialization (pickle save/load) during the execution pipeline to minimize disk I/O.
# 6. Enforced reproducibility using a fixed random seed (random_state=42) to ensure stable benchmarks.
# 7. Optimized data cleaning by leveraging pandas' vectorized 'dropna' and 'to_numeric' methods.
# 8. Eliminated unnecessary global variables and deep copy operations to reduce memory footprint.