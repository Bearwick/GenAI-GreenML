# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import json
import warnings
warnings.filterwarnings('ignore')

# Step 1: Load the dataset robustly
data = None
try:
    with open('train.json', 'r') as f:
        data = json.load(f)
except Exception:
    try:
        data = pd.read_json('train.json')
    except Exception:
        pass

if data is None:
    print("ACCURACY=0.000000")
    import sys
    sys.exit(0)

# Convert to DataFrame if needed
if isinstance(data, list):
    df = pd.DataFrame(data)
elif isinstance(data, dict):
    df = pd.DataFrame(data)
else:
    df = data.copy()

# Step 2: Normalize column names
df.columns = [str(c).strip().lower() for c in df.columns]
df = df[[c for c in df.columns if not c.startswith('unnamed')]]

# Step 3: Identify target and features
# Based on the project context, this is a cuisine prediction task from ingredients
target_col = None
ingredients_col = None

for c in df.columns:
    if 'cuisine' in c:
        target_col = c
    if 'ingredient' in c:
        ingredients_col = c

# Fallback: if columns not found by name, try to detect
if target_col is None:
    # Look for a string column with multiple categories (not ingredients-like)
    for c in df.columns:
        if df[c].dtype == object and c != 'id':
            unique_ratio = df[c].nunique() / len(df)
            if unique_ratio < 0.05:  # likely a categorical target
                target_col = c
                break

if ingredients_col is None:
    # Look for a column that contains lists
    for c in df.columns:
        if c == target_col or c == 'id':
            continue
        sample = df[c].dropna().iloc[0] if len(df[c].dropna()) > 0 else None
        if isinstance(sample, list):
            ingredients_col = c
            break

assert target_col is not None, "Could not find target column"
assert ingredients_col is not None, "Could not find ingredients column"

# Step 4: Preprocess ingredients - join list into a single string per recipe
df['ingredients_text'] = df[ingredients_col].apply(
    lambda x: ' '.join(x) if isinstance(x, list) else str(x)
)

# Clean text: lowercase, remove special characters
df['ingredients_text'] = df['ingredients_text'].str.lower().str.replace(r'[^a-z\s]', ' ', regex=True)

# Remove rows with missing target or ingredients
df = df.dropna(subset=[target_col, 'ingredients_text'])
df = df[df['ingredients_text'].str.strip() != '']
assert len(df) > 0, "Dataset empty after preprocessing"

# Step 5: Encode target
le = LabelEncoder()
y = le.fit_transform(df[target_col])
n_classes = len(le.classes_)

assert n_classes >= 2, "Need at least 2 classes for classification"

X_text = df['ingredients_text'].values

# Step 6: Train/test split
X_train_text, X_test_text, y_train, y_test = train_test_split(
    X_text, y, test_size=0.2, random_state=42, stratify=y
)

assert len(X_train_text) > 0 and len(X_test_text) > 0, "Train/test split produced empty sets"

# Step 7: TF-IDF vectorization (energy-efficient: limit features)
# Using max_features to keep dimensionality manageable on