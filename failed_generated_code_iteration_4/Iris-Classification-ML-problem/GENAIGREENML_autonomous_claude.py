# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score
import os
import glob

# Step 1: Find the actual dataset file
# The provided DATASET_PATH is "requirements.txt" which is not the real dataset.
# We need to search for the actual Iris CSV file in the project directory.

dataset_path = None
search_dirs = [
    os.path.dirname(os.path.abspath(__file__)) if '__file__' in dir() else '.',
    '.',
    '..',
    os.path.expanduser('~/Documents/NTNU/Master/Master Thesis/GenAI-GreenML/repos/Iris-Classification-ML-problem'),
]

for search_dir in search_dirs:
    if not os.path.isdir(search_dir):
        continue
    for pattern in ['*.csv', '**/*.csv']:
        found = glob.glob(os.path.join(search_dir, pattern), recursive=True)
        for f in found:
            if 'iris' in os.path.basename(f).lower() or 'data' in os.path.basename(f).lower():
                dataset_path = f
                break
            if dataset_path is None and f.endswith('.csv'):
                dataset_path = f
        if dataset_path:
            break
    if dataset_path:
        break

# If no CSV found, try common Iris dataset locations or fall back to sklearn's iris
if dataset_path is None:
    # Try any CSV in current directory tree
    for search_dir in search_dirs:
        if not os.path.isdir(search_dir):
            continue
        found = glob.glob(os.path.join(search_dir, '**/*.csv'), recursive=True)
        if found:
            dataset_path = found[0]
            break

df = None

if dataset_path is not None and os.path.isfile(dataset_path):
    # Robust CSV parsing
    try:
        df = pd.read_csv(dataset_path)
        if df.shape[1] < 2:
            df = pd.read_csv(dataset_path, sep=';', decimal=',')
    except Exception:
        try:
            df = pd.read_csv(dataset_path, sep=';', decimal=',')
        except Exception:
            df = None

# Fallback: use sklearn's built-in iris dataset
if df is None or df.empty or df.shape[1] < 2:
    from sklearn.datasets import load_iris
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['species'] = iris.target_names[iris.target]

# Step 2: Clean column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
drop_cols = [c for c in df.columns if c.startswith('Unnamed')]
if drop_cols:
    df = df.drop(columns=drop_cols)

assert df.shape[0] > 0 and df.shape[1] >= 2, "Dataset is empty or has too few columns after cleaning"

# Step 3: Identify target and features
# For Iris, the target is typically the last column or a column with species/class names
target_col = None
# Look for likely target column names
for col in df.columns:
    col_lower = col.lower()
    if any(kw in col_lower for kw in ['species', 'class', 'variety', 'target', 'label', 'type']):
        target_col = col
        break

if target_col is None:
    # Use the last column if it's categorical (object/string), otherwise pick the last column
    if df.dtypes.iloc[-1] == object:
        target_col = df.columns[-1]
    else:
        # Check if any column is object type
        obj_cols