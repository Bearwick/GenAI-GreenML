# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# Load the pickle file
DATASET_PATH = "dict.pickle"

with open(DATASET_PATH, "rb") as f:
    data = pickle.load(f, encoding="latin1")

# Inspect what we got
if isinstance(data, dict):
    # Try to convert dict to DataFrame
    # Common patterns: {'features': ..., 'labels': ...} or column-based dict
    keys = list(data.keys())
    
    # Check if values are arrays/lists of same length -> column-based dict
    lengths = {}
    for k, v in data.items():
        if hasattr(v, '__len__') and not isinstance(v, str):
            lengths[k] = len(v)
    
    if len(lengths) > 0 and len(set(lengths.values())) == 1:
        # All same length, treat as column-based DataFrame
        df = pd.DataFrame(data)
    elif len(lengths) > 0:
        # Different lengths - might be features + labels stored separately
        # Try common key patterns
        feature_keys = [k for k in keys if k.lower() in ('features', 'data', 'x', 'train_data', 'feature')]
        label_keys = [k for k in keys if k.lower() in ('labels', 'label', 'y', 'target', 'targets', 'class', 'classes')]
        
        if feature_keys and label_keys:
            X_raw = np.array(data[feature_keys[0]])
            y_raw = np.array(data[label_keys[0]]).ravel()
            # Create DataFrame from features
            if X_raw.ndim == 2:
                df = pd.DataFrame(X_raw, columns=[f"feat_{i}" for i in range(X_raw.shape[1])])
            else:
                df = pd.DataFrame(X_raw, columns=["feat_0"])
            df["target"] = y_raw
        else:
            # Try to figure out: largest array might be features, matching length array is labels
            sorted_keys = sorted(lengths.keys(), key=lambda k: lengths[k], reverse=True)
            # Or try to build from whatever we have
            # Fallback: just use all arrays
            max_len = max(lengths.values())
            cols = {k: np.array(data[k]).ravel() for k in lengths if lengths[k] == max_len}
            if len(cols) > 1:
                df = pd.DataFrame(cols)
            else:
                # Single large array - check if 2D
                single_key = list(cols.keys())[0]
                arr = np.array(data[single_key])
                if arr.ndim == 2:
                    df = pd.DataFrame(arr, columns=[f"feat_{i}" for i in range(arr.shape[1])])
                    # Look for a label array
                    for k in lengths:
                        if lengths[k] == arr.shape[0] and k != single_key:
                            df["target"] = np.array(data[k]).ravel()
                            break
                else:
                    df = pd.DataFrame({single_key: arr.ravel()})
    else:
        # Values might be nested structures
        # Try direct DataFrame construction
        try:
            df = pd.DataFrame(data)
        except Exception:
            # Last resort: try to extract any usable structure
            df = pd.DataFrame()
            for k, v in data.items():
                try:
                    arr = np.array(v)
                    if arr.ndim <= 2:
                        if arr.ndim == 2:
                            for i in range(arr.shape[1]):
                                df[f