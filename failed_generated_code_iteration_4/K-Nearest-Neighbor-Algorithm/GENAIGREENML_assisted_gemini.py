# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
import os

def load_robust(path):
    if not os.path.exists(path):
        return None
    try:
        df = pd.read_csv(path)
        if df.shape[1] < 2:
            raise ValueError
        return df
    except Exception:
        return pd.read_csv(path, sep=';', decimal=',')

def knn_predict(x_train, y_train, x_test, k):
    distances_sq = np.sum((x_train - x_test)**2, axis=1)
    k_idx = np.argsort(distances_sq)[:k]
    
    k_dists = np.sqrt(distances_sq[k_idx])
    k_labels = y_train[k_idx]
    
    votes = {}
    for d, l in zip(k_dists, k_labels):
        weight = 1.0 / (d if d > 0 else 1e-10)
        votes[l] = votes.get(l, 0) + weight
    
    max_weight = -1.0
    best_class = None
    for label, weight in votes.items():
        if weight > max_weight:
            max_weight = weight
            best_class = label
    return best_class

def main():
    np.random.seed(42)
    
    train_df = load_robust("MNIST_train.csv")
    test_df = load_robust("MNIST_test.csv")
    
    if train_df is None:
        return

    if test_df is None:
        test_df = train_df.sample(n=min(len(train_df), 500), random_state=42)
        train_df = train_df.drop(test_df.index)

    x_train = train_df.iloc[:, 1:].values.astype('float32')
    y_train = train_df.iloc[:, 0].values
    x_test = test_df.iloc[:, 1:].values.astype('float32')
    y_test = test_df.iloc[:, 0].values

    k = 7
    correct = 0
    total = len(x_test)

    for i in range(total):
        prediction = knn_predict(x_train, y_train, x_test[i], k)
        if prediction == y_test[i]:
            correct += 1

    accuracy = (correct / total) * 100
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# 1. Vectorized Euclidean distance computation using NumPy to replace nested Python loops and math.pow.
# 2. Replaced manual top-K search logic with NumPy's optimized argsort for faster neighbor selection.
# 3. Optimized memory footprint by using float32 for pixel data and avoiding redundant list copies.
# 4. Implemented robust CSV parsing with fallbacks for different delimiters and decimals.
# 5. Minimized redundant calculations by only computing square roots for the final K-nearest neighbors.
# 6. Eliminated redundant dictionary max() calls inside loops to reduce computational overhead.
# 7. Reduced data movement by loading datasets directly into NumPy arrays for high-performance processing.
# 8. Ensured reproducibility using a fixed random seed for any stochastic operations like data splitting.
# 9. Simplified preprocessing by using pandas' built-in header and type handling.
# 10. Avoided unnecessary intermediate data structures by using a single-pass voting mechanism.