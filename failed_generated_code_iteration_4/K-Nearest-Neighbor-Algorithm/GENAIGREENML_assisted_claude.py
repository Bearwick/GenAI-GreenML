# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import pandas as pd

RANDOM_SEED = 42

def load_data(filepath):
    try:
        df = pd.read_csv(filepath)
        if df.shape[1] < 3:
            df = pd.read_csv(filepath, sep=';', decimal=',')
    except Exception:
        df = pd.read_csv(filepath, sep=';', decimal=',')
    return df

def main():
    df = load_data("MNIST_train.csv")
    label_col = df.columns[0]
    feature_cols = df.columns[1:]
    X = df[feature_cols].values.astype(np.float32)
    y = df[label_col].values.astype(np.int32)
    X /= 255.0
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y
    )
    k = 7
    knn = KNeighborsClassifier(
        n_neighbors=k,
        weights='distance',
        algorithm='ball_tree',
        n_jobs=-1
    )
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    correct = np.sum(y_pred == y_test)
    total = len(y_test)
    accuracy = (correct / total) * 100
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Replaced manual pure-Python KNN with sklearn KNeighborsClassifier using ball_tree for O(n log n) queries instead of O(n*m) brute force in Python loops.
# - Used numpy arrays with float32 dtype to reduce memory footprint by half compared to float64.
# - Normalized pixel values once (divide by 255) to improve distance computation numerical stability and tree performance.
# - Used n_jobs=-1 to parallelize neighbor searches across available CPU cores.
# - Used weights='distance' to match original weighted voting scheme (1/distance).
# - Eliminated all redundant Python-level loops for distance computation, replaced with optimized C-level sklearn internals.
# - Since original code uses separate train/test CSVs but only train CSV is guaranteed available, used train_test_split with stratification for evaluation.
# - Removed all prints, plots, and file saves except the required accuracy output.
# - Fixed random seed for reproducibility.
# - Robust CSV loading with fallback separator handling.