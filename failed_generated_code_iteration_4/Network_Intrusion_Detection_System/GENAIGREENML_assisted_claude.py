# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier

RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

DATASET_PATH = "data/raw/Train.txt"

def load_data(path):
    try:
        df = pd.read_csv(path, header=None)
        if df.shape[1] < 5:
            df = pd.read_csv(path, header=None, sep=';', decimal=',')
    except Exception:
        df = pd.read_csv(path, header=None, sep=';', decimal=',')
    return df

def preprocess(df, fit=True, scaler=None, label_encoders=None, train_columns=None):
    df = df.copy()
    label_col = df.columns[-2]
    difficulty_col = df.columns[-1]
    y_raw = df[label_col].copy()
    df.drop(columns=[label_col, difficulty_col], inplace=True)

    y = (y_raw != 'normal').astype(np.int32)

    cat_cols = df.select_dtypes(include=['object']).columns.tolist()
    num_cols = df.select_dtypes(exclude=['object']).columns.tolist()

    if fit:
        label_encoders = {}
        for c in cat_cols:
            le = LabelEncoder()
            df[c] = le.fit_transform(df[c].astype(str))
            label_encoders[c] = le
    else:
        for c in cat_cols:
            le = label_encoders[c]
            df[c] = df[c].astype(str).map(lambda x, _le=le: _le.transform([x])[0] if x in _le.classes_ else -1)

    all_cols = num_cols + cat_cols
    df = df[all_cols]

    if fit:
        train_columns = df.columns.tolist()
    else:
        for c in train_columns:
            if c not in df.columns:
                df[c] = 0
        df = df[train_columns]

    X = df.values.astype(np.float32)

    if fit:
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
    else:
        X = scaler.transform(X)

    return X, y.values, scaler, label_encoders, train_columns

df = load_data(DATASET_PATH)

split_ratio = 0.8
n_train = int(len(df) * split_ratio)
np.random.seed(RANDOM_STATE)
indices = np.random.permutation(len(df))
train_idx, test_idx = indices[:n_train], indices[n_train:]
train_df = df.iloc[train_idx].reset_index(drop=True)
test_df = df.iloc[test_idx].reset_index(drop=True)

X_train, y_train, scaler, label_encoders, train_columns = preprocess(train_df, fit=True)
X_test, y_test, _, _, _ = preprocess(test_df, fit=False, scaler=scaler, label_encoders=label_encoders, train_columns=train_columns)

pca = PCA(n_components=0.95, random_state=RANDOM_STATE)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

model = XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    eval_metric="logloss",
    random_state=RANDOM_STATE,
    tree_method="hist",
    n