# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
import warnings
warnings.filterwarnings("ignore")

DATASET_PATH = "bodyPerformance.csv"

# Robust CSV loading
df = None
try:
    df = pd.read_csv(DATASET_PATH)
    if df.shape[1] < 3:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')
except Exception:
    try:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')
    except Exception as e:
        raise RuntimeError(f"Cannot load dataset: {e}")

# Normalize column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df.loc[:, ~df.columns.str.startswith('Unnamed')]

# Identify columns from expected schema
expected_headers = [
    "age", "height_cm", "weight_kg", "body fat_%", "diastolic", "systolic",
    "gripForce", "sit and bend forward_cm", "sit-ups counts", "broad jump_cm", "Blass"
]

# Map expected to actual columns (case-insensitive fuzzy match)
col_map = {}
actual_lower = {c.lower().strip(): c for c in df.columns}
for eh in expected_headers:
    el = eh.lower().strip()
    if el in actual_lower:
        col_map[eh] = actual_lower[el]

# Determine target column
target_col = None
target_candidates = ["Blass", "class", "Class", "grade", "Grade"]
for tc in target_candidates:
    tc_lower = tc.lower().strip()
    if tc_lower in actual_lower:
        target_col = actual_lower[tc_lower]
        break

# If no known target found, pick last column if it's categorical
if target_col is None:
    last_col = df.columns[-1]
    if df[last_col].dtype == object or df[last_col].nunique() < 20:
        target_col = last_col
    else:
        # Pick first object column
        obj_cols = df.select_dtypes(include=['object']).columns
        if len(obj_cols) > 0:
            target_col = obj_cols[0]
        else:
            target_col = df.columns[-1]

assert target_col is not None, "No target column identified"

# Separate features and target
feature_cols = [c for c in df.columns if c != target_col]

# Coerce numeric columns
for col in feature_cols:
    if df[col].dtype == object:
        try:
            df[col] = pd.to_numeric(df[col].str.replace(',', '.'), errors='coerce')
        except Exception:
            pass

# Classify feature types
numeric_features = []
categorical_features = []
for col in feature_cols:
    if df[col].dtype in [np.float64, np.int64, np.float32, np.int32, float, int]:
        numeric_features.append(col)
    elif df[col].dtype == object:
        if df[col].nunique() < 50:
            categorical_features.append(col)
        # Drop high-cardinality string columns silently

# Encode target
le = LabelEncoder()
is_classification = True

if df[target_col].dtype == object:
    df[target_col] = le.fit_transform(df[target_col].astype(str))
else:
    # Check if it looks like classification
    nunique = df[target_col].nunique()
    if nunique < 20:
        df[target_col] = le.fit_transform(df[