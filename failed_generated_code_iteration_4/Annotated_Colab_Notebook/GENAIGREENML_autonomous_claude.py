# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# Step 1: Load data with robust fallback for ARFF format
def load_arff_as_dataframe(path):
    try:
        from scipy.io import arff
        data, meta = arff.loadarff(path)
        df = pd.DataFrame(data)
        # Decode bytes columns (scipy arff returns bytes for string/nominal)
        for col in df.columns:
            if df[col].dtype == object:
                try:
                    df[col] = df[col].str.decode('utf-8')
                except Exception:
                    pass
        return df
    except Exception:
        pass

    # Fallback: manual ARFF parser
    try:
        columns = []
        data_started = False
        rows = []
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped = line.strip()
                if not stripped or stripped.startswith('%'):
                    continue
                lower = stripped.lower()
                if lower.startswith('@attribute'):
                    parts = stripped.split()
                    col_name = parts[1].strip("'\"")
                    columns.append(col_name)
                elif lower.startswith('@data'):
                    data_started = True
                    continue
                elif data_started:
                    vals = stripped.split(',')
                    vals = [v.strip().strip("'\"") for v in vals]
                    rows.append(vals)
        df = pd.DataFrame(rows, columns=columns)
        # Replace '?' with NaN
        df.replace('?', np.nan, inplace=True)
        return df
    except Exception:
        pass

    # Last fallback: try CSV
    try:
        df = pd.read_csv(path)
        if df.shape[1] < 2:
            df = pd.read_csv(path, sep=';', decimal=',')
        return df
    except Exception:
        df = pd.read_csv(path, sep=';', decimal=',')
        return df

df = load_arff_as_dataframe("dataset_adult.arff")

# Step 2: Clean column names
df.columns = [str(c).strip().replace('\t', ' ') for c in df.columns]
df.columns = [' '.join(c.split()) for c in df.columns]
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# Step 3: Identify target column
# Adult dataset typically has 'class' or 'income' as target
target_col = None
candidate_targets = ['class', 'income', 'target', 'label', 'y']
for candidate in candidate_targets:
    matches = [c for c in df.columns if c.lower() == candidate.lower()]
    if matches:
        target_col = matches[0]
        break

if target_col is None:
    # Use last column as target (common convention for ARFF)
    target_col = df.columns[-1]

feature_cols = [c for c in df.columns if c != target_col]

# Step 4: Clean target
df[target_col] = df[target_col].astype(str).str.strip().str.strip("'\".")

# Drop rows where target is NaN-like
df = df[~df[target_col].isin(['nan', 'NaN', '', 'None'])]

assert df.shape[0] > 0, "Dataset empty after cleaning"

# Step 5: Determine task type
unique_targets = df[target_col].nunique()
is_classification = unique_targets <= 50

# Step 6: Identify numeric vs categorical features
numeric_cols = []
categorical_