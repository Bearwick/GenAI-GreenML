# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


DATASET_HEADERS = ["Id", "SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm", "Species"]
CSV_PATH = "Iris.csv"
RANDOM_SEED = 42


def _read_csv_with_fallback(path: str) -> pd.DataFrame:
    df_default = pd.read_csv(path)
    parsed_wrong = (df_default.shape[1] == 1) or (df_default.columns.size == 1 and ";" in str(df_default.columns[0]))
    if parsed_wrong:
        return pd.read_csv(path, sep=";", decimal=",")
    return df_default


def _align_schema(df: pd.DataFrame) -> pd.DataFrame:
    rename_map = {c: c.strip() for c in df.columns if isinstance(c, str) and c.strip() != c}
    if rename_map:
        df = df.rename(columns=rename_map)

    if df.shape[1] == len(DATASET_HEADERS) and list(df.columns) != DATASET_HEADERS:
        df.columns = DATASET_HEADERS

    return df


def _prepare_xy(df: pd.DataFrame):
    if "Id" in df.columns:
        df = df.drop(columns=["Id"])

    if "Species" not in df.columns:
        raise ValueError(f"Target column 'Species' not found. Available columns: {list(df.columns)}")

    y_raw = df["Species"]
    if not np.issubdtype(y_raw.dtype, np.number):
        y = LabelEncoder().fit_transform(y_raw.astype(str))
    else:
        y = y_raw.to_numpy()

    X = df.drop(columns=["Species"])
    return X, y


def build_pipeline(random_seed: int) -> Pipeline:
    model = LogisticRegression(
        max_iter=200,
        solver="lbfgs",
        n_jobs=1,
        random_state=random_seed,
    )
    return Pipeline([("scaler", StandardScaler()), ("model", model)])


def main() -> None:
    os.environ.setdefault("PYTHONHASHSEED", str(RANDOM_SEED))
    np.random.seed(RANDOM_SEED)

    df = _read_csv_with_fallback(CSV_PATH)
    df = _align_schema(df)
    X, y = _prepare_xy(df)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y
    )

    pipeline = build_pipeline(RANDOM_SEED)
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    _ = cross_val_score(pipeline, X, y, cv=5)

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed plotting/visualization and verbose reporting to eliminate unnecessary compute and rendering overhead.
# - Dropped unused imports (matplotlib, seaborn, extra metrics) to reduce import time and memory footprint.
# - Avoided in-place DataFrame mutations when not needed and limited intermediate objects (single drop for Id/Species split).
# - Added robust CSV parsing fallback (default read_csv, then sep=';' and decimal=',') to prevent costly downstream failures.
# - Derived schema from provided headers and df.columns with lightweight normalization to improve input reliability without extra passes.
# - Ensured reproducibility via fixed seeds and deterministic single-threaded solver usage (n_jobs=1) to stabilize results and reduce energy.