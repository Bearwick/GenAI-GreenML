# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# --- Robust CSV loading ---
file_name = 'iris.csv'

try:
    df = pd.read_csv(file_name)
    if df.shape[1] < 2:
        df = pd.read_csv(file_name, sep=';', decimal=',')
except Exception:
    df = pd.read_csv(file_name, sep=';', decimal=',')

# --- Column name normalization ---
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df.loc[:, ~df.columns.str.startswith('Unnamed')]

# --- Identify target and features ---
expected_target = 'species'
expected_features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']

if expected_target in df.columns:
    target_col = expected_target
else:
    # Fallback: pick the last non-numeric column, or last column
    non_numeric = df.select_dtypes(exclude='number').columns.tolist()
    if non_numeric:
        target_col = non_numeric[-1]
    else:
        target_col = df.columns[-1]

available_features = [c for c in expected_features if c in df.columns]
if len(available_features) == 0:
    available_features = [c for c in df.columns if c != target_col]

# --- Prepare features and target ---
X = df[list(available_features)].copy()
y = df[target_col].copy()

# Coerce features to numeric
for col in X.columns:
    X[col] = pd.to_numeric(X[col], errors='coerce')

# Drop rows with NaN in features or target
valid_mask = X.notna().all(axis=1) & y.notna()
X = X.loc[valid_mask].reset_index(drop=True)
y = y.loc[valid_mask].reset_index(drop=True)

# Replace inf with NaN then drop
X = X.replace([np.inf, -np.inf], np.nan).dropna()
y = y.loc[X.index].reset_index(drop=True)
X = X.reset_index(drop=True)

assert len(X) > 0, "Dataset is empty after preprocessing"

# --- Encode target if categorical ---
is_classification = True
if y.dtype == object or y.dtype.name == 'category':
    le = LabelEncoder()
    y = pd.Series(le.fit_transform(y))
else:
    y_numeric = pd.to_numeric(y, errors='coerce')
    unique_vals = y_numeric.dropna().unique()
    if len(unique_vals) < 20:
        le = LabelEncoder()
        y = pd.Series(le.fit_transform(y.astype(str)))
    else:
        is_classification = True
        le = LabelEncoder()
        y = pd.Series(le.fit_transform(y.astype(str)))

n_classes = y.nunique()
if n_classes < 2:
    # Trivial baseline: predict the single class
    accuracy = 1.0
    print(f"ACCURACY={accuracy:.6f}")
    import sys
    sys.exit(0)

# --- Train/test split ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

assert len(X_train) > 0 and len(X_test) > 0, "Train/test split produced empty sets"

# --- Lightweight pipeline: StandardScaler + LogisticRegression ---
pipeline = Pipeline([
    ('scaler',