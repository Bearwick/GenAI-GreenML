# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np

def load_data(file_path):
    try:
        df = pd.read_csv(file_path)
        if df.shape[1] < 5:
            raise ValueError
    except:
        df = pd.read_csv(file_path, sep=';', decimal=',')
    return df

def run_pipeline():
    df = load_data('iris.csv')
    
    mapping = {'setosa': 0, 'versicolor': 1, 'virginica': 2}
    y = df.iloc[:, -1].map(mapping).values.astype(int)
    
    X_petal = df.iloc[:, [2, 3]].values.astype(float)
    
    centroids = np.array([X_petal[y == i].mean(axis=0) for i in range(3)])
    
    sample = np.array([[3.1, 1.2]])
    
    diff_sample = sample - centroids
    dist_sample = np.sqrt(np.sum(diff_sample**2, axis=1))
    prediction = np.argmin(dist_sample)
    
    diff_all = X_petal[:, np.newaxis, :] - centroids
    dist_sq_all = np.sum(diff_all**2, axis=2)
    y_pred = np.argmin(dist_sq_all, axis=1)
    
    accuracy = np.mean(y_pred == y)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    np.random.seed(42)
    run_pipeline()

# Optimization Summary
# 1. Removed all visualization logic (matplotlib) to eliminate heavy rendering and I/O overhead.
# 2. Replaced numpy.loadtxt (object mode) with pandas.read_csv for more efficient C-based parsing.
# 3. Optimized label encoding by using a dictionary map instead of multiple boolean mask assignments.
# 4. Vectorized centroid calculation using list comprehension and numpy boolean indexing.
# 5. Replaced scipy.spatial.distance.cdist with numpy broadcasting to reduce external library call overhead and compute distances in a single vectorized step.
# 6. Minimized memory footprint by selecting only necessary features (petal dimensions) for the core classification task.
# 7. Eliminated redundant data type conversions and intermediate print statements.
# 8. Removed all file system side effects (saving plots) to reduce energy consumption.