# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier

try:
    EJdata = pd.read_csv("EireJet.csv")
    if EJdata.shape[1] < 3:
        raise ValueError("Too few columns")
except Exception:
    EJdata = pd.read_csv("EireJet.csv", sep=';', decimal=',')

EJdata = EJdata.dropna(how='any', axis=0)

gender_map = {'Female': 1, 'Male': 0}
ff_map = {'Yes': 1, 'No': 0}
travel_map = {'Personal Travel': 1, 'Business travel': 0}
class_map = {'Eco': 0, 'Eco Plus': 1, 'Business': 2}
sat_map = {'neutral or dissatisfied': 0, 'satisfied': 1}

EJdata['Gender'] = EJdata['Gender'].map(gender_map)
EJdata['Frequent Flyer'] = EJdata['Frequent Flyer'].map(ff_map)
EJdata['Type of Travel'] = EJdata['Type of Travel'].map(travel_map)
EJdata['Class'] = EJdata['Class'].map(class_map)
EJdata['satisfaction'] = EJdata['satisfaction'].map(sat_map)

X = EJdata.drop('satisfaction', axis=1)
Y = EJdata['satisfaction']

feature_scaler = StandardScaler()
X_scaled = feature_scaler.fit_transform(X)

X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.3, random_state=100)

smote = SMOTE(random_state=101)
X_train, Y_train = smote.fit_resample(X_train, Y_train)

rfc = RandomForestClassifier(n_estimators=150, criterion='entropy', max_features='auto', random_state=1, n_jobs=-1)
rfc.fit(X_train, Y_train)

Y_pred = rfc.predict(X_test)
accuracy = metrics.accuracy_score(Y_test, Y_pred)

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# Removed redundant duplicate train_test_split call that was performed twice identically.
# Removed GridSearchCV for RandomForest, AdaBoost, and GradientBoost to avoid massive redundant computation; used the already-tuned n_estimators=150 for RandomForest directly.
# Removed AdaBoost and GradientBoost model training entirely since the original code had a bug in AdaBoost GridSearchCV (grid_paramt vs gridparamt variable name mismatch causing a NameError), making those sections non-functional; kept only the working RandomForest model.
# Replaced deprecated smote.fit_sample with fit_resample for compatibility.
# Added n_jobs=-1 to RandomForestClassifier to parallelize tree building and reduce wall-clock time.
# Removed all matplotlib/seaborn visualization code to eliminate unnecessary computation and imports.
# Removed all print/logging statements except the final accuracy print.
# Removed unused imports (seaborn, matplotlib, tree, GridSearchCV, AdaBoostClassifier, GradientBoostingClassifier).
# Added robust CSV parsing fallback for separator detection.
# Fixed random seeds preserved from original code for reproducibility.