# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
import warnings
warnings.filterwarnings("ignore")

# Robust CSV loading
df = None
try:
    df = pd.read_csv("EireJet.csv")
    if df.shape[1] < 3:
        df = pd.read_csv("EireJet.csv", sep=';', decimal=',')
except Exception:
    try:
        df = pd.read_csv("EireJet.csv", sep=';', decimal=',')
    except Exception:
        pass

if df is None or df.empty:
    print("ACCURACY=0.000000")
    raise SystemExit

# Normalize column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# Drop rows with any NaN
df = df.dropna(how='any', axis=0)

# Identify target
target_col = None
expected_target = 'satisfaction'
for c in df.columns:
    if c.strip().lower() == expected_target.lower():
        target_col = c
        break

if target_col is None:
    # Fallback: pick last column if categorical, else last numeric non-constant
    for c in reversed(list(df.columns)):
        if df[c].nunique() >= 2:
            target_col = c
            break
    if target_col is None:
        print("ACCURACY=0.000000")
        raise SystemExit

# Encode target if needed
y_raw = df[target_col].copy()
if y_raw.dtype == object or y_raw.dtype.name == 'category':
    le_target = LabelEncoder()
    y = pd.Series(le_target.fit_transform(y_raw), index=y_raw.index)
else:
    y = y_raw.copy()
    # Check if this is classification (few unique values) or regression
    if y.nunique() > 50:
        # Treat as regression fallback - but try classification first
        pass

assert y.nunique() >= 2, "Target has fewer than 2 classes"

feature_cols = [c for c in df.columns if c != target_col]
X = df[list(feature_cols)].copy()

# Identify numeric and categorical columns
numeric_cols = []
categorical_cols = []

for c in feature_cols:
    col_converted = pd.to_numeric(X[c], errors='coerce')
    non_null_ratio = col_converted.notna().sum() / len(X)
    if non_null_ratio > 0.5:
        numeric_cols.append(c)
        X[c] = col_converted
    else:
        categorical_cols.append(c)

# Build preprocessing pipeline
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, max_categories=20))
])

transformers = []
if numeric_cols:
    transformers.append(('num', numeric_transformer, numeric_cols))
if categorical_cols:
    transformers.append(('cat', categorical_transformer, categorical_cols))

if not transformers:
    print("ACCURACY=0.000000")
    raise SystemExit

preprocessor = ColumnTransformer(transformers=transformers)

# Handle inf values in numeric columns
for c in numeric