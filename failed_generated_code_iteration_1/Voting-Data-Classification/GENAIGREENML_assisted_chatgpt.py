# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import sys
import random
import numpy as np
import pandas as pd

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.svm import LinearSVC


SEED = 0


def _set_reproducible_seed(seed: int = SEED) -> None:
    random.seed(seed)
    np.random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if not isinstance(df, pd.DataFrame) or df.shape[1] < 2:
        df = pd.read_csv(path, sep=";", decimal=",")
        return df
    if df.shape[1] == 1:
        col = df.columns[0]
        sample = df[col].astype(str).head(10).tolist()
        if any((";" in s) for s in sample):
            df2 = pd.read_csv(path, sep=";", decimal=",")
            if df2.shape[1] >= 2:
                return df2
    return df


def _resolve_columns(df: pd.DataFrame, dataset_headers: str) -> tuple[str, str]:
    expected = [h.strip() for h in dataset_headers.split(",") if h.strip()]
    col_map = {c.strip().lower(): c for c in df.columns}

    if len(expected) >= 2:
        text_key = expected[0].strip().lower()
        label_key = expected[1].strip().lower()
        if text_key in col_map and label_key in col_map:
            return col_map[text_key], col_map[label_key]

    if df.shape[1] >= 2:
        return df.columns[0], df.columns[1]

    raise ValueError("Dataset must contain at least two columns (text, label).")


def _prepare_xy(df: pd.DataFrame, text_col: str, label_col: str):
    x = df[text_col].fillna("").astype(str)
    y = df[label_col]
    return x, y


def _compute_accuracy(y_true, y_pred) -> float:
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    if y_true.size == 0:
        return 0.0
    return float(np.mean(y_true == y_pred))


def run_train(csv_path: str, dataset_headers: str = "text,label") -> float:
    df = _read_csv_robust(csv_path)
    text_col, label_col = _resolve_columns(df, dataset_headers)
    x, y = _prepare_xy(df, text_col, label_col)

    x_train, x_test, y_train, y_test = train_test_split(
        x, y, train_size=0.75, test_size=0.25, random_state=SEED
    )

    tfidf = TfidfVectorizer()
    x_train_vec = tfidf.fit_transform(x_train)
    x_test_vec = tfidf.transform(x_test)

    model = LinearSVC(random_state=SEED)
    model.fit(x_train_vec, y_train)
    y_pred = model.predict(x_test_vec)

    return _compute_accuracy(y_test, y_pred)


def run_cross_val(csv_path: str, dataset_headers: str = "text,label") -> float:
    df = _read_csv_robust(csv_path)
    text_col, label_col = _resolve_columns(df, dataset_headers)
    x, y = _prepare_xy(df, text_col, label_col)

    tfidf = TfidfVectorizer()
    x_vec = tfidf.fit_transform(x)

    model = LinearSVC(random_state=SEED)
    scores = cross_val_score(model, x_vec, y, cv=10)
    return float(np.mean(scores))


def run_predict(sentence: str, csv_path: str, dataset_headers: str = "text,label") -> float:
    df = _read_csv_robust(csv_path)
    text_col, label_col = _resolve_columns(df, dataset_headers)
    x, y = _prepare_xy(df, text_col, label_col)

    tfidf = TfidfVectorizer()
    x_vec = tfidf.fit_transform(x)

    model = LinearSVC(random_state=SEED)
    model.fit(x_vec, y)

    _ = model.predict(tfidf.transform([sentence]))
    y_pred = model.predict(x_vec)
    return _compute_accuracy(y, y_pred)


def _parse_args(argv: list[str]):
    mode = None
    value = None
    path = None

    if len(argv) >= 3 and argv[1] == "--mode":
        mode = argv[2]

    if len(argv) >= 5:
        value = argv[4]

    if len(argv) >= 4:
        path = argv[3]
    if path is None:
        path = value

    return mode, value, path


def main() -> None:
    _set_reproducible_seed(SEED)
    mode, value, path = _parse_args(sys.argv)

    if mode == "train":
        if path is None:
            raise SystemExit(2)
        accuracy = run_train(path)
    elif mode == "cross_val":
        if path is None:
            raise SystemExit(2)
        accuracy = run_cross_val(path)
    elif mode == "predict":
        if value is None or path is None:
            raise SystemExit(2)
        accuracy = run_predict(value, path)
    else:
        raise SystemExit(2)

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# Removed unused heavy imports (matplotlib, graphviz, IPython, pickle, csv, extra models) to cut startup time and memory.
# Eliminated artifact saving/loading (joblib .pkl) to avoid I/O energy and side effects while keeping task behavior (train/eval/predict).
# Ensured deterministic behavior by setting fixed seeds and using random_state where supported.
# Implemented robust CSV parsing with a low-cost fallback to handle delimiter/decimal variations without manual edits.
# Avoided redundant predictions and unnecessary intermediate structures; compute accuracy directly via vectorized NumPy comparison.
# Kept sparse TF-IDF matrices throughout to minimize memory footprint and avoid dense conversions/data movement.
# Modularized code paths (train/cross_val/predict) for clarity and to avoid executing unused example code.