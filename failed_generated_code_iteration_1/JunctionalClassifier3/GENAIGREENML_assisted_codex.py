# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
DATASET_HEADERS = None

features = []
labels = []
pFeatures = []


def read_csv_with_fallback(path):
    try:
        df = pd.read_csv(path)
    except Exception:
        return pd.read_csv(path, sep=";", decimal=",")
    if df.shape[1] == 1:
        sample = df.iloc[0, 0]
        if isinstance(sample, str) and ";" in sample:
            df_fb = pd.read_csv(path, sep=";", decimal=",")
            if df_fb.shape[1] > 1:
                return df_fb
    return df


def clean_dataframe(df):
    if df.columns.dtype == object:
        df = df.loc[:, ~df.columns.str.match(r"^Unnamed")]
    df = df.dropna(axis=1, how="all")
    if DATASET_HEADERS:
        cols = [c for c in DATASET_HEADERS if c in df.columns]
        if cols:
            df = df[cols]
    df = df.dropna(how="all")
    return df


def load_dataset(path):
    df = read_csv_with_fallback(path)
    df = clean_dataframe(df)
    df = df.apply(pd.to_numeric, errors="raise")
    if df.shape[1] < 2:
        raise ValueError("Dataset must contain at least one feature column and one label column.")
    y_raw = df.iloc[:, -1].to_numpy()
    X = df.iloc[:, :-1].to_numpy()
    y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0))
    return X, y


def makeCSV(inpt):
    global features, labels
    X, y = load_dataset(inpt)
    features = X.tolist()
    labels = y.tolist()
    return features, labels


def takeInput(path="input.csv"):
    global pFeatures
    df = read_csv_with_fallback(path)
    df = clean_dataframe(df)
    df = df.apply(pd.to_numeric, errors="raise")
    pFeatures = df.to_numpy().tolist()
    return pFeatures


def wipeVariables():
    global features, labels, pFeatures
    features = []
    labels = []
    pFeatures = []


def train_and_test_model(data_path="14k.csv"):
    X, y = load_dataset(data_path)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=RANDOM_SEED, shuffle=True
    )
    model = svm.SVC(kernel="linear", random_state=RANDOM_SEED)
    model.fit(X_train, y_train)
    pred = model.predict(X_test)
    return accuracy_score(y_test, pred)


def main():
    accuracy = train_and_test_model()
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Replaced row-wise CSV parsing with vectorized pandas loading and a delimiter/decimal fallback to reduce loop overhead.
# - Centralized dataset cleaning and numeric conversion to avoid redundant processing and data movement.
# - Used numpy vectorized label transformation instead of per-element logic for lower computational cost.
# - Limited global state updates to only required functions, reducing memory footprint during training.
# - Fixed random seed and deterministic split to ensure reproducible results without extra computation.