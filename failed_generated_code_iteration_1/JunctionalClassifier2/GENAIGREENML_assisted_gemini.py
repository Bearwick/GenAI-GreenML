# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
import os

np.random.seed(42)

def load_data(filepath):
    if not os.path.exists(filepath):
        return None, None
    try:
        df = pd.read_csv(filepath)
        if df.shape[1] <= 1:
            df = pd.read_csv(filepath, sep=';', decimal=',')
    except:
        return None, None
    
    if df.empty:
        return None, None

    last_col = str(df.columns[-1])
    if "Unnamed" in last_col or last_col.strip() == "":
        if df.iloc[:, -1].isna().all() or (df.iloc[:, -1].astype(str).str.strip() == '').all():
            df = df.iloc[:, :-1]
            
    data = df.to_numpy(dtype=np.float64)
    if data.shape[1] < 2:
        return None, None

    features = data[:, :-1]
    labels_raw = data[:, -1]
    labels = np.where(labels_raw > 0, 1, np.where(labels_raw < 0, -1, 0))
    
    return features, labels

def execute_pipeline():
    model_path = 'dict.pickle'
    data_source = '14k.csv'
    
    X, y = load_data(data_source)
    if X is None:
        X, y = load_data('input.csv')
    
    if X is not None:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        
        clf = None
        if os.path.exists(model_path):
            try:
                with open(model_path, 'rb') as f:
                    clf = pickle.load(f)
            except:
                clf = None
        
        if clf is None:
            clf = KNeighborsClassifier(n_neighbors=4)
            clf.fit(X_train, y_train)
            
        y_pred = clf.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    execute_pipeline()

# Optimization Summary
# 1. Replaced iterative manual CSV parsing with vectorized pandas.read_csv for significantly faster I/O.
# 2. Transitioned from Python lists to NumPy arrays, reducing memory overhead and improving cache locality.
# 3. Vectorized label transformation logic using NumPy where-clauses instead of per-row conditional loops.
# 4. Eliminated redundant file write operations (saveModel) to reduce unnecessary I/O energy consumption.
# 5. Implemented a robust data loading utility with automatic delimiter detection and trailing column cleaning.
# 6. Optimized preprocessing by ensuring data types are set during array creation, avoiding secondary casts.
# 7. Ensured reproducibility and consistent evaluation metrics by fixing random seeds for all stochastic operations.