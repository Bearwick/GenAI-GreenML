# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

SEED = 42
np.random.seed(SEED)

DATASET_PATH = "14k.csv"
TEST_SIZE = 0.3
N_NEIGHBORS = 4
DATASET_HEADERS = None


def read_csv_flexible(path):
    try:
        df = pd.read_csv(path)
        if df.shape[1] == 1:
            df_alt = pd.read_csv(path, sep=";", decimal=",")
            if df_alt.shape[1] > 1:
                df = df_alt
    except Exception:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def apply_schema(df):
    headers = globals().get("DATASET_HEADERS")
    if headers:
        cols = [c for c in headers if c in df.columns]
        if cols:
            df = df[cols]
    return df


def prepare_data(df):
    df = apply_schema(df)
    df = df.dropna(axis=1, how="all")
    df = df.apply(pd.to_numeric, errors="raise")
    X = df.iloc[:, :-1].to_numpy(dtype=float, copy=False)
    y_raw = df.iloc[:, -1].to_numpy(dtype=float, copy=False)
    y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0))
    return X, y


def train_evaluate(path):
    df = read_csv_flexible(path)
    X, y = prepare_data(df)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TEST_SIZE, random_state=SEED, shuffle=True
    )
    model = KNeighborsClassifier(n_neighbors=N_NEIGHBORS)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)


def main():
    accuracy = train_evaluate(DATASET_PATH)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# Replaced row-wise CSV parsing with vectorized pandas loading and numeric conversion to reduce Python-level loops.
# Added a lightweight, deterministic data split with fixed seed for reproducibility.
# Used numpy vectorization for label mapping to minimize redundant computation.
# Removed global mutable state and model persistence to reduce memory and I/O overhead.
# Dropped unnecessary intermediate structures and copies where possible to lower memory footprint.