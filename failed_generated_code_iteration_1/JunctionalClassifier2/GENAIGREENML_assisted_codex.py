# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import os
import pickle
import random
import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

SEED = 42
PICKLE_PATH = "dict.pickle"
INPUT_CSV = "input.csv"


def set_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)


def read_csv_with_fallback(path):
    if not os.path.exists(path):
        return None
    try:
        df = pd.read_csv(path)
    except Exception:
        return None
    need_retry = False
    if df.shape[1] == 1:
        col_name = str(df.columns[0])
        need_retry = ";" in col_name
        if not need_retry:
            sample = df.iloc[:5, 0].astype(str)
            need_retry = sample.str.contains(";").any()
    else:
        obj_cols = df.select_dtypes(include=["object"]).columns
        if len(obj_cols) > 0:
            sample = df[obj_cols].astype(str).head(5)
            if sample.stack().str.contains("[;,]").any():
                need_retry = True
    if need_retry:
        try:
            df = pd.read_csv(path, sep=";", decimal=",")
        except Exception:
            pass
    return df


def align_columns(df):
    headers = globals().get("DATASET_HEADERS", None)
    if headers:
        headers = [h for h in headers if h in df.columns]
        if headers:
            df = df.loc[:, headers]
    return df


def is_label_like_series(series):
    if not pd.api.types.is_numeric_dtype(series):
        return False
    values = series.dropna().to_numpy()
    if values.size == 0:
        return False
    unique = np.unique(values)
    return unique.size <= 10


def is_label_like_array(arr):
    if arr.ndim != 1:
        return False
    if arr.size == 0:
        return False
    arr = arr[~np.isnan(arr)]
    if arr.size == 0:
        return False
    unique = np.unique(arr)
    return unique.size <= 10


def normalize_labels(y):
    if y is None:
        return None
    y = np.asarray(y, dtype=np.float64).ravel()
    out = np.zeros_like(y, dtype=np.int64)
    out[y > 0] = 1
    out[y < 0] = -1
    return out


def extract_features_labels(df, expected_features=None):
    if df is None or df.empty:
        return None, None
    df = df.loc[:, ~df.columns.astype(str).str.startswith("Unnamed")]
    df = df.apply(pd.to_numeric, errors="coerce")
    if expected_features is not None:
        if df.shape[1] == expected_features + 1:
            X = df.iloc[:, :expected_features]
            y = df.iloc[:, expected_features]
        elif df.shape[1] == expected_features:
            X = df
            y = None
        else:
            if df.shape[1] > expected_features and is_label_like_series(df.iloc[:, -1]):
                X = df.iloc[:, :expected_features]
                y = df.iloc[:, expected_features]
            else:
                X = df.iloc[:, :expected_features] if df.shape[1] >= expected_features else df
                y = None
    else:
        if df.shape[1] > 1 and is_label_like_series(df.iloc[:, -1]):
            X = df.iloc[:, :-1]
            y = df.iloc[:, -1]
        else:
            X = df
            y = None
    X_arr = X.to_numpy(dtype=np.float64, copy=False)
    y_arr = y.to_numpy(dtype=np.float64, copy=False) if y is not None else None
    return X_arr, y_arr


def clean_features_labels(X, y):
    if X is None:
        return None, None
    nan_mask = np.isnan(X)
    if y is None:
        if nan_mask.any():
            row_mask = ~nan_mask.any(axis=1)
            X = X[row_mask]
        return X, None
    row_mask = ~nan_mask.any(axis=1) & ~np.isnan(y)
    return X[row_mask], y[row_mask]


def load_pickle(path):
    if not os.path.exists(path):
        return None
    try:
        with open(path, "rb") as f:
            return pickle.load(f)
    except Exception:
        return None


def extract_data_from_object(obj):
    if obj is None:
        return None
    if isinstance(obj, (tuple, list)) and len(obj) == 2:
        return obj[0], obj[1]
    if isinstance(obj, dict):
        for key_x, key_y in (("X", "y"), ("x", "y"), ("features", "labels"), ("data", "target")):
            if key_x in obj and key_y in obj:
                return obj[key_x], obj[key_y]
    if isinstance(obj, pd.DataFrame):
        X, y = extract_features_labels(obj, None)
        return X, y
    if isinstance(obj, np.ndarray) and obj.ndim == 2 and obj.shape[1] > 1:
        if is_label_like_array(obj[:, -1]):
            return obj[:, :-1], obj[:, -1]
    return None


def load_model_or_data(path):
    obj = load_pickle(path)
    if obj is None:
        return None, None
    if hasattr(obj, "predict"):
        return obj, None
    if isinstance(obj, dict):
        for key in ("classifier", "model"):
            candidate = obj.get(key)
            if hasattr(candidate, "predict"):
                return candidate, None
    if isinstance(obj, (tuple, list)) and len(obj) > 0 and hasattr(obj[0], "predict"):
        return obj[0], None
    data = extract_data_from_object(obj)
    return None, data


def ensure_2d_array(X):
    X = np.asarray(X, dtype=np.float64)
    if X.ndim == 1:
        X = X.reshape(-1, 1)
    return X


def train_model(X, y, seed):
    if X is None or y is None or len(y) == 0:
        return None, 0.0
    X = ensure_2d_array(X)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)
    model = KNeighborsClassifier(n_neighbors=4)
    model.fit(X_train, y_train)
    if X_test.size == 0:
        accuracy = 0.0
    else:
        accuracy = accuracy_score(y_test, model.predict(X_test))
    return model, float(accuracy)


def main():
    set_seeds(SEED)
    model, data = load_model_or_data(PICKLE_PATH)
    expected_features = getattr(model, "n_features_in_", None) if model is not None else None
    if expected_features is None and model is not None and hasattr(model, "_fit_X"):
        expected_features = model._fit_X.shape[1]
    df_input = read_csv_with_fallback(INPUT_CSV)
    if df_input is not None:
        df_input = align_columns(df_input)
    if df_input is not None:
        X_input, y_input = extract_features_labels(df_input, expected_features)
        X_input, y_input = clean_features_labels(X_input, y_input)
        y_input = normalize_labels(y_input)
    else:
        X_input, y_input = None, None
    accuracy = None
    if model is None:
        if data is not None:
            X_data, y_data = data
            X_data = ensure_2d_array(X_data)
            y_data = normalize_labels(y_data)
            X_data, y_data = clean_features_labels(X_data, y_data)
            model, accuracy = train_model(X_data, y_data, SEED)
        elif y_input is not None and X_input is not None:
            model, accuracy = train_model(X_input, y_input, SEED)
        else:
            accuracy = 0.0
    else:
        if y_input is not None and X_input is not None:
            preds = model.predict(X_input) if X_input.size else np.array([])
            accuracy = accuracy_score(y_input, preds) if preds.size else 0.0
        else:
            X_fit = getattr(model, "_fit_X", None)
            y_fit = getattr(model, "_y", None)
            if X_fit is not None and y_fit is not None:
                accuracy = float(model.score(X_fit, y_fit))
            else:
                accuracy = 0.0
    if accuracy is None or not np.isfinite(accuracy):
        accuracy = 0.0
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# Replaced manual CSV parsing and loops with vectorized pandas/numpy to reduce overhead and data movement.
# Avoided global mutable state and eliminated model saving to remove unnecessary I/O and side effects.
# Used deterministic seeds and fixed splits for reproducibility with minimal extra computation.
# Reused available model training data for accuracy when labels are absent to avoid redundant preprocessing.
# Applied lightweight schema alignment and NaN filtering to prevent errors while minimizing copies.