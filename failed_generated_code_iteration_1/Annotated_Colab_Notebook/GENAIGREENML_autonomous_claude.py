# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

# Step 1: Load ARFF file with robust fallback
def load_arff_as_dataframe(path):
    try:
        from scipy.io import arff
        data, meta = arff.loadarff(path)
        df = pd.DataFrame(data)
        # Decode bytes columns if needed
        for col in df.columns:
            if df[col].dtype == object:
                try:
                    df[col] = df[col].str.decode('utf-8')
                except (AttributeError, UnicodeDecodeError):
                    pass
        return df
    except Exception:
        pass

    # Fallback: manual ARFF parsing
    try:
        columns = []
        data_started = False
        rows = []
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped = line.strip()
                if stripped.lower().startswith('@attribute'):
                    parts = stripped.split()
                    col_name = parts[1].strip("'\"")
                    columns.append(col_name)
                elif stripped.lower().startswith('@data'):
                    data_started = True
                elif data_started and stripped and not stripped.startswith('%'):
                    # Handle quoted values
                    vals = []
                    in_quote = False
                    current = ''
                    for ch in stripped:
                        if ch in ("'", '"') and not in_quote:
                            in_quote = True
                        elif ch in ("'", '"') and in_quote:
                            in_quote = False
                        elif ch == ',' and not in_quote:
                            vals.append(current.strip())
                            current = ''
                        else:
                            current += ch
                    vals.append(current.strip())
                    rows.append(vals)
        df = pd.DataFrame(rows, columns=columns)
        df.replace('?', np.nan, inplace=True)
        return df
    except Exception:
        pass

    # Final fallback: try CSV
    try:
        df = pd.read_csv(path)
        if df.shape[1] <= 1:
            df = pd.read_csv(path, sep=';', decimal=',')
        return df
    except Exception:
        return pd.DataFrame()

df = load_arff_as_dataframe('dataset_adult.arff')

# Step 2: Normalize column names
df.columns = [str(c).strip().replace('  ', ' ') for c in df.columns]
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

assert df.shape[0] > 0, "Dataset is empty after loading"

# Step 3: Identify target column
# For adult dataset, target is typically 'class' or 'income' or last column
target_col = None
candidate_targets = ['class', 'income', 'target', 'label']
for ct in candidate_targets:
    matches = [c for c in df.columns if c.lower() == ct.lower()]
    if matches:
        target_col = matches[0]
        break

if target_col is None:
    # Use last column as target
    target_col = df.columns[-1]

# Step 4: Clean target
df[target_col] = df[target_col].astype(str).str.strip().str.strip("'\".")

# Check if classification is viable
unique_targets = df[target_col].dropna().unique()
is_classification = len(unique_targets) >= 2 and len(unique_targets) <= 50

if not is_classification:
    # Fallback: try to find a better target
    for col in df.columns: