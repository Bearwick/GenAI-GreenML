# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


SEED = 3
DATASET_PATH = "mail_data.csv"
DATASET_HEADERS = ("Category", "Message")


def set_reproducible_seed(seed: int) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def read_mail_data(path: str, expected_headers=DATASET_HEADERS) -> pd.DataFrame:
    df = pd.read_csv(path)
    if not all(h in df.columns for h in expected_headers) or df.shape[1] < 2:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def prepare_dataset(df: pd.DataFrame) -> tuple[pd.Series, pd.Series]:
    df = df.copy()

    missing_cols = [c for c in DATASET_HEADERS if c not in df.columns]
    if missing_cols:
        raise ValueError(f"Missing required columns: {missing_cols}. Found columns: {list(df.columns)}")

    df[DATASET_HEADERS] = df[list(DATASET_HEADERS)].fillna("")

    labels = df["Category"].map({"spam": 0, "ham": 1}).astype("int64")
    texts = df["Message"]

    return texts, labels


def train_and_evaluate(texts: pd.Series, labels: pd.Series, seed: int) -> float:
    x_train, x_test, y_train, y_test = train_test_split(
        texts, labels, test_size=0.2, random_state=seed
    )

    vectorizer = TfidfVectorizer(min_df=1, stop_words="english", lowercase=True)

    x_train_vec = vectorizer.fit_transform(x_train)
    x_test_vec = vectorizer.transform(x_test)

    y_train = y_train.astype(np.int64, copy=False)
    y_test = y_test.astype(np.int64, copy=False)

    model = LogisticRegression(random_state=seed, solver="liblinear")
    model.fit(x_train_vec, y_train)

    y_pred = model.predict(x_test_vec)
    accuracy = accuracy_score(y_test, y_pred)

    return float(accuracy)


def main() -> None:
    set_reproducible_seed(SEED)
    df = read_mail_data(DATASET_PATH)
    texts, labels = prepare_dataset(df)
    accuracy = train_and_evaluate(texts, labels, SEED)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed all exploratory prints, head/shape calls, and the predictive demo block to eliminate redundant computation and I/O while keeping the same training/evaluation task.
# - Added robust CSV parsing: read with defaults first, then retry with sep=';' and decimal=',' if headers/schema do not match, reducing failed parses and rework.
# - Filled NaNs only in required columns (Category, Message) instead of applying a dataframe-wide where(), reducing unnecessary data movement.
# - Avoided duplicate imports and kept a single vectorizer/model creation path to reduce overhead.
# - Ensured reproducibility with fixed seeds (PYTHONHASHSEED, random, numpy) and LogisticRegression(random_state=...), stabilizing results across runs.
# - Used solver='liblinear' for this small sparse binary classification to reduce runtime and energy compared to heavier default solvers, without changing the model type or intent.
# - Used astype(..., copy=False) for labels to reduce memory copies.