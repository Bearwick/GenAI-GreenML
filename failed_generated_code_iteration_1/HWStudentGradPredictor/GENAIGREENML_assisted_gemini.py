# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

def load_data(path):
    try:
        data = pd.read_csv(path, sep=';', decimal=',')
        if 'Graduated (target)' not in data.columns:
            data = pd.read_csv(path)
        return data
    except Exception:
        return pd.read_csv(path, sep=';')

def run_pipeline():
    dataset_path = 'data/students_graduate_predict.csv'
    df = load_data(dataset_path)
    
    target_col = 'Graduated (target)'
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    x_train, x_test, y_train, y_test = train_test_split(
        X, y, test_size=0.15, random_state=1
    )
    
    model = MLPClassifier(
        hidden_layer_sizes=[5, 7], 
        max_iter=800, 
        random_state=1
    )
    model.fit(x_train, y_train)
    
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_pipeline()

# Optimization Summary
# - Removed visualization libraries (matplotlib, seaborn) to reduce memory footprint and import overhead.
# - Eliminated redundant computations such as intermediate predictions on the training set and unused metric calculations.
# - Removed exploratory data analysis steps (histograms, head/tail displays) to minimize runtime.
# - Implemented robust CSV loading with efficient fallback logic to handle potential delimiter variations.
# - Avoided creation of unnecessary intermediate data structures (DataFrames for comparison).
# - Set a fixed random_state for the MLPClassifier to ensure deterministic results and reproducibility.
# - Encapsulated logic in a modular function to improve execution efficiency and scope management.