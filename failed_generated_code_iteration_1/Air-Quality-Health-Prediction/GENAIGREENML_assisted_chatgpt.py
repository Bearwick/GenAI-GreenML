# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
from typing import Tuple, Optional

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split


DATASET_HEADERS = [
    "Date",
    "Time",
    "CO(GT)",
    "PT08.S1(CO)",
    "NMHC(GT)",
    "C6H6(GT)",
    "PT08.S2(NMHC)",
    "NOx(GT)",
    "PT08.S3(NOx)",
    "NO2(GT)",
    "PT08.S4(NO2)",
    "PT08.S5(O3)",
    "T",
    "RH",
    "AH",
    "",
    "",
]


def _set_reproducibility(seed: int = 42) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 2:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _resolve_columns(df_columns: pd.Index, desired: list) -> list:
    cols = set(map(str, df_columns))
    return [c for c in desired if c in cols]


def _coerce_numeric_inplace(df: pd.DataFrame, cols: list) -> None:
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")


def load_and_preprocess(path: str, features: list) -> Tuple[pd.DataFrame, list]:
    df = _read_csv_robust(path)

    features_present = _resolve_columns(df.columns, features)

    target_reg = "C6H6(GT)" if "C6H6(GT)" in df.columns else None
    target_clf = "Risk_Label" if "Risk_Label" in df.columns else None

    numeric_cols = list(dict.fromkeys(features_present + ([target_reg] if target_reg else [])))
    _coerce_numeric_inplace(df, numeric_cols)

    keep_cols = features_present + ([target_reg] if target_reg else []) + ([target_clf] if target_clf else [])
    keep_cols = [c for c in keep_cols if c in df.columns]

    df = df.loc[:, keep_cols].dropna()

    if target_clf is None:
        if "NO2(GT)" in df.columns:
            med = float(df["NO2(GT)"].median())
            df["Risk_Label"] = (df["NO2(GT)"] > med).astype(np.int8)
        else:
            df["Risk_Label"] = 0

    return df, features_present


def train_models(data: pd.DataFrame, features: list, seed: int = 42) -> Tuple[RandomForestRegressor, RandomForestClassifier, np.ndarray, np.ndarray]:
    X = data[features].to_numpy(dtype=np.float32, copy=False)

    y_reg_col = "C6H6(GT)" if "C6H6(GT)" in data.columns else None
    y_reg = data[y_reg_col].to_numpy(dtype=np.float32, copy=False) if y_reg_col else np.zeros((X.shape[0],), dtype=np.float32)

    y_clf = data["Risk_Label"].to_numpy(copy=False)
    if y_clf.dtype.kind not in ("i", "u", "b"):
        y_clf = pd.to_numeric(y_clf, errors="coerce").fillna(0).astype(np.int32).to_numpy(copy=False)

    X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test = train_test_split(
        X,
        y_reg,
        y_clf,
        test_size=0.2,
        random_state=seed,
        shuffle=True,
        stratify=y_clf if len(np.unique(y_clf)) > 1 else None,
    )

    reg = RandomForestRegressor(
        n_estimators=100,
        random_state=seed,
        n_jobs=1,
    )
    clf = RandomForestClassifier(
        n_estimators=100,
        random_state=seed,
        n_jobs=1,
    )

    reg.fit(X_train, y_reg_train)
    clf.fit(X_train, y_clf_train)

    y_clf_pred = clf.predict(X_test)
    return reg, clf, y_clf_test, y_clf_pred


def main() -> None:
    _set_reproducibility(42)

    features = ["CO(GT)", "NOx(GT)", "NO2(GT)", "C6H6(GT)", "T", "RH"]
    data, features_present = load_and_preprocess("data/AirQualityUCI.csv", features)
    _, _, y_true, y_pred = train_models(data, features_present, seed=42)

    accuracy = float(accuracy_score(y_true, y_pred))
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed all plotting/visualization and verbose reporting to avoid heavy rendering overhead and unnecessary imports.
# - Implemented robust CSV parsing with a lightweight fallback (default read, then retry with sep=';' and decimal=',') to prevent mis-parses without repeated manual edits.
# - Reduced data movement by selecting only required columns, converting to NumPy arrays once, and using copy=False where safe.
# - Coerced only the necessary columns to numeric (features + target), avoiding full-frame type conversions.
# - Dropped redundant computations by skipping unused metrics/structures from the original flow and computing only final accuracy as required.
# - Enforced reproducibility with fixed seeds for Python, NumPy, and model/train-test split random_state; used single-thread (n_jobs=1) for deterministic, lower-overhead execution.