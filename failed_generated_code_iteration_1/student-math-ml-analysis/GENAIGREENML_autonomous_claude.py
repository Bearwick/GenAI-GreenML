# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline

# Robust CSV loading
try:
    df = pd.read_csv("./data/student-mat.csv")
    if df.shape[1] < 3:
        df = pd.read_csv("./data/student-mat.csv", sep=';', decimal=',')
except Exception:
    df = pd.read_csv("./data/student-mat.csv", sep=';', decimal=',')

# Strip/normalize column names
df.columns = [c.strip().replace('  ', ' ') for c in df.columns]
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# Check expected columns
expected_cols = ['school','sex','age','address','famsize','Pstatus','Medu','Fedu',
                 'Mjob','Fjob','reason','guardian','traveltime','studytime','failures',
                 'schoolsup','famsup','paid','activities','nursery','higher','internet',
                 'romantic','famrel','freetime','goout','Dalc','Walc','health','absences',
                 'G1','G2','G3']

# Map columns if they exist
col_map = {}
for ec in expected_cols:
    for dc in df.columns:
        if dc.lower().strip() == ec.lower().strip():
            col_map[dc] = ec
            break
df.rename(columns=col_map, inplace=True)

# Determine target: G3 (final grade) -> categorical
target_col = None
if 'G3' in df.columns:
    target_col = 'G3'
else:
    # fallback: last numeric column
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if num_cols:
        target_col = num_cols[-1]

assert target_col is not None, "No suitable target column found"

# Coerce target to numeric
df[target_col] = pd.to_numeric(df[target_col], errors='coerce')
df.dropna(subset=[target_col], inplace=True)

# Create categorical target: good (15-20), fair (10-14), poor (0-9)
def grade_category(score):
    if score >= 15:
        return 'good'
    elif score >= 10:
        return 'fair'
    else:
        return 'poor'

df['final_grade'] = df[target_col].apply(grade_category)
la = LabelEncoder()
df['final_grade_enc'] = la.fit_transform(df['final_grade'])

# Determine features: all columns except target and derived
exclude_cols = {target_col, 'final_grade', 'final_grade_enc'}
feature_cols = [c for c in df.columns if c not in exclude_cols]

# Separate numeric and categorical
numeric_features = []
categorical_features = []
for c in feature_cols:
    df[c] = df[c].astype(str).str.strip()
    converted = pd.to_numeric(df[c], errors='coerce')
    if converted.notna().sum() / len(df) > 0.8:
        df[c] = converted
        numeric_features.append(c)
    else:
        categorical_features.append(c)

# Impute numeric
for c in numeric_features:
    df[c] = df[c].fillna(df[c].median())

# One-hot encode categoricals
if categorical_features:
    df = pd.get_dummies(df, columns=categorical_features, drop_first=True)

# Rebuild feature list after encoding
exclude_cols_final = {target_col, 'final_grade', 'final_grade_enc'}
feature_cols_final = [c for c in df.columns if