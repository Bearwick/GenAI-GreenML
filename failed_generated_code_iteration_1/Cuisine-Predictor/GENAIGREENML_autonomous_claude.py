# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import json
import warnings
warnings.filterwarnings("ignore")

# Step 1: Load dataset robustly
data = None
try:
    data = pd.read_json("train.json")
except Exception:
    try:
        with open("train.json", "r") as f:
            raw = json.load(f)
        data = pd.DataFrame(raw)
    except Exception:
        try:
            data = pd.read_json("train.json", lines=True)
        except Exception:
            pass

assert data is not None and len(data) > 0, "Failed to load dataset"

# Step 2: Normalize column names
data.columns = [str(c).strip() for c in data.columns]
data = data[[c for c in data.columns if not c.startswith("Unnamed")]]

# Step 3: Identify target and feature columns
# Expected schema: id, cuisine (target), ingredients (list of strings)
target_col = None
ingredients_col = None

for c in data.columns:
    cl = c.lower()
    if cl == "cuisine":
        target_col = c
    elif cl == "ingredients":
        ingredients_col = c

# Fallback: if no cuisine column, pick first string column with multiple unique values as target
if target_col is None:
    for c in data.columns:
        if data[c].dtype == object and data[c].nunique() > 1 and data[c].nunique() < len(data) * 0.5:
            target_col = c
            break

# Fallback for ingredients: pick a column that contains lists
if ingredients_col is None:
    for c in data.columns:
        if c == target_col:
            continue
        sample = data[c].dropna().iloc[0] if len(data[c].dropna()) > 0 else None
        if isinstance(sample, list):
            ingredients_col = c
            break

assert target_col is not None, "Could not identify target column"
assert ingredients_col is not None, "Could not identify ingredients column"

# Step 4: Preprocessing
# Convert ingredient lists to space-joined strings for TF-IDF
data = data.dropna(subset=[target_col, ingredients_col]).reset_index(drop=True)

def ingredients_to_text(ing):
    if isinstance(ing, list):
        return " ".join([str(i).lower().strip().replace(" ", "_") for i in ing])
    return str(ing).lower()

data["ingredients_text"] = data[ingredients_col].apply(ingredients_to_text)

# Encode target
le = LabelEncoder()
data["target_encoded"] = le.fit_transform(data[target_col].astype(str))

n_classes = data["target_encoded"].nunique()
assert n_classes >= 2, "Need at least 2 classes for classification"

# Step 5: Train/test split
X_text = data["ingredients_text"]
y = data["target_encoded"]

X_train_text, X_test_text, y_train, y_test = train_test_split(
    X_text, y, test_size=0.2, random_state=42, stratify=y
)

assert len(X_train_text) > 0 and len(X_test_text) > 0, "Empty split"

# Step 6: TF-IDF vectorization (energy-efficient: limit features)
tfidf = TfidfVectorizer(
    max_features=3000,
    sublinear_tf=True,
    ngram_range=(1, 1),
    token_pattern=r"[^\s]+",
    dtype=np.float32
)

X_train = tfidf.fit_transform(X_train_text)
X_test = tfidf.transform(X_test