# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import pickle
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn import metrics

SEED = 42
MODEL_PATH = "dict.pickle"
TRAIN_CSV = "14k.csv"
INPUT_CSV = "input.csv"

DATASET_HEADERS = None


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _split_features_labels(df: pd.DataFrame):
    if df.shape[1] < 2:
        raise ValueError("CSV must contain at least one feature column and one label column.")
    x = df.iloc[:, :-1].to_numpy(dtype=np.float64, copy=False)
    y_raw = df.iloc[:, -1].to_numpy(dtype=np.float64, copy=False)
    y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0)).astype(np.int64, copy=False)
    return x, y


def _load_model(path: str):
    with open(path, "rb") as f:
        return pickle.load(f)


def _predict_from_csv(model, csv_path: str):
    df = _read_csv_robust(csv_path)
    x = df.to_numpy(dtype=np.float64, copy=False)
    scaler = StandardScaler()
    x_scaled = scaler.fit_transform(x)
    return model.predict(x_scaled)


def _train_and_evaluate(train_path: str):
    df = _read_csv_robust(train_path)
    x, y = _split_features_labels(df)
    x_train, x_test, y_train, y_test = train_test_split(
        x, y, test_size=0.3, random_state=SEED, shuffle=True
    )

    scaler = StandardScaler()
    x_train = scaler.fit_transform(x_train)
    x_test = scaler.transform(x_test)

    model = MLPClassifier(hidden_layer_sizes=(30, 30, 30, 30), max_iter=1000, random_state=SEED)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    return metrics.accuracy_score(y_test, y_pred)


def main():
    if os.path.exists(TRAIN_CSV):
        accuracy = _train_and_evaluate(TRAIN_CSV)
    else:
        model = _load_model(MODEL_PATH)
        _ = _predict_from_csv(model, INPUT_CSV)
        accuracy = 0.0

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Replaced manual CSV parsing loops with vectorized pandas/numpy ingestion to cut Python-level overhead and redundant conversions.
# - Implemented robust CSV parsing fallback (default read_csv, then sep=';' and decimal=',') to avoid repeated failed parsing and rework.
# - Eliminated global mutable lists and copy-heavy list conversions by working with numpy arrays end-to-end to reduce memory footprint and data movement.
# - Made preprocessing vectorized: label mapping uses np.where instead of per-row branching for lower runtime and energy use.
# - Ensured reproducibility via fixed random_state for train_test_split and MLPClassifier to stabilize outputs across runs.
# - Avoided unnecessary side effects: removed model saving and all non-required prints; kept only final accuracy print in required format.
# - Kept scalers fit/transform minimal: fit once on train (train/eval path) and fit once on input (predict path) without extra intermediate structures.