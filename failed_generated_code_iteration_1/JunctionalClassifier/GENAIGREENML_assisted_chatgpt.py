# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import pickle
import random
from typing import Tuple, Optional

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler


SEED = 42


def _set_reproducible(seed: int = SEED) -> None:
    os.environ.setdefault("PYTHONHASHSEED", str(seed))
    random.seed(seed)
    np.random.seed(seed)


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _load_model(path: str) -> MLPClassifier:
    with open(path, "rb") as f:
        model = pickle.load(f)
    return model


def _infer_label_column(df: pd.DataFrame) -> Optional[str]:
    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    if not numeric_cols:
        return None
    return numeric_cols[-1]


def _extract_xy_from_supervised_df(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
    label_col = _infer_label_column(df)
    if label_col is None:
        raise ValueError("No numeric columns found to infer labels.")
    df_num = df.select_dtypes(include=[np.number]).copy()
    if label_col not in df_num.columns:
        label_col = df_num.columns[-1]

    y_raw = df_num[label_col].to_numpy()
    y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0)).astype(np.int64)

    X = df_num.drop(columns=[label_col]).to_numpy(dtype=np.float64, copy=False)
    return X, y


def _train_test_accuracy(train_csv_path: str) -> float:
    df = _read_csv_robust(train_csv_path)
    X, y = _extract_xy_from_supervised_df(df)

    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.3,
        random_state=SEED,
        stratify=y if np.unique(y).size > 1 else None,
    )

    clf = MLPClassifier(hidden_layer_sizes=(30, 30, 30, 30), max_iter=1000, random_state=SEED)
    pipe = Pipeline([("scaler", StandardScaler()), ("clf", clf)])

    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)
    return float(accuracy_score(y_test, y_pred))


def main() -> None:
    _set_reproducible(SEED)
    accuracy = _train_test_accuracy("14k.csv")
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed interactive prediction flow and unit tests to ensure non-interactive, deterministic end-to-end execution focused on the training/evaluation task.
# - Replaced manual CSV parsing loops with vectorized pandas loading to reduce Python-level overhead and data movement.
# - Implemented robust CSV parsing fallback (default read_csv, then sep=';' and decimal=',') to handle common formatting issues without repeated parsing logic.
# - Avoided global mutable lists by extracting X/y as NumPy arrays directly, reducing memory churn and improving cache efficiency.
# - Used a sklearn Pipeline (StandardScaler + MLP) to prevent redundant transformations and keep preprocessing/model steps compact and efficient.
# - Ensured reproducibility via fixed random seeds (Python, NumPy, train_test_split, and MLPClassifier) to stabilize results across runs.
# - Limited intermediate copies by using to_numpy(..., copy=False) where feasible to reduce memory footprint and unnecessary allocations.