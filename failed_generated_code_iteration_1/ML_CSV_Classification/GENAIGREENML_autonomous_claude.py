# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
import warnings
warnings.filterwarnings("ignore")

# Robust CSV loading
file_path = 'grafici.csv'
df = None
try:
    df = pd.read_csv(file_path)
    if df.shape[1] < 2:
        raise ValueError("Too few columns with default sep")
except Exception:
    try:
        df = pd.read_csv(file_path, sep=';', decimal=',')
    except Exception:
        pass

if df is None or df.empty:
    try:
        df = pd.read_csv(file_path, sep=None, engine='python')
    except Exception:
        pass

assert df is not None and not df.empty, "Failed to load dataset"

# Normalize column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
drop_cols = [c for c in df.columns if c.startswith('Unnamed')]
df = df.drop(columns=drop_cols, errors='ignore')

# Coerce all possible numeric columns
for col in df.columns:
    if df[col].dtype == object:
        converted = pd.to_numeric(df[col].str.strip().str.replace(',', '.', regex=False), errors='coerce')
        if converted.notna().sum() > 0.5 * len(converted):
            df[col] = converted

# Identify target: last column (as in original code)
target_col = df.columns[-1]
feature_cols = list(df.columns[:-1])

# Try to make target numeric if it isn't already
if df[target_col].dtype == object:
    converted_target = pd.to_numeric(df[target_col], errors='coerce')
    if converted_target.notna().sum() > 0.5 * len(converted_target):
        df[target_col] = converted_target
    else:
        # Encode as categorical labels
        df[target_col] = df[target_col].astype('category').cat.codes

# Ensure target is not all NaN
df = df.dropna(subset=[target_col])

# Separate numeric and non-numeric features
numeric_features = []
for c in feature_cols:
    if pd.api.types.is_numeric_dtype(df[c]):
        numeric_features.append(c)

# If no numeric features, try to convert remaining
if len(numeric_features) == 0:
    for c in feature_cols:
        conv = pd.to_numeric(df[c], errors='coerce')
        if conv.notna().sum() > 0.3 * len(conv):
            df[c] = conv
            numeric_features.append(c)

# Use numeric features only for this lightweight pipeline
feature_cols_final = numeric_features if numeric_features else feature_cols

assert len(feature_cols_final) > 0, "No usable feature columns found"

X = df[list(feature_cols_final)].copy()
y = df[target_col].copy()

# Coerce features to numeric, handle NaN/inf
X = X.apply(pd.to_numeric, errors='coerce')
X = X.replace([np.inf, -np.inf], np.nan)

# Drop rows where all features are NaN
valid_mask = X.notna().any(axis=1)
X = X.loc[valid_mask]
y = y.loc[valid_mask]

# Impute remaining NaN with column medians
X = X.fillna(X.median())

# Drop any still-remaining NaN rows
valid_mask2 = X.notna().all(axis=1) & y.notna()
X = X.loc[valid_mask2].reset_index(drop=True)
y = y.loc[valid_