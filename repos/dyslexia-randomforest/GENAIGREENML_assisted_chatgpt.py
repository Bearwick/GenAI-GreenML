# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix


def _load_and_prepare(filepath: str, drop_cols: tuple[str, ...]) -> pd.DataFrame:
    df = pd.read_csv(filepath)
    df = df.drop(list(drop_cols), axis="columns", errors="ignore")
    df["class"] = df["class"].replace({"CN": 0, "DYS": 1})
    return df


def confmatrix_of_RandomForest(trainingdata_filepath: str, testdata_filepath: str, criterion: str = "entropy") -> np.ndarray:
    drop_cols = ("parts {1=akoustiko,2=optiko,3=mousiki}", "Subject ID")

    training_data = _load_and_prepare(trainingdata_filepath, drop_cols)
    test_data = _load_and_prepare(testdata_filepath, drop_cols)

    cols_with_nan = training_data.columns[training_data.isna().any()].union(
        test_data.columns[test_data.isna().any()]
    )
    if len(cols_with_nan) > 0:
        training_data = training_data.drop(cols_with_nan, axis="columns")
        test_data = test_data.drop(cols_with_nan, axis="columns")

    y_training = training_data["class"].astype(np.int32, copy=False)
    x_training = training_data.drop(columns=["class"]).astype(np.float32, copy=False)

    y_test = test_data["class"].astype(np.int32, copy=False)
    x_test = test_data.drop(columns=["class"]).astype(np.float32, copy=False)

    conf_accum = np.zeros(4, dtype=np.float64)
    acc_accum = 0.0

    for seed in range(5):
        model = RandomForestClassifier(
            criterion=criterion,
            max_depth=8,
            random_state=seed,
            n_jobs=-1,
        )
        model.fit(x_training, y_training)
        acc_accum += model.score(x_test, y_test)
        y_pred = model.predict(x_test)
        conf_accum += confusion_matrix(y_test, y_pred, labels=[0, 1]).ravel()

    mean_conf = conf_accum / 5.0
    accuracy = acc_accum / 5.0
    print(f"ACCURACY={accuracy:.6f}")
    return mean_conf


if __name__ == "__main__":
    confmatrix_of_RandomForest("entire brain_training_2.csv", "entire brain_test_2.csv")


# OPTIMIZATION SUMMARY
# - Removed CSV writes and all intermediate prints to eliminate unnecessary I/O and console overhead.
# - Centralized loading/preprocessing in a helper to avoid duplicated work and reduce code paths.
# - Used a single pass to compute NaN columns via column union, avoiding list/set constructions and extra conversions.
# - Avoided repeated DataFrame astype on full frames; cast only feature matrix to float32 and target to int32 to reduce memory.
# - Accumulated confusion matrices directly in a fixed-size NumPy array (ravel) to avoid storing per-run matrices.
# - Set n_jobs=-1 to utilize parallelism for RandomForest fitting/prediction, reducing wall-clock time for the same model.
# - Added random_state per run to keep runs reproducible/stable while preserving the original "run 5 times then average" behavior.