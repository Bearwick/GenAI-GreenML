# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix

def safe_load(path):
    try:
        df = pd.read_csv(path)
        if df.shape[1] <= 1:
            df = pd.read_csv(path, sep=';', decimal=',')
    except Exception:
        df = pd.read_csv(path, sep=';', decimal=',')
    return df

def confmatrix_of_RandomForest(training_path, test_path, criterion="entropy"):
    tr_df = safe_load(training_path)
    te_df = safe_load(test_path)
    
    d_cols = ['parts {1=akoustiko,2=optiko,3=mousiki}', 'Subject ID']
    tr_df.drop(columns=[c for c in d_cols if c in tr_df.columns], inplace=True)
    te_df.drop(columns=[c for c in d_cols if c in te_df.columns], inplace=True)
    
    mapping = {'CN': 0, 'DYS': 1}
    tr_df.replace(mapping, inplace=True)
    te_df.replace(mapping, inplace=True)
    
    nan_cols = set(tr_df.columns[tr_df.isna().any()]) | set(te_df.columns[te_df.isna().any()])
    if nan_cols:
        ln = list(nan_cols)
        tr_df.drop(columns=ln, inplace=True)
        te_df.drop(columns=ln, inplace=True)
    
    tr_df = tr_df.astype(np.float32, copy=False)
    if 'class' in tr_df.columns:
        tr_df['class'] = tr_df['class'].astype(np.int32, copy=False)
        
    te_df = te_df.astype(np.float32, copy=False)
    if 'class' in te_df.columns:
        te_df['class'] = te_df['class'].astype(np.int32, copy=False)
    
    y_tr = tr_df['class']
    x_tr = tr_df.drop(columns=['class'])
    y_te = te_df['class']
    x_te = te_df.drop(columns=['class'])
    
    cms = []
    for i in range(5):
        clf = RandomForestClassifier(criterion=criterion, max_depth=8, random_state=42+i)
        clf.fit(x_tr, y_tr)
        y_pred = clf.predict(x_te)
        cms.append(confusion_matrix(y_te, y_pred, labels=[0, 1]).flatten())
        
    return np.mean(cms, axis=0)

if __name__ == '__main__':
    m_conf = confmatrix_of_RandomForest("entire brain_training_2.csv", "entire brain_test_2.csv")
    accuracy = (m_conf[0] + m_conf[3]) / m_conf.sum()
    print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Removed energy-intensive disk I/O operations by eliminating intermediate CSV exports.
# - Implemented memory-efficient data manipulation using inplace operations and explicit dtype management.
# - Consolidated column dropping and NaN handling to minimize redundant scanning of the dataframes.
# - Enhanced performance by replacing model.score() with confusion matrix-based metrics to avoid redundant computation.
# - Provided robust data ingestion with fallback delimiter logic to handle varied CSV formats.
# - Utilized NumPy vectorization for aggregating performance metrics across multiple iterations.
# - Fixed random seeds for the RandomForestClassifier to ensure reproducible and stable outputs.
# - Minimized memory footprint by casting the dataset to float32 and reusing existing structures.