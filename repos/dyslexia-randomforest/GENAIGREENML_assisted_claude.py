# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

def confmatrix_of_RandomForest(trainingdata_filepath, testdata_filepath, criterion="entropy"):
    training_data = pd.read_csv(trainingdata_filepath)
    test_data = pd.read_csv(testdata_filepath)

    cols_to_drop_train = [c for c in ['parts {1=akoustiko,2=optiko,3=mousiki}', 'Subject ID'] if c in training_data.columns]
    cols_to_drop_test = [c for c in ['parts {1=akoustiko,2=optiko,3=mousiki}', 'Subject ID'] if c in test_data.columns]
    training_data.drop(cols_to_drop_train, axis='columns', inplace=True)
    test_data.drop(cols_to_drop_test, axis='columns', inplace=True)

    label_map = {'CN': 0, 'DYS': 1}
    training_data.replace(label_map, inplace=True)
    test_data.replace(label_map, inplace=True)

    na_cols_train = training_data.columns[training_data.isna().any()].tolist()
    na_cols_test = test_data.columns[test_data.isna().any()].tolist()
    exclude_list = set(na_cols_train + na_cols_test)
    if exclude_list:
        training_data.drop(exclude_list, axis='columns', inplace=True)
        test_data.drop(exclude_list, axis='columns', inplace=True)

    training_data = training_data.astype(np.float32, copy=False)
    training_data = training_data.astype({'class': np.int32}, copy=False)
    test_data = test_data.astype(np.float32, copy=False)
    test_data = test_data.astype({'class': np.int32}, copy=False)

    y_training = training_data['class'].values
    x_training = training_data.drop('class', axis='columns').values
    y_test = test_data['class'].values
    x_test = test_data.drop('class', axis='columns').values

    n_runs = 5
    conf_accum = np.zeros(4, dtype=np.float64)
    total_accuracy = 0.0

    for _ in range(n_runs):
        model = RandomForestClassifier(criterion=criterion, max_depth=8, n_jobs=-1)
        model.fit(x_training, y_training)
        y_pred = model.predict(x_test)
        total_accuracy += accuracy_score(y_test, y_pred)
        conf = confusion_matrix(y_test, y_pred, labels=[0, 1]).flatten()
        conf_accum += conf

    mean_conf = conf_accum / n_runs
    accuracy = total_accuracy / n_runs

    print(f"ACCURACY={accuracy:.6f}")
    return mean_conf

if __name__ == '__main__':
    confmatrix_of_RandomForest("entire brain_training_2.csv", "entire brain_test_2.csv")

# OPTIMIZATION SUMMARY
# 1. Removed file saving (trainingfinal.csv, testfinal.csv) to eliminate unnecessary I/O.
# 2. Removed all print statements except the required accuracy print.
# 3. Removed plots and interactive inputs as required.
# 4. Combined label replacements into a single dict-based replace call to reduce overhead.
# 5. Converted DataFrames to numpy arrays (.values) before model training to avoid repeated pandas overhead.
# 6. Accumulated confusion matrix in a single array instead of creating a 2D array and computing mean separately.
# 7. Used n_jobs=-1 in RandomForestClassifier to leverage all CPU cores for faster training.
# 8. Computed accuracy directly via accuracy_score instead of model.score