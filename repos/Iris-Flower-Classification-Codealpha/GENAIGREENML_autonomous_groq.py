# Generated by generate_llm_code.py
# LLM: groq
# Mode: autonomous

# Energy‑efficient Iris flower classifier
# ----------------------------------------
# Design choices:
# • Logistic regression is a linear model that converges quickly and
#   requires minimal memory – ideal for small datasets.
# • StandardScaler standardises features, improving numerical stability.
# • No heavy embeddings or deep learning components are used.
# • All random seeds are fixed for reproducibility.
# • The script is lightweight and runs efficiently on a CPU.

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load data (assumes 'Iris.csv' is in the current working directory)
df = pd.read_csv("Iris.csv")

# Drop unused identifier column if present
df = df.drop(columns=[c for c in ["Id"] if c in df.columns])

# Encode class labels
le = LabelEncoder()
df["Species"] = le.fit_transform(df["Species"])

X = df.drop("Species", axis=1)
y = df["Species"]

# Train–test split (fixed random state for reproducibility)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Preprocessing + model pipeline
pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("model", LogisticRegression(max_iter=200, solver="lbfgs", multi_class="auto"))
])

# Fit and evaluate
pipe.fit(X_train, y_train)
y_pred = pipe.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Output only the requested accuracy
print(f"ACCURACY={accuracy:.6f}")