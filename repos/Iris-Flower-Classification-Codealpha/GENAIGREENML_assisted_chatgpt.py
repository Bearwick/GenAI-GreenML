# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


def load_data(path: str) -> tuple[np.ndarray, np.ndarray]:
    df = pd.read_csv(path)
    if "Id" in df.columns:
        df = df.drop(columns=["Id"])
    y = pd.Categorical(df["Species"]).codes.astype(np.int64, copy=False)
    X = df.drop(columns=["Species"]).to_numpy(dtype=np.float32, copy=False)
    return X, y


def build_model() -> Pipeline:
    return Pipeline(
        steps=[
            ("scaler", StandardScaler(copy=False)),
            ("model", LogisticRegression(max_iter=200, solver="lbfgs")),
        ]
    )


def main() -> None:
    X, y = load_data("Iris.csv")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    model = build_model()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# - Removed unused heavy imports (matplotlib, seaborn, cross_val_score, report/matrix) to reduce startup time and memory.
# - Replaced LabelEncoder with pandas.Categorical codes to avoid extra transformer object and reduce overhead while preserving label behavior.
# - Converted features to a compact NumPy float32 array to reduce memory footprint and speed up numeric operations.
# - Used StandardScaler(copy=False) to reduce intermediate allocations and data movement during scaling.
# - Removed plotting, verbose printing, and cross-validation to avoid extra computation and runtime while keeping the core train/test behavior unchanged.
# - Modularized into small functions for clarity and to avoid accidental repeated work; fixed random_state for reproducibility.