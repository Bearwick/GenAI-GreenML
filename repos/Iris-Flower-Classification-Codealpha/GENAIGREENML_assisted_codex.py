# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

DATASET_HEADERS = "Id,SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species"

def _normalize_columns(columns):
    return [str(c).strip() for c in columns]

def _needs_fallback(df, expected_headers):
    if df.shape[1] <= 1:
        return True
    if not expected_headers:
        return False
    cols_lower = {str(c).strip().lower() for c in df.columns}
    matches = sum(1 for h in expected_headers if h.lower() in cols_lower)
    return matches < max(2, len(expected_headers) // 2)

def read_csv_robust(path, expected_headers):
    df = pd.read_csv(path)
    df.columns = _normalize_columns(df.columns)
    if _needs_fallback(df, expected_headers):
        df = pd.read_csv(path, sep=";", decimal=",")
        df.columns = _normalize_columns(df.columns)
    return df

def find_column(columns, target):
    if target is None:
        return None
    target_lower = target.lower()
    for col in columns:
        if str(col).lower() == target_lower:
            return col
    return None

def main():
    np.random.seed(42)
    expected_headers = [h.strip() for h in DATASET_HEADERS.split(",") if h.strip()]
    df = read_csv_robust("Iris.csv", expected_headers)
    id_hint = expected_headers[0] if expected_headers else None
    label_hint = expected_headers[-1] if expected_headers else None
    id_col = find_column(df.columns, id_hint)
    if id_col is not None:
        df.drop(columns=[id_col], inplace=True)
    label_col = find_column(df.columns, label_hint)
    if label_col is None:
        label_col = df.columns[-1]
    y_raw = df.pop(label_col)
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y_raw)
    X_values = df.to_numpy()
    X_train, X_test, y_train, y_test = train_test_split(
        X_values, y, test_size=0.2, random_state=42, stratify=y
    )
    pipeline = Pipeline([
        ("scaler", StandardScaler(copy=False)),
        ("model", LogisticRegression(max_iter=200, random_state=42))
    ])
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    _ = classification_report(y_test, y_pred, output_dict=True)
    _ = confusion_matrix(y_test, y_pred)
    _ = cross_val_score(pipeline, X_values, y, cv=5, n_jobs=1).mean()
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed plotting and extraneous logging to avoid unnecessary computation.
# - Used in-place column removal and pop to minimize DataFrame copying.
# - Converted features to a NumPy array once to reduce repeated pandas conversions.
# - Enabled in-place scaling with StandardScaler(copy=False) to lower memory usage.
# - Set fixed random seeds and deterministic parameters for reproducibility.