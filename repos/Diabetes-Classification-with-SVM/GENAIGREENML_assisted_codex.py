# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import os
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")
os.environ.setdefault("OPENBLAS_NUM_THREADS", "1")
os.environ.setdefault("VECLIB_MAXIMUM_THREADS", "1")
os.environ.setdefault("NUMEXPR_NUM_THREADS", "1")

import random
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVC
from imblearn.over_sampling import SMOTE
import scipy.stats as stats

SEED = 42
random.seed(SEED)
np.random.seed(SEED)

DATASET_HEADERS = [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age",
    "Outcome",
]

def load_dataset(path, expected_headers):
    def _read(**kwargs):
        df = pd.read_csv(path, **kwargs)
        df.columns = df.columns.str.strip()
        return df
    df = _read()
    expected_lower = [h.lower() for h in expected_headers]
    cols_lower = [c.lower() for c in df.columns]
    if df.shape[1] == 1 or not set(expected_lower).issubset(cols_lower):
        df = _read(sep=";", decimal=",")
    return df

data = load_dataset("diabetes2.csv", DATASET_HEADERS)
data.columns = data.columns.str.strip()
available = {c.lower(): c for c in data.columns}
expected_lower = [h.lower() for h in DATASET_HEADERS]
target_col = available.get("outcome", data.columns[-1])

if all(h in available for h in expected_lower):
    feature_cols = [available[h] for h in expected_lower if h != "outcome"]
else:
    feature_cols = [c for c in data.columns if c != target_col]

X = data[feature_cols].to_numpy()
y = data[target_col].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=SEED
)

scaler = MinMaxScaler(copy=False)
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

smote = SMOTE(random_state=SEED)
X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)

param_distributions = {
    "C": stats.loguniform(1e-3, 1e3),
    "gamma": stats.loguniform(1e-3, 1e3),
    "kernel": ["linear", "rbf"],
}

random_search = RandomizedSearchCV(
    SVC(),
    param_distributions,
    n_iter=50,
    cv=5,
    n_jobs=1,
    random_state=SEED,
)
random_search.fit(X_resampled, y_resampled)

best_model = random_search.best_estimator_
accuracy = best_model.score(X_test_scaled, y_test)
print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Removed visualization and extra metric computations to avoid redundant inference work.
# - Implemented robust CSV parsing with a fallback to prevent repeated manual fixes.
# - Converted features to numpy arrays and used in-place scaling to reduce memory usage.
# - Limited thread usage and parallel jobs for lower resource consumption and determinism.
# - Retained only final accuracy evaluation to minimize unnecessary processing.