# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def load_dataset():
    expected_cols = [
        "Pregnancies",
        "Glucose",
        "BloodPressure",
        "SkinThickness",
        "Insulin",
        "BMI",
        "DiabetesPedigreeFunction",
        "Age",
        "Outcome",
    ]
    for file in os.listdir("."):
        if file.lower().endswith(".csv"):
            try:
                df = pd.read_csv(file)
            except Exception:
                continue
            if set(expected_cols).issubset(df.columns):
                return df[expected_cols]
    raise FileNotFoundError("Dataset with expected headers not found.")

df = load_dataset()

missing_zero_cols = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
df[missing_zero_cols] = df[missing_zero_cols].replace(0, np.nan)

feature_cols = [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age",
]

X = df[feature_cols]
y = df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

model = Pipeline(
    steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
        ("classifier", LogisticRegression(solver="liblinear", max_iter=200)),
    ]
)

model.fit(X_train, y_train)
preds = model.predict(X_test)
accuracy = accuracy_score(y_test, preds)
print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# Used a simple logistic regression model for low computational cost on CPU.
# Applied median imputation and standard scaling in a compact pipeline for reproducibility.
# Avoided complex models and deep learning to minimize energy and compute usage.