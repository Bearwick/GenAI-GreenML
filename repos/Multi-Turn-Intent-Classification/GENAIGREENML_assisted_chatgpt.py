# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import json
import csv
import random
from typing import List, Dict, Any, Optional

import numpy as np
import torch
from transformers import pipeline


SEED = 42


def _set_reproducibility(seed: int = SEED) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    torch.use_deterministic_algorithms(True, warn_only=True)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True


def _select_device() -> int:
    return 0 if torch.cuda.is_available() else -1


def _create_conversation(messages: List[Dict[str, Any]], max_messages: Optional[int] = None) -> str:
    if not messages:
        return ""
    if max_messages is not None and max_messages > 0 and len(messages) > max_messages:
        messages = messages[-max_messages:]

    lines = []
    append = lines.append
    for m in messages:
        sender = m.get("sender", "")
        text = m.get("text", "")
        if sender:
            sender = sender[:1].upper() + sender[1:].lower()
        append(f"{sender}: {text}")
    return "\n".join(lines)


class IntentDetector:
    def __init__(self, device: int):
        self.intent_options = [
            "Book Appointment",
            "Product Inquiry",
            "Pricing Negotiation",
            "Support Request",
            "Follow-Up",
        ]
        model_name = "cross-encoder/nli-distilroberta-base"
        self.intent_pipeline = pipeline(
            task="zero-shot-classification",
            model=model_name,
            device=device,
        )

    def classify_intent(self, dialogue: str) -> Dict[str, str]:
        classification = self.intent_pipeline(dialogue, self.intent_options)
        top_intent = classification["labels"][0]
        return {
            "predicted_intent": top_intent,
            "rationale": f"Based on the conversation, the customer is likely interested in '{top_intent.lower()}'.",
        }


def _load_conversations(input_file: str) -> List[Dict[str, Any]]:
    with open(input_file, "r", encoding="utf-8") as infile:
        data = json.load(infile)
    return data if isinstance(data, list) else []


def predict_intents(
    input_file: str,
    json_output: str,
    csv_output: str,
    detector: IntentDetector,
) -> float:
    conversations = _load_conversations(input_file)

    output_data: List[Dict[str, Any]] = []
    append_out = output_data.append

    correct = 0
    total = 0

    for entry in conversations:
        conv_id = entry.get("conversation_id")
        formatted_text = _create_conversation(entry.get("messages", []))

        intent_result = detector.classify_intent(formatted_text)
        pred = intent_result["predicted_intent"]

        append_out(
            {
                "conversation_id": conv_id,
                "predicted_intent": pred,
                "rationale": intent_result["rationale"],
            }
        )

        gold = entry.get("intent")
        if isinstance(gold, str):
            total += 1
            if pred == gold:
                correct += 1

    os.makedirs(os.path.dirname(json_output) or ".", exist_ok=True)

    with open(json_output, "w", encoding="utf-8") as jf:
        json.dump(output_data, jf, indent=2, ensure_ascii=False)

    with open(csv_output, "w", newline="", encoding="utf-8") as cf:
        fieldnames = ["conversation_id", "predicted_intent", "rationale"]
        writer = csv.DictWriter(cf, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(output_data)

    accuracy = (correct / total) if total else 0.0
    return accuracy


def main() -> None:
    _set_reproducibility(SEED)
    device = _select_device()
    detector = IntentDetector(device=device)

    accuracy = predict_intents(
        input_file="data/input.json",
        json_output="data/output/predictions.json",
        csv_output="data/output/predictions.csv",
        detector=detector,
    )
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused imports and the unused text-cleaning function to reduce startup overhead and avoid redundant computation.
# - Enabled deterministic execution (fixed seeds + deterministic torch settings) for reproducibility without iterative reruns.
# - Selected GPU only when available via a single device check, minimizing unnecessary data movement/config branching.
# - Avoided intermediate structures in conversation formatting by using a single list with local variable bindings for faster appends.
# - Streamlined the prediction loop by using local references (append_out) and computing accuracy in a single pass without extra traversals.
# - Kept output writing minimal and direct (single JSON dump + CSV writer) while preserving required artifacts and schema.