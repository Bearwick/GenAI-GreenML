# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import json
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

# Load JSON data robustly
data = None
with open("data/input.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# data could be a list of records or a dict with a key containing records
if isinstance(data, dict):
    # Try to find the main list inside the dict
    possible_keys = list(data.keys())
    if len(possible_keys) == 1:
        records = data[possible_keys[0]]
    else:
        # Try common keys
        for k in ["data", "conversations", "records", "samples", "examples", "items"]:
            if k in data:
                records = data[k]
                break
        else:
            # If dict values are all lists, pick the longest
            list_vals = {k: v for k, v in data.items() if isinstance(v, list)}
            if list_vals:
                records = list_vals[max(list_vals, key=lambda k: len(list_vals[k]))]
            else:
                records = [data]
elif isinstance(data, list):
    records = data
else:
    records = [data]

df = pd.DataFrame(records)

# Strip/normalize column names
df.columns = [str(c).strip() for c in df.columns]
df = df[[c for c in df.columns if not c.startswith("Unnamed")]]

# Identify text and target columns
# For multi-turn intent classification, we expect some text field(s) and an intent/label field
text_col = None
target_col = None

# Heuristics for target column (intent/label)
target_candidates = ["intent", "label", "target", "class", "category", "prediction", "predicted_intent"]
for candidate in target_candidates:
    matches = [c for c in df.columns if candidate.lower() in c.lower()]
    if matches:
        target_col = matches[0]
        break

# Heuristics for text column (conversation/message/text)
text_candidates = ["conversation", "text", "message", "messages", "input", "query", "utterance", "content", "turns"]
for candidate in text_candidates:
    matches = [c for c in df.columns if candidate.lower() in c.lower()]
    if matches:
        text_col = matches[0]
        break

# If we couldn't find a text column, try to construct text from available columns
# For multi-turn conversations, the text might be nested (list of dicts with role/content)
if text_col is None:
    # Pick the first column that has string or list data
    for c in df.columns:
        if c == target_col:
            continue
        sample = df[c].dropna().iloc[0] if len(df[c].dropna()) > 0 else None
        if isinstance(sample, (str, list)):
            text_col = c
            break

# If target_col is still None, try to find a categorical column that isn't the text
if target_col is None:
    for c in df.columns:
        if c == text_col:
            continue
        if df[c].dtype == object or df[c].nunique() < 50:
            target_col = c
            break

# If still no target, check if there's a nested structure with intent inside conversations
if target_col is None and text_col is not None:
    # Maybe intent is embedded in the records themselves
    sample_record = records[0] if records else {}
    for k in sample_record:
        if k != text_col and "intent" in k.lower() or k.lower() in ["label", "class", "category"]:
            target_col = k
            break

# Fallback: if we truly have no target, look for any column with limited unique values
if