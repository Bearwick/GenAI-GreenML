# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: autonomous

import sys
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def read_data():
    path = sys.argv[1] if len(sys.argv) > 1 else "data.csv"
    try:
        df = pd.read_csv(path, sep=None, engine="python")
    except Exception:
        df = pd.read_csv(path)
    return df

def normalize_columns(df):
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    df = df.loc[:, ~df.columns.str.match(r"^\s*$")]
    return df

def parse_datetime_features(df):
    df = df.copy()
    if "Date" in df.columns:
        df["Date"] = df["Date"].astype(str).str.strip()
    if "Time" in df.columns:
        df["Time"] = df["Time"].astype(str).str.strip()

    if "Date" in df.columns:
        dt = pd.to_datetime(df["Date"], errors="coerce", dayfirst=True)
        df["month"] = dt.dt.month
        df["dayofweek"] = dt.dt.dayofweek

    if "Time" in df.columns:
        tm = pd.to_datetime(df["Time"], errors="coerce", format="%H.%M.%S")
        if tm.isna().all():
            tm = pd.to_datetime(df["Time"], errors="coerce", format="%H:%M:%S")
        df["hour"] = tm.dt.hour
    return df

def coerce_numeric(df):
    df = df.copy()
    for c in df.columns:
        if c in ("Date", "Time"):
            continue
        if df[c].dtype == "object":
            df[c] = df[c].astype(str).str.replace(",", ".", regex=False).str.strip()
        df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

def build_target(df):
    if "CO(GT)" not in df.columns:
        raise ValueError("Expected target column 'CO(GT)' not found.")
    y_cont = df["CO(GT)"].copy()
    y_cont = pd.to_numeric(y_cont, errors="coerce")
    valid = y_cont.notna() & np.isfinite(y_cont)
    y_cont_valid = y_cont[valid]
    if y_cont_valid.empty:
        raise ValueError("Target column contains no valid numeric values.")
    median = float(y_cont_valid.median())
    y = (y_cont > median).astype(int)
    return y

def main():
    df = read_data()
    df = normalize_columns(df)
    df = parse_datetime_features(df)
    df = coerce_numeric(df)

    y = build_target(df)
    X = df.drop(columns=[c for c in ["CO(GT)"] if c in df.columns], errors="ignore")

    valid = y.notna()
    X = X.loc[valid].copy()
    y = y.loc[valid].astype(int).to_numpy()

    X = X.replace([-200, -999, -1], np.nan)

    numeric_features = [c for c in X.columns if c not in ("Date", "Time") and pd.api.types.is_numeric_dtype(X[c])]
    categorical_features = [c for c in X.columns if c in ("Date", "Time")]

    num_pipe = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler(with_mean=True, with_std=True)),
    ])

    cat_pipe = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=True)),
    ])

    pre = ColumnTransformer(
        transformers=[
            ("num", num_pipe, numeric_features),
            ("cat", cat_pipe, categorical_features),
        ],
        remainder="drop",
        sparse_threshold=0.3
    )

    model = LogisticRegression(
        solver="liblinear",
        max_iter=300,
        C=1.0,
        class_weight=None
    )

    pipe = Pipeline(steps=[("pre", pre), ("clf", model)])

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y if len(np.unique(y)) > 1 else None
    )

    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()