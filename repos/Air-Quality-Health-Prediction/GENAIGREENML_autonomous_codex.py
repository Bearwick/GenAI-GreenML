# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import pandas as pd
import numpy as np
import glob
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import Ridge, LogisticRegression
from sklearn.metrics import r2_score, accuracy_score

justification = "Lightweight preprocessing with median imputation and scaling; linear models selected for efficiency on small tabular data."

csv_files = glob.glob("*.csv")
if not csv_files:
    raise FileNotFoundError("No CSV file found.")
df = pd.read_csv(csv_files[0], sep=None, engine="python", decimal=",")

df = df.loc[:, ~df.columns.str.contains("^Unnamed")]
df = df.dropna(axis=1, how="all")
df.replace([-200, -200.0, "-200"], np.nan, inplace=True)
df = df.dropna(axis=0, how="all")

target_col = None
if "CO(GT)" in df.columns:
    target_col = "CO(GT)"
elif "target" in df.columns:
    target_col = "target"
else:
    for col in reversed(df.columns):
        if str(col).strip() == "" or col in ["Date", "Time"]:
            continue
        target_col = col
        break
if target_col is None:
    raise ValueError("Target column not found.")

if "Date" in df.columns or "Time" in df.columns:
    if "Date" in df.columns and "Time" in df.columns:
        dt = pd.to_datetime(df["Date"].astype(str) + " " + df["Time"].astype(str), errors="coerce", dayfirst=True)
        df = df.drop(columns=["Date", "Time"])
    elif "Date" in df.columns:
        dt = pd.to_datetime(df["Date"].astype(str), errors="coerce", dayfirst=True)
        df = df.drop(columns=["Date"])
    else:
        dt = pd.to_datetime(df["Time"].astype(str), errors="coerce")
        df = df.drop(columns=["Time"])
    df["Year"] = dt.dt.year
    df["Month"] = dt.dt.month
    df["Day"] = dt.dt.day
    df["Hour"] = dt.dt.hour
    df["Minute"] = dt.dt.minute

y = df[target_col]
X = df.drop(columns=[target_col])

if y.dtype == "object":
    y_conv = pd.to_numeric(y.str.replace(",", ".", regex=False), errors="coerce")
    if y_conv.notna().sum() == y.shape[0]:
        y = y_conv

for col in X.columns:
    if X[col].dtype == "object":
        X[col] = pd.to_numeric(X[col].str.replace(",", ".", regex=False), errors="coerce")

X = X.dropna(axis=1, how="all")

mask = y.notna()
X = X.loc[mask]
y = y.loc[mask]

is_classification = False
if y.dtype == "object":
    is_classification = True
elif y.dtype.kind in "biu":
    unique_vals = y.nunique()
    if unique_vals <= max(20, int(0.05 * len(y)) + 1):
        is_classification = True

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

if is_classification:
    if y_train.dtype == "object":
        le = LabelEncoder()
        y_train = le.fit_transform(y_train)
        y_test = le.transform(y_test)
    model = Pipeline(
        [
            ("imputer", SimpleImputer(strategy="median")),
            ("scaler", StandardScaler()),
            ("model", LogisticRegression(max_iter=200, solver="liblinear")),
        ]
    )
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    accuracy = accuracy_score(y_test, preds)
else:
    model = Pipeline(
        [
            ("imputer", SimpleImputer(strategy="median")),
            ("scaler", StandardScaler()),
            ("model", Ridge(alpha=1.0)),
        ]
    )
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    accuracy = r2_score(y_test, preds)

print(f"ACCURACY={accuracy:.6f}")