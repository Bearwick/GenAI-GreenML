# Generated by generate_llm_code.py
# LLM: gemini
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score

def load_data(path):
    # Robust parsing as per requirement 3 & 4
    try:
        # Initial attempt
        df = pd.read_csv(path, sep=None, engine='python')
    except Exception:
        # Fallback to common UCI format
        df = pd.read_csv(path, sep=';', decimal=',')
    
    # Normalize column names
    df.columns = [str(c).strip() for c in df.columns]
    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
    df = df.dropna(how='all', axis=0).dropna(how='all', axis=1)
    
    return df

def clean_and_prepare(df):
    # Convert numeric columns and handle the UCI specific -200 null marker
    cols_to_fix = ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH', 'NOx(GT)', 'NO2(GT)']
    
    for col in df.columns:
        if col not in ['Date', 'Time']:
            # Handle string-based decimals if present
            if df[col].dtype == 'object':
                df[col] = df[col].str.replace(',', '.')
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # Replace UCI null value (-200) with NaN
    df = df.replace(-200, np.nan)
    
    # Select features based on context requirements
    features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']
    available_features = [f for f in features if f in df.columns]
    
    if not available_features:
        # Fallback: take any numeric columns if specific ones are missing
        available_features = df.select_dtypes(include=[np.number]).columns.tolist()
        if 'Hospital_Visits' in available_features: available_features.remove('Hospital_Visits')
        if 'Risk_Label' in available_features: available_features.remove('Risk_Label')

    # Data cleaning: drop rows where features are mostly missing to ensure quality
    df = df.dropna(subset=available_features, thresh=len(available_features)//2)
    
    # Generate Synthetic Target as per ML_PROJECT_CONTEXT
    # Risk_Label (high-risk if visits > median)
    # Hospital_Visits is modeled as a function of pollutants
    if 'Hospital_Visits' not in df.columns:
        # Simple weighted sum of pollutants to simulate hospital visits
        # Higher pollutants = higher visits.
        pollutant_mix = df[available_features].mean(axis=1).fillna(0)
        df['Hospital_Visits'] = pollutant_mix * 1.5 + np.random.normal(0, 1, len(df))
        
    if 'Risk_Label' not in df.columns:
        median_visits = df['Hospital_Visits'].median()
        df['Risk_Label'] = (df['Hospital_Visits'] > median_visits).astype(int)

    return df, available_features, 'Risk_Label'

def main():
    path = 'data/AirQualityUCI.csv'
    
    try:
        df = load_data(path)
        df, features, target = clean_and_prepare(df)
        
        if df.empty or len(df[target].unique()) < 2:
            # Trivial baseline if data is insufficient
            print(f"ACCURACY={0.000000:.6f}")
            return

        X = df[features]
        y = df[target]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # Pipeline: Energy efficient choices
        # Imputer (Mean) -> Scaler (Standard) -> Logistic Regression (Lightweight)
        pipeline = Pipeline([
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(
                solver='liblinear', # Efficient for small/medium datasets
                max_iter=1000,
                random_state=42
            ))
        ])

        pipeline.fit(X_train, y_train)
        y_pred = pipeline.predict(X_test)
        
        accuracy = accuracy_score(y_test, y_pred)
        print(f"ACCURACY={accuracy:.6f}")

    except Exception:
        # Ensure the script never crashes and provides the required output format
        print(f"ACCURACY={0.000000:.6f}")

if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# 1. Model Choice: Logistic Regression was chosen over RandomForest (mentioned in context) to minimize 
#    CPU cycles and memory footprint, as it provides a robust linear baseline with minimal energy cost.
# 2. Solver Selection: 'liblinear' solver used as it is computationally efficient for smaller datasets 
#    and binary classification tasks.
# 3. Preprocessing: Used sklearn Pipeline to prevent data leakage and minimize redundant transformations 
#    of the feature space.
# 4. Data Handling: Robust CSV parsing with multiple fallbacks ensures the pipeline runs without 
#    manual intervention, handling the specific decimal/separator quirks of the UCI Air Quality dataset.
# 5. Missing Values: Replaced UCI-specific sentinel values (-200) with NaN and used SimpleImputer 
#    instead of complex iterative methods to save compute time.
# 6. Resource Usage: The solution runs entirely on CPU with very low RAM overhead by avoiding 
#    heavy ensemble methods or deep learning frameworks.