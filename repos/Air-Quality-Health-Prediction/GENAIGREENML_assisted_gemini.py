# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import accuracy_score

def load_and_preprocess(filepath):
    cols_to_use = ['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)', 
                   'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH']
    df = pd.read_csv(filepath, sep=';', decimal=',', usecols=cols_to_use).dropna()
    df = df.replace(-200, np.nan).dropna()
    df['Risk_Label'] = (df['CO(GT)'] > df['CO(GT)'].median()).astype(int)
    return df.astype(np.float32)

def train_models(data, feature_cols):
    X = data[feature_cols]
    y_reg = data['PT08.S1(CO)']
    y_clf = data['Risk_Label']

    X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test = train_test_split(
        X, y_reg, y_clf, test_size=0.2, random_state=42
    )

    reg_model = LinearRegression().fit(X_train, y_reg_train)
    clf_model = LogisticRegression(max_iter=1000).fit(X_train, y_clf_train)
    
    y_clf_pred = clf_model.predict(X_test)
    accuracy = accuracy_score(y_clf_test, y_clf_pred)
    
    return accuracy

def main():
    features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']
    data = load_and_preprocess('data/AirQualityUCI.csv')
    accuracy = train_models(data, features)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# OPTIMIZATIONS APPLIED:
# 1. Efficient Data Loading: Used 'usecols' in read_csv to prevent loading unnecessary columns into memory.
# 2. Reduced Data Footprint: Converted the dataframe to 'float32' to halve memory usage compared to default 'float64'.
# 3. Streamlined Preprocessing: Combined cleaning steps (dropping NaNs and handling -200 markers) to minimize data passes.
# 4. Computationally Lightweight Models: Utilized LinearRegression and LogisticRegression instead of heavy ensemble methods.
# 5. Minimized Data Movement: Performed a single train-test split for both regression and classification tasks.
# 6. Eliminated Redundant Computation: Removed all visualization, complex metric calculations, and intermediate logging.
# 7. Vectorized Logic: Replaced potential loops with native pandas/numpy vectorized operations for thresholding and cleaning.