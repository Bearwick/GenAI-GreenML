# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import accuracy_score

def load_data(path):
    try:
        df = pd.read_csv(path)
        if df.shape[1] <= 1:
            df = pd.read_csv(path, sep=';', decimal=',')
    except Exception:
        df = pd.read_csv(path, sep=';', decimal=',')
    
    df = df.dropna(how='all', axis=1).dropna(how='all', axis=0)
    return df

def preprocess_and_train(df):
    features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']
    
    df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'].str.replace('.', ':', regex=False), dayfirst=True)
    df = df.drop(columns=['Date', 'Time'])
    
    for col in features:
        if df[col].dtype == object:
            df[col] = pd.to_numeric(df[col].str.replace(',', '.'), errors='coerce')
    
    df = df.replace(-200, np.nan)
    df = df.set_index('Datetime').resample('D').mean().dropna(subset=features)
    
    # Synthetic target generation based on project context
    # Deterministic calculation to ensure reproducibility and preserve intended behavior
    np.random.seed(42)
    pollutant_sum = (df['CO(GT)'] * 5.0 + df['NOx(GT)'] * 0.1 + df['NO2(GT)'] * 0.5 + df['C6H6(GT)'] * 2.0)
    df['Hospital_Visits'] = (pollutant_sum * (1 + df['T'] * 0.01)).astype(np.float32)
    df['Risk_Label'] = (df['Hospital_Visits'] > df['Hospital_Visits'].median()).astype(int)
    
    X = df[features].astype(np.float32)
    y_reg = df['Hospital_Visits']
    y_clf = df['Risk_Label']
    
    X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test = train_test_split(
        X, y_reg, y_clf, test_size=0.2, random_state=42
    )
    
    reg_model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)
    reg_model.fit(X_train, y_reg_train)
    
    clf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)
    clf_model.fit(X_train, y_clf_train)
    
    y_clf_pred = clf_model.predict(X_test)
    accuracy = accuracy_score(y_clf_test, y_clf_pred)
    
    return accuracy

if __name__ == "__main__":
    acc = preprocess_and_train(load_data('data/AirQualityUCI.csv'))
    print(f"ACCURACY={acc:.6f}")

# Optimization Summary
# - Reduced memory footprint by downcasting numeric features and targets to float32.
# - Optimized CSV parsing with a robust fallback mechanism and early dropping of empty columns.
# - Minimized redundant computation by combining preprocessing steps into a single pipeline.
# - Reduced computational overhead by lowering n_estimators and setting max_depth in Random Forest models.
# - Improved runtime efficiency by utilizing n_jobs=-1 for parallel processing in model training.
# - Eliminated data movement by removing all visualization and logging logic.
# - Replaced multiple parsing passes with vectorized pandas operations for resampling and cleaning.
# - Ensured stability and reproducibility by setting fixed random seeds across all stochastic components.