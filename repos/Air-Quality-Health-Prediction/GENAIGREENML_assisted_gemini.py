# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def load_data(filepath):
    try:
        df = pd.read_csv(filepath, sep=';', decimal=',', parse_dates={'Datetime': ['Date', 'Time']})
    except Exception:
        df = pd.read_csv(filepath)
        if 'Date' in df.columns and 'Time' in df.columns:
            df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'].str.replace('.', ':'))
    
    df.replace(-200, np.nan, inplace=True)
    df.dropna(axis=1, how='all', inplace=True)
    return df

def preprocess_data(df):
    features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']
    df = df[['Datetime'] + features].copy()
    df.set_index('Datetime', inplace=True)
    
    df = df.resample('D').mean().dropna()
    
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], downcast='float')
    
    np.random.seed(42)
    df['Hospital_Visits'] = (
        0.5 * df['CO(GT)'] + 
        0.05 * df['NOx(GT)'] + 
        0.1 * df['NO2(GT)'] + 
        1.2 * df['C6H6(GT)'] + 
        np.random.normal(0, 2, len(df))
    ).astype('float32')
    
    median_visits = df['Hospital_Visits'].median()
    df['Risk_Label'] = (df['Hospital_Visits'] > median_visits).astype('int8')
    
    return df, features

def run_pipeline():
    raw_data = load_data('data/AirQualityUCI.csv')
    data, features = preprocess_data(raw_data)
    
    X = data[features]
    y_reg = data['Hospital_Visits']
    y_clf = data['Risk_Label']
    
    X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test = train_test_split(
        X, y_reg, y_clf, test_size=0.2, random_state=42
    )
    
    reg_model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)
    reg_model.fit(X_train, y_reg_train)
    
    clf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)
    clf_model.fit(X_train, y_clf_train)
    
    y_clf_pred = clf_model.predict(X_test)
    accuracy = accuracy_score(y_clf_test, y_clf_pred)
    
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_pipeline()

# Optimization Summary
# 1. Reduced memory footprint by downcasting numerical columns to float32 and int8.
# 2. Optimized CSV loading with specific separator and decimal handling to prevent multiple passes.
# 3. Streamlined preprocessing by combining resampling and dropping NaNs early to reduce row count.
# 4. Reduced computational overhead by lowering RandomForest n_estimators from 100 to 50 and setting max_depth.
# 5. Parallelized model training using n_jobs=-1 to utilize all available CPU cores efficiently.
# 6. Eliminated redundant data copies and intermediate structures by using inplace operations and focused feature selection.
# 7. Removed energy-intensive visualization libraries and logging to focus purely on computation.
# 8. Optimized resampling to 'Daily' frequency which significantly reduces the dataset size for the ML phase while maintaining trend analysis.