# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# ---- 1. Robust CSV Loading ----
dataset_path = "data/AirQualityUCI.csv"

try:
    df = pd.read_csv(dataset_path)
    # Check if parsing looks wrong (too few columns or single column)
    if df.shape[1] < 3:
        raise ValueError("Too few columns, retry with sep=';'")
except Exception:
    df = pd.read_csv(dataset_path, sep=';', decimal=',', encoding='utf-8')

# If still problematic, try sep=';' anyway if many columns have semicolons
if df.shape[1] < 5:
    df = pd.read_csv(dataset_path, sep=';', decimal=',', encoding='utf-8')

# ---- 2. Column Normalization ----
df.columns = df.columns.str.strip()
df.columns = df.columns.str.replace(r'\s+', ' ', regex=True)

# Drop unnamed or empty columns
drop_cols = [c for c in df.columns if c.startswith('Unnamed') or c.strip() == '']
df.drop(columns=drop_cols, inplace=True, errors='ignore')

# ---- 3. Handle European decimal format ----
# Some columns may still be strings with commas as decimal separators
for col in df.columns:
    if df[col].dtype == object and col not in ['Date', 'Time']:
        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)
        df[col] = pd.to_numeric(df[col], errors='coerce')

# ---- 4. Parse Date/Time and create Datetime index ----
if 'Date' in df.columns and 'Time' in df.columns:
    # Time might be like 18.00.00 â€” replace dots with colons
    df['Time'] = df['Time'].astype(str).str.replace('.', ':', regex=False)
    df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], dayfirst=True, errors='coerce')
    df.drop(columns=['Date', 'Time'], inplace=True, errors='ignore')
    df = df.dropna(subset=['Datetime'])
    df.set_index('Datetime', inplace=True)

# ---- 5. Replace sentinel values (-200) with NaN ----
df.replace(-200, np.nan, inplace=True)
df.replace(-200.0, np.nan, inplace=True)

# ---- 6. Coerce all remaining columns to numeric ----
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# ---- 7. Drop rows/columns with too many NaNs ----
# Drop columns that are >80% NaN
thresh_col = len(df) * 0.2
df = df.dropna(axis=1, thresh=int(thresh_col))

# Drop rows where all values are NaN
df.dropna(how='all', inplace=True)

# ---- 8. Resample to daily averages as per project context ----
if isinstance(df.index, pd.DatetimeIndex):
    df = df.resample('D').mean()
    df.dropna(how='all', inplace=True)

# ---- 9. Define features per project context ----
desired_features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']
available_features = [f for f in desired_features if f in df.columns]

# If not enough desired features, use all available numeric columns
if len(available_features) < 2: