# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# --- Robust CSV Loading ---
DATASET_PATH = "data/AirQualityUCI.csv"

try:
    df = pd.read_csv(DATASET_PATH)
    # Check if parsing looks wrong (e.g., single column with semicolons)
    if df.shape[1] < 3:
        raise ValueError("Too few columns, likely wrong separator")
except Exception:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')

# --- Column Name Normalization ---
df.columns = df.columns.str.strip()
df.columns = [' '.join(c.split()) for c in df.columns]
# Drop unnamed/empty columns
df = df.loc[:, ~df.columns.str.match(r'^Unnamed|^$')]

# --- Parse European-style decimals ---
# The dataset uses comma as decimal separator for numeric fields when loaded with default sep
# If loaded with sep=';' and decimal=',', they should already be numeric
# But let's be safe and coerce everything that looks like a comma-decimal string
for col in df.columns:
    if df[col].dtype == object and col not in ['Date', 'Time']:
        # Try replacing comma with dot and converting
        converted = df[col].astype(str).str.replace(',', '.', regex=False)
        converted = pd.to_numeric(converted, errors='coerce')
        if converted.notna().sum() > 0.3 * len(df):
            df[col] = converted

# --- Combine Date and Time into Datetime, then resample to daily ---
datetime_col = None
if 'Date' in df.columns and 'Time' in df.columns:
    try:
        # Time format: 18.00.00
        time_str = df['Time'].astype(str).str.replace('.', ':', regex=False)
        datetime_str = df['Date'].astype(str) + ' ' + time_str
        # Try multiple date formats
        for fmt in ['%d/%m/%Y %H:%M:%S', '%m/%d/%Y %H:%M:%S', '%Y-%m-%d %H:%M:%S']:
            try:
                datetime_col = pd.to_datetime(datetime_str, format=fmt)
                break
            except Exception:
                continue
        if datetime_col is None:
            datetime_col = pd.to_datetime(datetime_str, dayfirst=True, errors='coerce')
    except Exception:
        datetime_col = None

drop_cols = []
if 'Date' in df.columns:
    drop_cols.append('Date')
if 'Time' in df.columns:
    drop_cols.append('Time')

if datetime_col is not None:
    df['Datetime'] = datetime_col
    df = df.drop(columns=drop_cols, errors='ignore')
    df = df.dropna(subset=['Datetime'])
    df = df.set_index('Datetime')
    # Resample to daily averages (only numeric)
    df = df.resample('D').mean()
    df = df.dropna(how='all')
else:
    df = df.drop(columns=drop_cols, errors='ignore')

# --- Replace sentinel values (-200) with NaN ---
df = df.replace(-200, np.nan)
df = df.replace(-200.0, np.nan)

# --- Coerce all columns to numeric ---
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# --- Drop rows/columns with too many NaN ---
df = df.dropna(axis=1, thresh=int(0.5 * len(df)))
df = df.dropna(axis=0, how='all')

# --- Define feature columns per README ---
desired_features = ['CO(GT)',