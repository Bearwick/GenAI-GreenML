# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# --- Robust CSV loading ---
DATASET_PATH = "data/AirQualityUCI.csv"

try:
    df = pd.read_csv(DATASET_PATH)
    # Check if parsing went wrong (too few columns might indicate wrong separator)
    if df.shape[1] < 3:
        raise ValueError("Too few columns, retry with sep=';'")
except Exception:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')

# If still only 1-2 columns, try another combo
if df.shape[1] < 3:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')

# --- Column name normalization ---
df.columns = df.columns.str.strip()
df.columns = [' '.join(c.split()) for c in df.columns]
# Drop unnamed columns
df = df.loc[:, ~df.columns.str.match(r'^Unnamed')]

# --- Parse European-style decimals ---
# The dataset uses commas as decimal separators in quoted fields
for col in df.columns:
    if df[col].dtype == object and col not in ['Date', 'Time']:
        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)
        df[col] = pd.to_numeric(df[col], errors='coerce')

# --- Parse datetime and resample to daily ---
try:
    # Time is in format like 18.00.00
    if 'Date' in df.columns and 'Time' in df.columns:
        df['Datetime'] = pd.to_datetime(
            df['Date'].astype(str) + ' ' + df['Time'].astype(str).str.replace('.', ':', regex=False),
            dayfirst=True, errors='coerce'
        )
        df = df.drop(columns=['Date', 'Time'], errors='ignore')
        df = df.set_index('Datetime')
    elif 'Date' in df.columns:
        df['Datetime'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')
        df = df.drop(columns=['Date'], errors='ignore')
        df = df.set_index('Datetime')
except Exception:
    # If datetime parsing fails, just drop Date/Time
    df = df.drop(columns=['Date', 'Time'], errors='ignore')

# --- Replace sentinel values: -200 is the missing value marker in this dataset ---
df = df.replace(-200, np.nan)
df = df.replace(-200.0, np.nan)

# --- Drop rows that are entirely NaN ---
df = df.dropna(how='all')

# --- Coerce all remaining columns to numeric ---
for col in df.columns:
    if df[col].dtype == object:
        df[col] = pd.to_numeric(df[col], errors='coerce')

# --- Resample to daily averages if we have a datetime index ---
if isinstance(df.index, pd.DatetimeIndex):
    df = df.resample('D').mean()
    df = df.dropna(how='all')

# --- Feature selection based on README context ---
desired_features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']
available_features = [f for f in desired_features if f in df.columns]

# Fallback: if fewer than 2 desired features found, use all numeric columns
if len(available_features) < 2:
    available_features = [c for c in df.columns if df[c].dtype in [np.float64, np.int64, np.float32, np.int32]]

# --- Create synthetic target as described in README ---
# Hospital_Visits = synthetic regression