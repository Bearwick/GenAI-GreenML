# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# --- Robust CSV loading ---
DATASET_PATH = "data/AirQualityUCI.csv"

try:
    df = pd.read_csv(DATASET_PATH)
    # Check if parsing went wrong (too few columns often means wrong separator)
    if df.shape[1] < 3:
        raise ValueError("Too few columns, retry with sep=';'")
except Exception:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',', na_values=['', ' '])

# If still only 1-2 columns, try another combo
if df.shape[1] < 3:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',', na_values=['', ' '])

# --- Column name normalization ---
df.columns = df.columns.str.strip()
df.columns = [' '.join(c.split()) for c in df.columns]
# Drop Unnamed columns
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# --- Parse Date and Time into Datetime index ---
if 'Date' in df.columns and 'Time' in df.columns:
    # Time is in format like 18.00.00
    df['Time_str'] = df['Time'].astype(str).str.replace('.', ':', regex=False)
    # Try to parse datetime
    try:
        df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time_str'], dayfirst=True, errors='coerce')
    except Exception:
        df['Datetime'] = pd.NaT
    df = df.drop(columns=['Date', 'Time', 'Time_str'], errors='ignore')
    if df['Datetime'].notna().sum() > 0:
        df = df.set_index('Datetime')
else:
    # Drop Date/Time if only one exists
    df = df.drop(columns=['Date', 'Time'], errors='ignore')

# --- Convert all remaining columns to numeric ---
for col in df.columns:
    if df[col].dtype == object:
        # Handle European decimal comma: replace comma with dot
        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)
    df[col] = pd.to_numeric(df[col], errors='coerce')

# --- Drop rows/columns that are all NaN ---
df = df.dropna(axis=1, how='all')
df = df.dropna(axis=0, how='all')

# --- Replace sentinel values: -200 is used as missing in this dataset ---
df = df.replace(-200, np.nan)
df = df.replace(-200.0, np.nan)

# --- Feature selection based on README ---
desired_features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']
available_features = [f for f in desired_features if f in df.columns]

# If we don't have enough desired features, pick numeric columns
if len(available_features) < 2:
    available_features = [c for c in df.columns if df[c].dtype in ['float64', 'int64', 'float32', 'int32']]
    # Limit to reasonable number
    available_features = available_features[:10]

# --- Resample to daily averages if we have a datetime index ---
if isinstance(df.index, pd.DatetimeIndex) and df.index.notna().sum() > 0:
    df = df.resample('D').mean()
    df = df.dropna(how='all')

# --- Drop rows with NaN in features ---
feature_cols = [c for c in available_features if c in df.columns]
df_model = df[feature_cols