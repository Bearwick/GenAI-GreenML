# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import r2_score, mean_squared_error, accuracy_score

def load_and_preprocess(filepath):
    data = pd.read_csv(filepath, sep=';', decimal=',', na_values=-200)
    data.drop(columns=[col for col in data.columns if 'Unnamed' in col or col in ('Date', 'Time')], inplace=True, errors='ignore')
    data.dropna(inplace=True)
    data.reset_index(drop=True, inplace=True)
    return data

def main():
    data = load_and_preprocess('data/AirQualityUCI.csv')
    features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']

    available_features = [f for f in features if f in data.columns]
    X = data[available_features].values

    if 'PT08.S5(O3)' in data.columns:
        y_reg = data['PT08.S5(O3)'].values
    else:
        y_reg = data.iloc[:, -1].values

    median_val = np.median(y_reg)
    y_clf = (y_reg > median_val).astype(np.int32)

    X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test = train_test_split(
        X, y_reg, y_clf, test_size=0.2, random_state=42
    )

    reg_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    reg_model.fit(X_train, y_reg_train)
    y_pred_reg = reg_model.predict(X_test)

    clf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    clf_model.fit(X_train, y_clf_train)
    y_clf_pred = clf_model.predict(X_test)

    accuracy = accuracy_score(y_clf_test, y_clf_pred)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# 1. Removed all visualization imports and plotting calls to eliminate unnecessary computation and I/O.
# 2. Removed all print statements except the required accuracy print.
# 3. Removed saving of trained models.
# 4. Inlined preprocessing and modeling to avoid importing external modules, reducing import overhead.
# 5. Used .values to work with numpy arrays directly instead of pandas Series where possible.
# 6. Used n_jobs=-1 for parallel training in RandomForest models to reduce wall-clock time.
# 7. Combined train_test_split into a single call for regression and classification targets to avoid redundant splitting.
# 8. Used numpy median instead of pandas for threshold computation (lighter operation).
# 9. Dropped unused columns early and used inplace operations to reduce memory footprint.
# 10. Maintained reproducibility with random_state=42.