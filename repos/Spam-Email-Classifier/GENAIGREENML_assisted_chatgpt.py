# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from nltk.stem import PorterStemmer


RANDOM_SEED = 42


def set_reproducible_seed(seed: int) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def read_csv_robust(path: str, expected_headers: set) -> pd.DataFrame:
    df = pd.read_csv(path)
    cols = set(map(str, df.columns))
    if not expected_headers.issubset(cols):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def stem_message_series(messages: pd.Series, stemmer: PorterStemmer) -> pd.Series:
    stem = stemmer.stem

    def convert(text: str) -> str:
        if not isinstance(text, str):
            return ""
        return " ".join(stem(tok) for tok in text.split())

    return messages.astype(str, copy=False).map(convert)


def main() -> None:
    set_reproducible_seed(RANDOM_SEED)

    expected_headers = {"Category", "Message"}
    df = read_csv_robust("spam.csv", expected_headers)

    available_cols = set(map(str, df.columns))
    if not expected_headers.issubset(available_cols):
        raise ValueError(f"Required columns missing. Found columns: {list(df.columns)}")

    df = df.loc[:, ["Category", "Message"]].copy()

    le = LabelEncoder()
    y = le.fit_transform(df["Category"].astype(str, copy=False))

    ps = PorterStemmer()
    X_text = stem_message_series(df["Message"], ps)

    cv = CountVectorizer(stop_words="english")
    X_train, X_test, y_train, y_test = train_test_split(
        X_text,
        y,
        test_size=0.2,
        random_state=RANDOM_SEED,
        shuffle=True,
        stratify=y if len(np.unique(y)) > 1 else None,
    )

    X_train_count = cv.fit_transform(X_train)
    X_test_count = cv.transform(X_test)

    model = MultinomialNB()
    model.fit(X_train_count, y_train)

    y_pred = model.predict(X_test_count)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed interactive input and per-query prediction to avoid idle runtime/energy; replaced with deterministic evaluation on the held-out test set.
# - Added fixed seeds (Python/NumPy + train_test_split random_state) for reproducible, stable results and to prevent repeated reruns due to variability.
# - Implemented robust CSV parsing with a fallback delimiter/decimal configuration to avoid costly manual fixes and reruns.
# - Reduced unnecessary data movement by selecting only required columns and avoiding global pandas display options.
# - Vectorized/stabilized preprocessing: used Series.map with a locally bound stem function to reduce attribute lookups and intermediate lists.
# - Avoided redundant computation by transforming the test split once and reusing the fitted vectorizer/model for scoring.
# - Kept sparse matrices throughout (CountVectorizer output) to minimize memory footprint during training and evaluation.