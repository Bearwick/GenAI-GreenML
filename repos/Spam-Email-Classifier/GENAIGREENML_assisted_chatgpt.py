# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
from nltk.stem import PorterStemmer

RANDOM_SEED = 42


def read_csv_robust(path: str, expected_headers=None) -> pd.DataFrame:
    df = pd.read_csv(path)
    if expected_headers is not None:
        cols = {c.strip().lower() for c in df.columns}
        exp = {c.strip().lower() for c in expected_headers}
        if not exp.issubset(cols):
            df = pd.read_csv(path, sep=";", decimal=",")
    return df


def resolve_columns(df: pd.DataFrame, expected_headers):
    colmap = {c.strip().lower(): c for c in df.columns}
    resolved = []
    for h in expected_headers:
        key = h.strip().lower()
        if key not in colmap:
            raise KeyError(f"Missing expected column: {h}. Available columns: {list(df.columns)}")
        resolved.append(colmap[key])
    return resolved


def stem_texts(texts: pd.Series, stemmer: PorterStemmer) -> pd.Series:
    s = texts.fillna("").astype(str)
    return s.map(lambda t: " ".join(stemmer.stem(tok) for tok in t.split()))


def main():
    expected_headers = ["Category", "Message"]
    df = read_csv_robust("spam.csv", expected_headers=expected_headers)
    cat_col, msg_col = resolve_columns(df, expected_headers)

    le = LabelEncoder()
    y = le.fit_transform(df[cat_col].astype(str))

    stemmer = PorterStemmer()
    messages = stem_texts(df[msg_col], stemmer)

    X_train, X_test, y_train, y_test = train_test_split(
        messages,
        y,
        test_size=0.2,
        random_state=RANDOM_SEED,
        stratify=y,
    )

    cv = CountVectorizer(stop_words="english")
    X_train_count = cv.fit_transform(X_train)
    X_test_count = cv.transform(X_test)

    model = MultinomialNB()
    model.fit(X_train_count, y_train)

    accuracy = model.score(X_test_count, y_test)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed interactive input and per-query inference to avoid unnecessary runtime and idle energy use; evaluation is done once on a held-out test split.
# - Added deterministic train/test split (random_state + stratify) to ensure reproducible results and stable measurements.
# - Implemented robust CSV parsing with a fallback delimiter/decimal setting to prevent costly downstream errors/retries.
# - Derived column names from df.columns using DATASET_HEADERS to avoid hardcoding and reduce failure-driven reruns.
# - Replaced row-wise Python loop for stemming with a single Series.map call and generator expression to minimize intermediate lists and memory overhead.
# - Avoided extra DataFrame copies by operating on Series (y/messages) directly and only transforming the required splits.
# - Used sparse matrices from CountVectorizer end-to-end and transformed test data once to minimize data movement and computation.