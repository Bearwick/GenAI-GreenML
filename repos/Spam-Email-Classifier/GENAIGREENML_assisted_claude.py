# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
from nltk.stem import PorterStemmer
import numpy as np

SEED = 42
np.random.seed(SEED)

ps = PorterStemmer()

def convert(word):
    return " ".join(ps.stem(token) for token in word.split(" "))

try:
    df = pd.read_csv("spam.csv")
    if df.shape[1] < 2:
        raise ValueError
except (ValueError, pd.errors.ParserError):
    df = pd.read_csv("spam.csv", sep=";", decimal=",")

cat_col = df.columns[0]
msg_col = df.columns[1]

le = LabelEncoder()
y = le.fit_transform(df[cat_col].values)
messages = df[msg_col].apply(convert)

X_train, X_test, y_train, y_test = train_test_split(
    messages, y, test_size=0.2, random_state=SEED
)

cv = CountVectorizer(stop_words="english")
X_train_count = cv.fit_transform(X_train)
X_test_count = cv.transform(X_test)

model = MultinomialNB()
model.fit(X_train_count, y_train)

accuracy = model.score(X_test_count, y_test)
print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# Removed interactive input (is_spam) to eliminate manual intervention requirement.
# Removed all print statements and visualizations except the required accuracy print.
# Used generator expression in convert() instead of building an intermediate list.
# Derived column names from df.columns rather than hardcoding, with robust CSV fallback.
# Set fixed random seed for reproducibility in train_test_split and numpy.
# Avoided redundant pd.set_option call.
# Computed accuracy on the test set to provide the required metric output.
# Reduced memory by not storing intermediate transformed arrays unnecessarily.
# Imported PorterStemmer from nltk.stem directly for clarity.