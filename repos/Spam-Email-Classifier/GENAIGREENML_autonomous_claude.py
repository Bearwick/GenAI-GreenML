# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import re
import sys
import warnings
warnings.filterwarnings("ignore")

# Robust CSV loading
df = None
for sep, decimal in [(',', '.'), (';', ','), ('\t', '.')]:
    try:
        df = pd.read_csv("spam.csv", sep=sep, decimal=decimal, encoding='utf-8')
        if df.shape[1] >= 2:
            break
    except Exception:
        continue

if df is None or df.shape[1] < 2:
    try:
        df = pd.read_csv("spam.csv", encoding='latin-1')
    except Exception:
        df = pd.read_csv("spam.csv", encoding='latin-1', sep=',')

# Normalize column names
df.columns = [re.sub(r'\s+', ' ', str(c).strip()) for c in df.columns]
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# If there are extra columns (common in some spam.csv variants with extra unnamed cols), drop them
if df.shape[1] > 2:
    # Keep only first two columns if they look like category+message
    first_two = df.iloc[:, :2].copy()
    first_two.columns = ['Category', 'Message']
    df = first_two

# Identify Category and Message columns
cat_col = None
msg_col = None
for c in df.columns:
    cl = c.lower().strip()
    if cl in ('category', 'label', 'class', 'v1', 'type', 'spam'):
        cat_col = c
    elif cl in ('message', 'text', 'v2', 'sms', 'email', 'content'):
        msg_col = c

if cat_col is None:
    cat_col = df.columns[0]
if msg_col is None:
    msg_col = df.columns[1]

# Drop rows with missing values in key columns
df = df[[cat_col, msg_col]].dropna().reset_index(drop=True)
df[msg_col] = df[msg_col].astype(str)

assert df.shape[0] > 0, "Dataset is empty after preprocessing"

# Simple lightweight stemming without NLTK dependency
def simple_stem(word):
    """Very lightweight suffix-stripping stemmer to avoid NLTK dependency."""
    if len(word) > 5 and word.endswith('ing'):
        return word[:-3]
    if len(word) > 4 and word.endswith('ed'):
        return word[:-2]
    if len(word) > 4 and word.endswith('ly'):
        return word[:-2]
    if len(word) > 5 and word.endswith('tion'):
        return word[:-4]
    if len(word) > 3 and word.endswith('s') and not word.endswith('ss'):
        return word[:-1]
    return word

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    tokens = text.split()
    tokens = [simple_stem(t) for t in tokens if len(t) > 1]
    return ' '.join(tokens)

df['processed'] = df[msg_col].apply(preprocess_text)

# Encode target
le = LabelEncoder()
df['target'] = le.fit_transform(df[cat_col])

assert df['target'].nunique() >= 2, "Need at least 2 classes for classification"

# Train/test split with fixed random state for reproducibility
X_train, X_test, y_train, y_test = train_test_split(
    df['processed'], df['target'],