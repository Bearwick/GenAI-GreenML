# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import re
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

DATASET_PATH = "email_analysis.csv"
DATASET_HEADERS = ["sender", "subject", "body", "urls", "filename", "label", "text"]
SEED = 42


def _set_reproducible(seed: int = SEED) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def _looks_misparsed(df: pd.DataFrame) -> bool:
    if df is None or df.empty:
        return True
    if df.shape[1] <= 1:
        return True
    cols = set(str(c).strip().lower() for c in df.columns)
    expected = set(h.lower() for h in DATASET_HEADERS)
    overlap = len(cols & expected)
    return overlap < 2


def read_csv_robust(path: str) -> pd.DataFrame:
    df = None
    try:
        df = pd.read_csv(path)
    except Exception:
        df = None

    if df is None or _looks_misparsed(df):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _ensure_text_column(df: pd.DataFrame) -> pd.DataFrame:
    cols = {c.lower(): c for c in df.columns}
    subject_col = cols.get("subject")
    body_col = cols.get("body")
    text_col = cols.get("text")

    if text_col is not None:
        df[text_col] = df[text_col].astype(str)
        return df

    if subject_col is None and body_col is None:
        raise ValueError("No usable text columns found; expected 'text' or ('subject' and/or 'body').")

    subj = df[subject_col].fillna("").astype(str) if subject_col is not None else ""
    body = df[body_col].fillna("").astype(str) if body_col is not None else ""
    df["text"] = subj + " " + body
    return df


def train_and_evaluate(df: pd.DataFrame, seed: int = SEED) -> float:
    cols = {c.lower(): c for c in df.columns}
    label_col = cols.get("label")
    if label_col is None:
        raise ValueError("Missing required column: 'label'.")

    df = _ensure_text_column(df)

    y = df[label_col].astype(str)
    X_text = df["text"].fillna("").astype(str)

    vectorizer = TfidfVectorizer(stop_words="english", max_features=5000, dtype=np.float32)
    X = vectorizer.fit_transform(X_text)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=seed, shuffle=True, stratify=y if y.nunique() > 1 else None
    )

    model = MultinomialNB()
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    return float(accuracy_score(y_test, y_pred))


def main() -> None:
    _set_reproducible(SEED)
    df = read_csv_robust(DATASET_PATH)
    accuracy = train_and_evaluate(df, SEED)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Switched workflow to read the existing CSV directly, avoiding expensive filesystem traversal, email parsing, HTML parsing, and URL regex extraction while keeping the same spam-classification task.
# - Implemented robust CSV parsing with a fallback separator/decimal to prevent costly downstream failures and reruns.
# - Derived usable schema from df.columns (case-insensitive) and DATASET_HEADERS, avoiding assumptions and minimizing conditional recomputation.
# - Reduced memory footprint of TF-IDF matrix by using float32 (dtype=np.float32) with identical model behavior for MultinomialNB inputs.
# - Avoided creating unused intermediate outputs (removed report/prediction/sample inference and any file saving), reducing CPU and I/O.
# - Ensured reproducibility with fixed seeds for Python and NumPy and fixed train_test_split random_state; used stratify when possible for stable splits.