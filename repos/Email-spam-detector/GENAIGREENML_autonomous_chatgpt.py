# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: autonomous

import os
import re
import warnings
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.feature_extraction.text import HashingVectorizer
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import Ridge


warnings.filterwarnings("ignore")


def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [
        re.sub(r"\s+", " ", str(c).strip()) for c in df.columns
    ]
    df = df.loc[:, [c for c in df.columns if not str(c).startswith("Unnamed:")]]
    return df


def _robust_read_csv(path: str) -> pd.DataFrame:
    # Try default parsing first, then fallback to European CSV conventions if it looks wrong.
    try:
        df1 = pd.read_csv(path)
    except Exception:
        df1 = pd.DataFrame()

    def _looks_bad(df: pd.DataFrame) -> bool:
        if df is None or df.empty:
            return True
        if df.shape[1] <= 1:
            return True
        all_obj = True
        for c in df.columns:
            if pd.api.types.is_numeric_dtype(df[c]):
                all_obj = False
                break
        if all_obj:
            # Sometimes a failed parse yields one huge object column or all-strings.
            sample = df.head(20)
            if sample.shape[1] == 1:
                return True
        return False

    if _looks_bad(df1):
        try:
            df2 = pd.read_csv(path, sep=";", decimal=",")
            if not df2.empty and df2.shape[1] > df1.shape[1]:
                return df2
            return df2 if not _looks_bad(df2) else df1
        except Exception:
            return df1
    return df1


def _find_dataset_path() -> str:
    candidates = [
        "email_analysis.csv",
        "dataset.csv",
        "data.csv",
        "train.csv",
        "emails.csv",
        "spam.csv",
    ]
    for p in candidates:
        if os.path.exists(p) and os.path.isfile(p):
            return p
    # Fallback: first CSV in cwd
    for fn in os.listdir("."):
        if fn.lower().endswith(".csv") and os.path.isfile(fn):
            return fn
    return ""


def _safe_to_numeric(series: pd.Series) -> pd.Series:
    s = pd.to_numeric(series, errors="coerce")
    s = s.replace([np.inf, -np.inf], np.nan)
    return s


def _choose_target(df: pd.DataFrame):
    cols = list(df.columns)
    # Prefer common label names
    preferred = ["label", "target", "y", "class"]
    for c in preferred:
        if c in df.columns:
            return c

    # Otherwise prefer a non-constant object/categorical column with small-ish cardinality
    best = None
    best_score = -1
    for c in cols:
        if c.lower().startswith("unnamed:"):
            continue
        s = df[c]
        nun = s.nunique(dropna=True)
        if nun < 2:
            continue
        if s.dtype == "object" or pd.api.types.is_bool_dtype(s) or pd.api.types.is_categorical_dtype(s):
            # Score: prefer low/medium cardinality but not too low
            score = 0
            if 2 <= nun <= 50:
                score += 3
            elif nun <= 200:
                score += 1
            # Prefer columns that look like labels
            if any(k in c.lower() for k in ["label", "target", "spam", "class"]):
                score += 2
            if score > best_score:
                best_score = score
                best = c
    if best is not None:
        return best

    # Otherwise choose a numeric non-constant column
    for c in cols:
        s = _safe_to_numeric(df[c])
        if s.notna().sum() == 0:
            continue
        if s.nunique(dropna=True) >= 2:
            return c

    # Last resort: first column
    return cols[0] if cols else None


def _pick_text_features(df: pd.DataFrame, exclude: set) -> list:
    candidates = []
    # Prefer known email/text columns
    preferred_order = ["text", "body", "subject", "sender", "urls", "filename"]
    for c in preferred_order:
        if c in df.columns and c not in exclude:
            candidates.append(c)
    # Add other object columns
    for c in df.columns:
        if c in exclude or c in candidates:
            continue
        if df[c].dtype == "object" or pd.api.types.is_categorical_dtype(df[c]):
            candidates.append(c)
    return candidates


def _build_text_series(df: pd.DataFrame, text_cols: list) -> pd.Series:
    if not text_cols:
        return pd.Series([""] * len(df), index=df.index)
    parts = []
    for c in text_cols:
        s = df[c]
        if not (s.dtype == "object" or pd.api.types.is_categorical_dtype(s)):
            s = s.astype(str)
        s = s.fillna("").astype(str)
        parts.append(s)
    out = parts[0]
    for s in parts[1:]:
        out = out + " " + s
    return out


def _is_classification_target(y: pd.Series) -> bool:
    if y is None or len(y) == 0:
        return False
    if y.dtype == "object" or pd.api.types.is_bool_dtype(y) or pd.api.types.is_categorical_dtype(y):
        return y.nunique(dropna=True) >= 2
    # Numeric: treat as classification if integer-like with small cardinality
    yn = _safe_to_numeric(y)
    if yn.notna().sum() == 0:
        return False
    nun = yn.nunique(dropna=True)
    if nun < 2:
        return False
    # integer-like?
    frac = (yn.dropna() - np.floor(yn.dropna())).abs()
    is_int_like = (frac < 1e-9).mean() > 0.98
    if is_int_like and nun <= 20:
        return True
    return False


def main():
    path = _find_dataset_path()
    if not path:
        # No dataset; keep behavior defined without extra stdout.
        accuracy = 0.0
        print(f"ACCURACY={accuracy:.6f}")
        return

    df = _robust_read_csv(path)
    df = _normalize_columns(df)

    assert df is not None and not df.empty and df.shape[0] > 0

    target_col = _choose_target(df)
    if target_col is None or target_col not in df.columns:
        accuracy = 0.0
        print(f"ACCURACY={accuracy:.6f}")
        return

    y_raw = df[target_col]
    X_df = df.drop(columns=[target_col], errors="ignore")

    # Build a robust, schema-agnostic feature set:
    # - A hashed bag-of-words representation of all object-like columns (cheap memory, CPU-friendly).
    # - Basic numeric columns (imputed).
    exclude = {target_col}
    text_cols = _pick_text_features(df, exclude=exclude)
    text_series = _build_text_series(df, text_cols=text_cols)

    numeric_cols = []
    for c in X_df.columns:
        if c in text_cols:
            continue
        s = X_df[c]
        if pd.api.types.is_numeric_dtype(s):
            numeric_cols.append(c)
        else:
            # Attempt numeric coercion for mixed types
            coerced = _safe_to_numeric(s)
            if coerced.notna().sum() > 0 and coerced.nunique(dropna=True) >= 2:
                X_df[c] = coerced
                numeric_cols.append(c)

    # Create a modeling frame with explicit 'text' plus numeric columns.
    model_df = pd.DataFrame(index=df.index)
    model_df["__text__"] = text_series
    for c in numeric_cols:
        model_df[c] = _safe_to_numeric(X_df[c])

    # Clean infinities to NaN
    for c in numeric_cols:
        model_df[c] = model_df[c].replace([np.inf, -np.inf], np.nan)

    # Remove rows with missing target
    keep = pd.Series([True] * len(df), index=df.index)
    if y_raw.dtype == "object" or pd.api.types.is_categorical_dtype(y_raw) or pd.api.types.is_bool_dtype(y_raw):
        keep &= y_raw.notna()
    else:
        keep &= _safe_to_numeric(y_raw).notna()

    model_df = model_df.loc[keep].copy()
    y_raw = y_raw.loc[keep].copy()

    assert model_df.shape[0] > 1

    is_clf = _is_classification_target(y_raw)

    # Split (stratify only when feasible)
    stratify = None
    if is_clf:
        y_tmp = y_raw.astype(str).fillna("NA")
        if y_tmp.nunique(dropna=True) >= 2 and (y_tmp.value_counts().min() >= 2):
            stratify = y_tmp

    X_train, X_test, y_train, y_test = train_test_split(
        model_df,
        y_raw,
        test_size=0.2,
        random_state=42,
        stratify=stratify
    )

    assert X_train.shape[0] > 0 and X_test.shape[0] > 0

    # Preprocessing + model
    text_transformer = HashingVectorizer(
        n_features=2**18,  # fixed-size, sparse, avoids vocabulary build; modest CPU/RAM
        alternate_sign=False,
        norm="l2",
        lowercase=True,
        ngram_range=(1, 2),
        stop_words="english"
    )

    numeric_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median"))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ("text", text_transformer, "__text__"),
            ("num", numeric_transformer, numeric_cols),
        ],
        remainder="drop",
        sparse_threshold=0.3
    )

    if is_clf:
        # Ensure labels are clean strings for stable, low-cost classification
        y_train_clean = y_train.astype(str).fillna("NA")
        y_test_clean = y_test.astype(str).fillna("NA")
        if y_train_clean.nunique(dropna=True) < 2:
            # Fallback to trivial baseline
            pred = np.array([y_train_clean.mode().iloc[0]] * len(y_test_clean))
            accuracy = float(accuracy_score(y_test_clean, pred))
        else:
            clf = MultinomialNB(alpha=0.5)
            pipe = Pipeline(steps=[
                ("prep", preprocessor),
                ("model", clf)
            ])
            pipe.fit(X_train, y_train_clean)
            y_pred = pipe.predict(X_test)
            accuracy = float(accuracy_score(y_test_clean, y_pred))
    else:
        # Regression fallback; compute bounded "accuracy" proxy in [0,1] from R^2:
        # acc = clip((R^2 + 1)/2, 0, 1) to keep a stable metric.
        y_train_num = _safe_to_numeric(y_train)
        y_test_num = _safe_to_numeric(y_test)

        # Drop any remaining NaNs in target for regression
        tr_keep = y_train_num.notna()
        te_keep = y_test_num.notna()
        X_train_r = X_train.loc[tr_keep].copy()
        X_test_r = X_test.loc[te_keep].copy()
        y_train_num = y_train_num.loc[tr_keep]
        y_test_num = y_test_num.loc[te_keep]

        if len(y_train_num) < 2 or len(y_test_num) < 1 or y_train_num.nunique() < 2:
            accuracy = 0.0
        else:
            reg = Ridge(alpha=1.0, random_state=42)
            pipe = Pipeline(steps=[
                ("prep", preprocessor),
                ("model", reg)
            ])
            pipe.fit(X_train_r, y_train_num)
            y_pred = pipe.predict(X_test_r)

            y_true = y_test_num.to_numpy()
            y_pred = np.asarray(y_pred)

            ss_res = float(np.sum((y_true - y_pred) ** 2))
            ss_tot = float(np.sum((y_true - np.mean(y_true)) ** 2))
            r2 = 1.0 - (ss_res / ss_tot) if ss_tot > 0 else 0.0
            accuracy = float(np.clip((r2 + 1.0) / 2.0, 0.0, 1.0))

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Used HashingVectorizer instead of TF-IDF to avoid building/storing a vocabulary (lower memory, faster startup; deterministic feature size).
# - Chose MultinomialNB for text classification as a lightweight linear-time baseline on sparse features; Ridge for regression fallback.
# - Employed ColumnTransformer+Pipeline for reproducible preprocessing and to prevent redundant transformations.
# - Kept feature engineering minimal: concatenated available text-like columns; median-imputed numeric columns only.
# - Added robust CSV parsing fallback (default then sep=';' and decimal=',') and column-name normalization to handle unknown schemas.
# - Implemented defensive target selection and safe coercion to numeric with NaN/inf handling to ensure end-to-end execution.
# - For regression fallback, mapped R^2 to a bounded [0,1] proxy accuracy via clip((R^2+1)/2) to keep a stable printed metric.