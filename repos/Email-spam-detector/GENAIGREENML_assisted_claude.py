# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import os
import email
from email import policy
import re
from bs4 import BeautifulSoup
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

def extract_email_content(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            msg = email.message_from_file(f, policy=policy.default)
        sender = msg['From'] or ''
        subject = msg['Subject'] or ''
        body = ''
        if msg.is_multipart():
            for part in msg.walk():
                ctype = part.get_content_type()
                if ctype == 'text/plain':
                    body += part.get_payload(decode=True).decode('utf-8', errors='ignore')
                elif ctype == 'text/html':
                    html = part.get_payload(decode=True).decode('utf-8', errors='ignore')
                    body += BeautifulSoup(html, 'html.parser').get_text()
        else:
            body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')
        urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', body)
        return {
            'sender': sender,
            'subject': subject,
            'body': body,
            'urls': urls,
        }
    except Exception:
        return None

def load_emails(spam_dir, good_dir):
    data = []
    for label, directory in [('spam', spam_dir), ('good', good_dir)]:
        for filename in os.listdir(directory):
            if filename.endswith('.eml'):
                email_data = extract_email_content(os.path.join(directory, filename))
                if email_data:
                    email_data['filename'] = filename
                    email_data['label'] = label
                    data.append(email_data)
    return pd.DataFrame(data)

def train_spam_classifier(df):
    df['text'] = df['subject'].str.cat(df['body'], sep=' ')
    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    X = vectorizer.fit_transform(df['text'])
    y = df['label']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = MultinomialNB()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")
    return model, vectorizer

if __name__ == "__main__":
    spam_dir = "emails/spam"
    good_dir = "emails/good"
    df = load_emails(spam_dir, good_dir)
    model, vectorizer = train_spam_classifier(df)

# OPTIMIZATION SUMMARY
# 1. Merged two directory-loading loops into one to reduce code duplication and overhead.
# 2. Used str.cat for string concatenation instead of element-wise '+' for efficiency.
# 3. Removed all print statements except the required accuracy output.
# 4. Removed CSV saving, sample prediction, and classification_report to avoid unnecessary I/O and computation.
# 5. Removed plot/visualization code (none present) and interactive inputs.
# 6. Stored content type in a local variable to avoid repeated method calls.
# 7. Suppressed error printing in extract_email_content to avoid unnecessary I/O.