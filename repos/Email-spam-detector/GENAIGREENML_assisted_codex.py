# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
import random
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

DATASET_PATH = "email_analysis.csv"
DATASET_HEADERS = "sender,subject,body,urls,filename,label,text"
RANDOM_SEED = 42

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)

def needs_fallback(df, expected_headers):
    if df is None or df.shape[1] <= 1:
        return True
    cols = {str(c).strip().lower() for c in df.columns}
    matches = sum(1 for h in expected_headers if h.lower() in cols)
    return matches == 0

def read_dataset(path, expected_headers):
    try:
        df = pd.read_csv(path, dtype=str)
    except Exception:
        df = pd.read_csv(path, sep=';', decimal=',', dtype=str)
        return df
    if needs_fallback(df, expected_headers):
        df = pd.read_csv(path, sep=';', decimal=',', dtype=str)
    return df

def prepare_text_and_labels(df):
    cols = {str(c).strip().lower(): c for c in df.columns}
    label_col = cols.get('label')
    if label_col is None:
        raise ValueError("Label column not found in dataset.")
    subject_col = cols.get('subject')
    body_col = cols.get('body')
    text_col = cols.get('text')
    if subject_col is not None and body_col is not None:
        subject = df[subject_col].fillna('')
        body = df[body_col].fillna('')
        text = subject.astype(str) + ' ' + body.astype(str)
    elif text_col is not None:
        text = df[text_col].fillna('').astype(str)
    elif body_col is not None:
        text = df[body_col].fillna('').astype(str)
    elif subject_col is not None:
        text = df[subject_col].fillna('').astype(str)
    else:
        raise ValueError("No suitable text columns found in dataset.")
    labels = df[label_col].fillna('').astype(str)
    return text, labels

def train_and_evaluate(texts, labels, seed):
    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    X = vectorizer.fit_transform(texts)
    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=seed)
    model = MultinomialNB()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

def main():
    set_seed(RANDOM_SEED)
    expected_headers = [h.strip() for h in DATASET_HEADERS.split(',') if h.strip()]
    df = read_dataset(DATASET_PATH, expected_headers)
    texts, labels = prepare_text_and_labels(df)
    accuracy = train_and_evaluate(texts, labels, RANDOM_SEED)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Streamlined the workflow to use the provided CSV directly, eliminating costly .eml parsing and extra I/O.
# - Added robust CSV loading with delimiter fallback and string dtypes to reduce parsing overhead and ensure reliability.
# - Built text features only from necessary columns and removed redundant report/prediction steps to save computation.
# - Fixed random seeds and deterministic split for stable, reproducible results.