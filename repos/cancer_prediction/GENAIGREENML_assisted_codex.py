# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


def load_data(path, feature_names):
    usecols = ["diagnosis", *feature_names]
    df = pd.read_csv(path, usecols=usecols)
    y = df["diagnosis"].map({"M": 1, "B": 0}).to_numpy(dtype="int8")
    X = df[feature_names].to_numpy()
    return X, y


def train_evaluate(X, y):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    scaler = StandardScaler(copy=False)
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    model = LogisticRegression(solver="liblinear", random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)


def main():
    feature_names = [
        "texture_worst",
        "radius_se",
        "symmetry_worst",
        "concave points_mean",
        "area_se",
        "area_worst",
        "radius_worst",
        "concave points_worst",
        "concavity_mean",
        "fractal_dimension_se",
    ]
    try:
        X, y = load_data("Cancer_Data.csv", feature_names)
    except FileNotFoundError:
        raise SystemExit
    accuracy = train_evaluate(X, y)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# - Loaded only required columns to cut I/O and memory usage
# - Converted target and features to NumPy once to reduce dataframe overhead
# - Used in-place scaling (copy=False) and variable reuse to minimize extra copies
# - Removed unused evaluation, plotting, and persistence steps to reduce computation