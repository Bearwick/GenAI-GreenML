# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import glob
import re
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.dummy import DummyClassifier
from sklearn.metrics import accuracy_score, r2_score

def find_csv():
    preferred = ['Cancer_Data.csv', 'cancer_data.csv', 'breast_cancer.csv', 'data.csv']
    for p in preferred:
        if os.path.isfile(p):
            return p
    csvs = sorted(glob.glob("*.csv"))
    if csvs:
        return csvs[0]
    return None

def robust_read(path):
    if path is None:
        raise FileNotFoundError("No CSV file found")
    try:
        df = pd.read_csv(path)
    except Exception:
        df = pd.read_csv(path, sep=';', decimal=',')
        return df
    if df.shape[1] == 1:
        try:
            df2 = pd.read_csv(path, sep=';', decimal=',')
            if df2.shape[1] > 1:
                df = df2
        except Exception:
            pass
    return df

def choose_target(df):
    cols = list(df.columns)
    lower_map = {c.lower(): c for c in cols}
    preferred = ['diagnosis', 'target', 'label', 'class', 'outcome', 'y']
    for p in preferred:
        if p in lower_map:
            return lower_map[p]
    numeric_candidates = []
    for c in cols:
        s = df[c]
        if s.dtype.kind in 'biufc':
            numeric_candidates.append(c)
        else:
            s_num = pd.to_numeric(s, errors='coerce')
            if s_num.notna().mean() > 0.8:
                numeric_candidates.append(c)
    for c in numeric_candidates:
        if df[c].nunique(dropna=True) > 1:
            return c
    for c in cols:
        if df[c].nunique(dropna=True) > 1:
            return c
    return cols[0] if cols else None

csv_path = find_csv()
df = robust_read(csv_path)

df.columns = [re.sub(r'\s+', ' ', str(c).strip()) for c in df.columns]
drop_cols = [c for c in df.columns if str(c).lower().startswith('unnamed')]
if drop_cols:
    df = df.drop(columns=drop_cols)
df = df.dropna(axis=1, how='all')

assert df.shape[0] > 0 and df.shape[1] > 0

target_col = choose_target(df)
if target_col is None:
    target_col = df.columns[-1]

feature_cols = [c for c in df.columns if c != target_col]
id_like = [c for c in feature_cols if c.lower() == 'id' or c.lower().endswith(' id')]
if id_like and len(feature_cols) > len(id_like):
    feature_cols = [c for c in feature_cols if c not in id_like]

if len(feature_cols) == 0:
    df['_dummy'] = 1.0
    feature_cols = ['_dummy']

numeric_cols = []
categorical_cols = []
for col in feature_cols:
    s = df[col]
    if s.dtype.kind in 'biufc':
        df[col] = pd.to_numeric(s, errors='coerce')
        numeric_cols.append(col)
    else:
        s_num = pd.to_numeric(s, errors='coerce')
        if s_num.notna().mean() >= 0.8:
            df[col] = s_num
            numeric_cols.append(col)
        else:
            categorical_cols.append(col)

if numeric_cols:
    df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)

y_raw = df[target_col]
n_samples = len(df)
n_unique = y_raw.nunique(dropna=True)

if y_raw.dtype.kind in 'biufc':
    if n_unique <= max(20, int(0.1 * n_samples)):
        problem = 'classification'
    else:
        problem = 'regression'
else:
    problem = 'classification'

if problem == 'classification':
    if y_raw.dtype.kind in 'biufc':
        y_proc = pd.to_numeric(y_raw, errors='coerce')
    else:
        y_proc = pd.Series(pd.factorize(y_raw.astype(str))[0], index=df.index)
    mask = y_raw.notna() & y_proc.notna()
else:
    y_proc = pd.to_numeric(y_raw, errors='coerce')
    mask = y_proc.notna()

df = df.loc[mask].reset_index(drop=True)
y_proc = y_proc.loc[mask].reset_index(drop=True)

df = df.dropna(axis=1, how='all')
feature_cols = [c for c in feature_cols if c in df.columns]
numeric_cols = [c for c in numeric_cols if c in feature_cols]
categorical_cols = [c for c in categorical_cols if c in feature_cols]

if len(feature_cols) == 0:
    df['_dummy'] = 1.0
    feature_cols = ['_dummy']
    numeric_cols = ['_dummy']
    categorical_cols = []

assert len(df) > 0

if len(df) == 1:
    df = pd.concat([df, df], ignore_index=True)
    y_proc = pd.concat([y_proc, y_proc], ignore_index=True)

X = df[feature_cols]

n_samples = len(df)
test_size = max(1, int(round(0.2 * n_samples)))
if n_samples - test_size < 1:
    test_size = n_samples - 1
if test_size < 1:
    test_size = 1

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

transformers = []
if numeric_cols:
    transformers.append(('num', numeric_transformer, numeric_cols))
if categorical_cols:
    transformers.append(('cat', categorical_transformer, categorical_cols))
if not transformers:
    transformers = [('num', numeric_transformer, feature_cols)]

preprocess = ColumnTransformer(transformers=transformers, remainder='drop')

if problem == 'classification':
    n_unique = y_proc.nunique(dropna=True)
    if n_unique >= 2:
        model = LogisticRegression(solver='liblinear', max_iter=200)
    else:
        model = DummyClassifier(strategy='most_frequent')
    clf = Pipeline(steps=[('preprocess', preprocess), ('model', model)])
    stratify = None
    if n_unique >= 2:
        vc = y_proc.value_counts()
        if vc.min() >= 2:
            stratify = y_proc
    try:
        X_train, X_test, y_train, y_test = train_test_split(X, y_proc, test_size=test_size, random_state=42, stratify=stratify)
    except ValueError:
        X_train, X_test, y_train, y_test = train_test_split(X, y_proc, test_size=test_size, random_state=42, stratify=None)
    assert len(X_train) > 0 and len(X_test) > 0
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
else:
    model = Ridge(alpha=1.0)
    reg = Pipeline(steps=[('preprocess', preprocess), ('model', model)])
    X_train, X_test, y_train, y_test = train_test_split(X, y_proc, test_size=test_size, random_state=42)
    assert len(X_train) > 0 and len(X_test) > 0
    reg.fit(X_train, y_train)
    y_pred = reg.predict(X_test)
    if len(y_test) >= 2:
        r2 = r2_score(y_test, y_pred)
        if np.isnan(r2) or np.isinf(r2):
            r2 = 0.0
        accuracy = max(0.0, min(1.0, (r2 + 1.0) / 2.0))
    else:
        mae = float(np.mean(np.abs(y_test - y_pred)))
        denom = float(np.mean(np.abs(y_test)) + 1e-9)
        score = 1.0 - min(1.0, mae / (denom + 1e-9))
        accuracy = max(0.0, min(1.0, score))

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# Used lightweight linear models with simple preprocessing to minimize CPU and energy usage.
# Applied robust CSV parsing and schema-agnostic feature/target selection for reproducible end-to-end execution.
# Regression fallback maps R2 to a bounded [0,1] proxy to provide a stable accuracy-like metric without heavy evaluation overhead.