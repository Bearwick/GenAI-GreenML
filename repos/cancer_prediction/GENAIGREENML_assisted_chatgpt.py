# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
from typing import List, Tuple

import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

SEED = 42


def set_reproducibility(seed: int = SEED) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


DATASET_HEADERS: List[str] = [
    "id",
    "diagnosis",
    "radius_mean",
    "texture_mean",
    "perimeter_mean",
    "area_mean",
    "smoothness_mean",
    "compactness_mean",
    "concavity_mean",
    "concave points_mean",
    "symmetry_mean",
    "fractal_dimension_mean",
    "radius_se",
    "texture_se",
    "perimeter_se",
    "area_se",
    "smoothness_se",
    "compactness_se",
    "concavity_se",
    "concave points_se",
    "symmetry_se",
    "fractal_dimension_se",
    "radius_worst",
    "texture_worst",
    "perimeter_worst",
    "area_worst",
    "smoothness_worst",
    "compactness_worst",
    "concavity_worst",
    "concave points_worst",
    "symmetry_worst",
    "fractal_dimension_worst",
]


def _looks_misparsed(df: pd.DataFrame) -> bool:
    if df.empty or df.shape[1] <= 2:
        return True
    if df.shape[1] == 1:
        return True
    cols = [str(c) for c in df.columns]
    if len(cols) == 1 and ("," in cols[0] or ";" in cols[0]):
        return True
    return False


def load_csv_with_fallback(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if _looks_misparsed(df):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def resolve_columns(df: pd.DataFrame, dataset_headers: List[str]) -> Tuple[str, List[str]]:
    header_set = set(dataset_headers)
    cols_present = [c for c in df.columns if c in header_set]

    diagnosis_candidates = [c for c in cols_present if c.lower() == "diagnosis"]
    if not diagnosis_candidates:
        diagnosis_candidates = [c for c in df.columns if str(c).strip().lower() == "diagnosis"]
    if not diagnosis_candidates:
        raise ValueError("Target column 'diagnosis' not found in dataset.")
    target_col = diagnosis_candidates[0]

    requested_features = [
        "texture_worst",
        "radius_se",
        "symmetry_worst",
        "concave points_mean",
        "area_se",
        "area_worst",
        "radius_worst",
        "concave points_worst",
        "concavity_mean",
        "fractal_dimension_se",
    ]
    features = [f for f in requested_features if f in df.columns]
    missing = [f for f in requested_features if f not in df.columns]
    if missing:
        raise ValueError(f"Missing required feature columns: {missing}")
    return target_col, features


def prepare_xy(df: pd.DataFrame, target_col: str, feature_cols: List[str]) -> Tuple[pd.DataFrame, pd.Series]:
    y = df[target_col]
    if y.dtype == object or str(y.dtype).startswith("string"):
        y = y.map({"M": 1, "B": 0})
    y = pd.to_numeric(y, errors="coerce")

    X = df.loc[:, feature_cols]
    X = X.apply(pd.to_numeric, errors="coerce")

    valid_mask = y.notna()
    for col in feature_cols:
        valid_mask &= X[col].notna()

    X = X.loc[valid_mask]
    y = y.loc[valid_mask].astype(int)
    return X, y


def train_and_evaluate(X: pd.DataFrame, y: pd.Series, seed: int = SEED) -> float:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=seed
    )

    model = make_pipeline(
        StandardScaler(with_mean=True, with_std=True),
        LogisticRegression(solver="liblinear", random_state=seed),
    )
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return float(accuracy_score(y_test, y_pred))


def main() -> None:
    set_reproducibility(SEED)
    df = load_csv_with_fallback("Cancer_Data.csv")
    target_col, feature_cols = resolve_columns(df, DATASET_HEADERS)
    X, y = prepare_xy(df, target_col, feature_cols)
    accuracy = train_and_evaluate(X, y, SEED)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed plotting, report generation, and model/scaler serialization to eliminate unnecessary compute and I/O energy use.
# - Used a single Pipeline (StandardScaler + LogisticRegression) to avoid extra intermediate arrays and reduce data movement.
# - Avoided redundant DataFrame copies by selecting only required columns once and filtering invalid rows via a single boolean mask.
# - Implemented robust CSV parsing fallback to prevent repeated manual reruns and wasted computation due to mis-parsed inputs.
# - Ensured reproducibility with fixed seeds, stabilizing results and avoiding energy spent on repeated experimentation.