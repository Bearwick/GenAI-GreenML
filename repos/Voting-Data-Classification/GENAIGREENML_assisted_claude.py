# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

df = pd.read_csv("voting_data.csv", encoding="UTF-8")
if df.shape[1] < 2:
    df = pd.read_csv("voting_data.csv", sep=";", decimal=",", encoding="UTF-8")

text_col = df.columns[0]
label_col = df.columns[1]

feature = df[text_col]
labels = df[label_col]

train_x, test_x, train_y, test_y = train_test_split(
    feature, labels, train_size=0.75, test_size=0.25, random_state=RANDOM_SEED
)

tf = TfidfVectorizer()
train_x_vec = tf.fit_transform(train_x)
test_x_vec = tf.transform(test_x)

linearsvm = LinearSVC(random_state=RANDOM_SEED, dual="auto")
linearsvm.fit(train_x_vec, train_y)

pred_y = linearsvm.predict(test_x_vec)
accuracy = accuracy_score(test_y, pred_y)

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Removed unused imports (csv, os, pickle, sys, graphviz, matplotlib, IPython, joblib, GaussianNB, KNeighborsClassifier, DecisionTreeClassifier, etc.)
# - Removed all example/demo functions (naivebayes, linsupvec, knearneighbor) that were not part of the core task
# - Removed interactive sys.argv parsing and replaced with direct dataset loading
# - Removed saving of model artifacts (SVM.pkl, tfidf.pkl) to avoid unnecessary disk I/O
# - Removed all print statements (classification report, confusion matrix, cross-validation) except final accuracy
# - Removed plots and visualizations
# - Set fixed random seeds for reproducibility in train_test_split and LinearSVC
# - Used robust CSV fallback: tries default separator first, falls back to semicolon
# - Derived column names from actual dataframe columns instead of hardcoding
# - Used dual="auto" in LinearSVC to let sklearn pick the efficient solver based on data dimensions
# - Minimized memory footprint by not storing intermediate structures or redundant predictions