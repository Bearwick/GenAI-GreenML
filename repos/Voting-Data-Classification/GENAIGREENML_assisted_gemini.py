# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score
import sys

def load_data(filepath):
    try:
        df = pd.read_csv(filepath)
        if len(df.columns) < 2:
            raise ValueError
    except Exception:
        df = pd.read_csv(filepath, sep=';', decimal=',')
    
    if 'text' not in df.columns or 'label' not in df.columns:
        df.columns = ['text', 'label']
    return df

def main():
    dataset_path = "voting_data.csv"
    
    try:
        df = load_data(dataset_path)
    except Exception:
        return

    x = df['text'].values.astype('U')
    y = df['label']

    x_train, x_test, y_train, y_test = train_test_split(
        x, y, train_size=0.75, test_size=0.25, random_state=42
    )

    tfidf = TfidfVectorizer(sublinear_tf=True)
    x_train_tfidf = tfidf.fit_transform(x_train)
    x_test_tfidf = tfidf.transform(x_test)

    model = LinearSVC(random_state=42, tol=1e-4)
    model.fit(x_train_tfidf, y_train)
    
    predictions = model.predict(x_test_tfidf)
    accuracy = accuracy_score(y_test, predictions)

    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# 1. Removed unused and heavy dependencies (matplotlib, graphviz, IPython, joblib, pickle) to reduce memory and startup energy.
# 2. Replaced repetitive prediction calls and redundant scoring logic with a single accuracy calculation.
# 3. Eliminated disk I/O operations (saving/loading .pkl files) to reduce energy consumption and runtime.
# 4. Implemented robust CSV parsing with fallbacks to handle different delimiters efficiently without manual intervention.
# 5. Fixed random seeds (random_state=42) in train_test_split and LinearSVC to ensure reproducible results and avoid unnecessary re-runs.
# 6. Streamlined the workflow by removing experimental/unused model code (kNN, Decision Trees, Naive Bayes on cancer data).
# 7. Applied sublinear_tf=True in TfidfVectorizer, which often improves convergence and performance in LinearSVC for text tasks.
# 8. Minimized data movement by converting the feature column to a NumPy array of Unicode strings early in the process.
# 9. Removed all plotting, extensive logging, and diagnostic prints to focus compute resources strictly on training and evaluation.
# 10. Simplified the logic from a CLI-based multi-mode system to a direct, end-to-end execution path.