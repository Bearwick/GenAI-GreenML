# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import sys
from typing import Tuple

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC


SEED = 42


def _set_reproducible(seed: int = SEED) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def _read_csv_robust(path: str, expected_headers: Tuple[str, ...]) -> pd.DataFrame:
    df = pd.read_csv(path)
    if not set(expected_headers).issubset(df.columns) or df.shape[1] < len(expected_headers):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _resolve_columns(df: pd.DataFrame, expected_headers: Tuple[str, ...]) -> Tuple[str, str]:
    lower_map = {c.lower(): c for c in df.columns}
    text_col = lower_map.get(expected_headers[0], None)
    label_col = lower_map.get(expected_headers[1], None)

    if text_col is None or label_col is None:
        candidates = [c for c in df.columns if pd.api.types.is_string_dtype(df[c]) or df[c].dtype == object]
        if len(candidates) >= 2:
            text_col = text_col or candidates[0]
            label_col = label_col or candidates[1]
        else:
            text_col = df.columns[0]
            label_col = df.columns[1] if len(df.columns) > 1 else df.columns[0]
    return text_col, label_col


def _prepare_data(df: pd.DataFrame, text_col: str, label_col: str) -> Tuple[pd.Series, pd.Series]:
    x = df[text_col].astype(str).fillna("")
    y = df[label_col]
    return x, y


def train_and_evaluate(csv_path: str) -> float:
    df = _read_csv_robust(csv_path, expected_headers=("text", "label"))
    text_col, label_col = _resolve_columns(df, expected_headers=("text", "label"))
    x, y = _prepare_data(df, text_col, label_col)

    x_train, x_test, y_train, y_test = train_test_split(
        x,
        y,
        train_size=0.75,
        test_size=0.25,
        random_state=SEED,
        shuffle=True,
    )

    tfidf = TfidfVectorizer()
    x_train_vec = tfidf.fit_transform(x_train)
    x_test_vec = tfidf.transform(x_test)

    model = LinearSVC(random_state=SEED)
    model.fit(x_train_vec, y_train)

    y_pred = model.predict(x_test_vec)
    return float(accuracy_score(y_test, y_pred))


def main() -> None:
    _set_reproducible(SEED)

    csv_path = "voting_data.csv"
    if len(sys.argv) >= 2 and isinstance(sys.argv[1], str) and sys.argv[1].strip():
        csv_path = sys.argv[1].strip()

    accuracy = train_and_evaluate(csv_path)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused heavy imports (plotting, graphviz, IPython, pickle/joblib, extra models) to cut import time and memory.
# - Eliminated interactive/predict/cross-val branches and all side-effect artifact saving to reduce runtime and I/O energy.
# - Added robust CSV parsing fallback (default read_csv, then retry with ';' and decimal=',') to avoid costly downstream errors.
# - Derived text/label columns from expected headers and actual df.columns (case-insensitive) with safe fallback to avoid hardcoding.
# - Set fixed random seeds and deterministic train/test split via random_state to ensure stable, reproducible results.
# - Avoided redundant predictions and reports; compute only what is needed for the required final accuracy output.
# - Kept sparse TF-IDF matrices end-to-end (no densification) to minimize memory footprint and data movement.