# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split


RANDOM_SEED = 3


def load_csv_robust(path: str, expected_headers):
    df = pd.read_csv(path)
    expected = [h.strip() for h in expected_headers.split(",")]

    def looks_wrong(d):
        if d is None or d.empty:
            return True
        cols = list(map(str, d.columns))
        if any(c in cols for c in expected):
            return False
        if len(cols) == 1:
            col0 = cols[0]
            if ";" in col0:
                return True
        return True

    if looks_wrong(df):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def resolve_columns(df: pd.DataFrame, expected_headers: str):
    expected = [h.strip() for h in expected_headers.split(",")]
    cols = {c.lower(): c for c in df.columns}

    cat_col = cols.get(expected[0].lower())
    msg_col = cols.get(expected[1].lower())

    if cat_col is None:
        for k, v in cols.items():
            if "category" in k or k in ("label", "target", "class"):
                cat_col = v
                break

    if msg_col is None:
        for k, v in cols.items():
            if "message" in k or "text" in k or "content" in k or "email" in k:
                msg_col = v
                break

    if cat_col is None or msg_col is None:
        raise ValueError(f"Could not resolve required columns from df.columns={list(df.columns)}")

    return cat_col, msg_col


def preprocess(df: pd.DataFrame, cat_col: str, msg_col: str):
    df = df[[cat_col, msg_col]].copy()
    df[cat_col] = df[cat_col].fillna("")
    df[msg_col] = df[msg_col].fillna("")
    y = df[cat_col].map({"spam": 0, "ham": 1}).astype(np.int64)
    x = df[msg_col].astype(str)
    return x, y


def train_and_evaluate(x: pd.Series, y: pd.Series, seed: int):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=seed)

    vectorizer = TfidfVectorizer(min_df=1, stop_words="english", lowercase=True)
    x_train_vec = vectorizer.fit_transform(x_train)
    x_test_vec = vectorizer.transform(x_test)

    model = LogisticRegression(random_state=seed)
    model.fit(x_train_vec, y_train)

    y_pred = model.predict(x_test_vec)
    acc = accuracy_score(y_test, y_pred)
    return acc


def main():
    dataset_headers = "Category,Message"
    df = load_csv_robust("mail_data.csv", dataset_headers)
    cat_col, msg_col = resolve_columns(df, dataset_headers)
    x, y = preprocess(df, cat_col, msg_col)
    accuracy = train_and_evaluate(x, y, RANDOM_SEED)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed all non-essential prints, interactive behavior, and the predictive demo to avoid unnecessary compute and I/O while preserving the core train/test evaluation intent.
# - Avoided redundant preprocessing steps (replaced DataFrame.where(pd.notnull) with fillna on only the required columns) to reduce memory use and data movement.
# - Selected and copied only the required columns early to minimize DataFrame footprint and downstream overhead.
# - Ensured robust CSV parsing with a fallback delimiter/decimal retry to prevent costly failures or incorrect schema propagation.
# - Derived column names from provided headers and actual df.columns with lightweight heuristics to avoid hard-coded assumptions.
# - Added fixed random seeds (train_test_split and LogisticRegression) to ensure reproducible, stable results without extra computation.
# - Kept sparse TF-IDF matrices end-to-end (no dense conversion) to reduce memory and energy consumption.