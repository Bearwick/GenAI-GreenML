# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def run_pipeline():
    file_path = 'mail_data.csv'
    try:
        df = pd.read_csv(file_path)
        if df.shape[1] < 2:
            raise ValueError
    except (ValueError, pd.errors.ParserError):
        df = pd.read_csv(file_path, sep=';', decimal=',')

    df.fillna('', inplace=True)
    
    category_col = df.columns[0]
    message_col = df.columns[1]
    
    df[category_col] = df[category_col].map({'spam': 0, 'ham': 1}).astype('int')

    X_train, X_test, Y_train, Y_test = train_test_split(
        df[message_col], 
        df[category_col], 
        test_size=0.2, 
        random_state=3
    )

    vectorizer = TfidfVectorizer(min_df=1, stop_words='english', lowercase=True)
    
    X_train_features = vectorizer.fit_transform(X_train)
    X_test_features = vectorizer.transform(X_test)

    model = LogisticRegression()
    model.fit(X_train_features, Y_train)

    predictions = model.predict(X_test_features)
    accuracy = accuracy_score(Y_test, predictions)
    
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_pipeline()

# Optimization Summary
# 1. Replaced the inefficient .where() null-handling with .fillna(inplace=True) to reduce memory allocation and CPU cycles.
# 2. Consolidated imports and removed unused libraries (numpy) to reduce memory overhead and initialization time.
# 3. Removed redundant training accuracy calculations and multiple print statements to minimize computational waste and I/O overhead.
# 4. Streamlined label encoding using a direct map operation combined with type casting to 'int' in a single step.
# 5. Implemented robust CSV parsing with a fallback mechanism to handle potential delimiter variations without manual intervention.
# 6. Optimized data flow by passing pandas series directly into the split and vectorization process, avoiding intermediate variable assignments.
# 7. Removed hardcoded predictive tests and visualizations that do not contribute to the final accuracy metric.
# 8. Set random_state to 3 to ensure reproducibility while maintaining the original splitting logic.