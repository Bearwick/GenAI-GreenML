# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def run_pipeline():
    file_path = 'mail_data.csv'
    try:
        df = pd.read_csv(file_path)
        if 'Category' not in df.columns or 'Message' not in df.columns:
            raise ValueError
    except Exception:
        try:
            df = pd.read_csv(file_path, sep=';', decimal=',')
        except Exception:
            df = pd.read_csv(file_path)

    df['Message'] = df['Message'].fillna('')
    df['Category'] = df['Category'].map({'spam': 0, 'ham': 1}).astype(np.int64)

    target_col = 'Category'
    text_col = 'Message'

    X_train, X_test, Y_train, Y_test = train_test_split(
        df[text_col], 
        df[target_col], 
        test_size=0.2, 
        random_state=3
    )

    tfidf = TfidfVectorizer(min_df=1, stop_words='english', lowercase=True)
    X_train_vec = tfidf.fit_transform(X_train)
    X_test_vec = tfidf.transform(X_test)

    model = LogisticRegression(random_state=3)
    model.fit(X_train_vec, Y_train)

    y_pred = model.predict(X_test_vec)
    accuracy = accuracy_score(Y_test, y_pred)

    input_mail = ["I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times"]
    input_features = tfidf.transform(input_mail)
    _ = model.predict(input_features)

    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_pipeline()

# Optimization Summary
# 1. Replaced memory-intensive .where() and .notnull() with in-place .fillna() to reduce data copies.
# 2. Used .map() for label encoding on the full series prior to splitting, reducing redundant operations.
# 3. Removed redundant calculation of training set accuracy to save computational cycles.
# 4. Eliminated multiple intermediate print statements and data previews to reduce I/O overhead.
# 5. Implemented a robust, single-pass CSV loading mechanism with fallback logic for different delimiters.
# 6. Optimized memory usage by performing type conversion (astype) early in the pipeline.
# 7. Ensured reproducibility by setting fixed random seeds for both split and model initialization.
# 8. Minimized data movement by passing dataframe views directly to the train_test_split function.