# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: autonomous

import os
import re
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import FunctionTransformer, LabelEncoder
from sklearn.feature_extraction.text import HashingVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score


def _clean_text_series(X):
    s = X["Message"].astype(str)
    s = s.str.lower()
    s = s.str.replace(r"\s+", " ", regex=True).str.strip()
    s = s.str.replace(r"http\S+|www\.\S+", " URL ", regex=True)
    s = s.str.replace(r"\b[\w\.-]+@[\w\.-]+\.\w+\b", " EMAIL ", regex=True)
    s = s.str.replace(r"\b\d+\b", " NUM ", regex=True)
    s = s.str.replace(r"[^a-z\s]+", " ", regex=True)
    s = s.str.replace(r"\s+", " ", regex=True).str.strip()
    return s


def _find_dataset_path():
    candidates = [
        "dataset.csv",
        "data.csv",
        "spam.csv",
        "train.csv",
        "messages.csv",
        "SMSSpamCollection.csv",
        "SMSSpamCollection",
    ]
    for name in candidates:
        if os.path.exists(name) and os.path.isfile(name):
            return name
    csvs = [f for f in os.listdir(".") if f.lower().endswith(".csv")]
    if len(csvs) == 1:
        return csvs[0]
    if len(csvs) > 1:
        for f in csvs:
            try:
                df = pd.read_csv(f, nrows=1)
                cols = [c.strip() for c in df.columns]
                if "Category" in cols and "Message" in cols:
                    return f
            except Exception:
                continue
        return csvs[0]
    raise FileNotFoundError("No dataset file found in current directory.")


def _read_dataset(path):
    try:
        df = pd.read_csv(path)
    except Exception:
        df = pd.read_csv(path, sep="\t", header=None, names=["Category", "Message"])
    df.columns = [c.strip() for c in df.columns]
    if "Category" not in df.columns or "Message" not in df.columns:
        if df.shape[1] >= 2:
            df = df.iloc[:, :2].copy()
            df.columns = ["Category", "Message"]
        else:
            raise ValueError("Dataset must contain Category and Message columns.")
    df = df[["Category", "Message"]].dropna()
    df["Category"] = df["Category"].astype(str).str.strip()
    df["Message"] = df["Message"].astype(str)
    df = df[df["Category"].str.len() > 0]
    df = df[df["Message"].str.len() > 0]
    return df


def main():
    path = _find_dataset_path()
    df = _read_dataset(path)

    le = LabelEncoder()
    y = le.fit_transform(df["Category"].values)
    X = df[["Message"]]

    stratify = y if len(np.unique(y)) > 1 else None
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=42,
        stratify=stratify,
    )

    preprocess = ColumnTransformer(
        transformers=[
            (
                "msg",
                Pipeline(
                    steps=[
                        ("clean", FunctionTransformer(_clean_text_series, validate=False)),
                        (
                            "vec",
                            HashingVectorizer(
                                n_features=2**18,
                                alternate_sign=False,
                                norm="l2",
                                ngram_range=(1, 2),
                                lowercase=False,
                                token_pattern=r"(?u)\b[a-z]{2,}\b",
                            ),
                        ),
                    ]
                ),
                ["Message"],
            )
        ],
        remainder="drop",
        sparse_threshold=1.0,
    )

    clf = SGDClassifier(
        loss="log_loss",
        penalty="l2",
        alpha=1e-5,
        max_iter=1000,
        tol=1e-3,
        random_state=42,
        n_jobs=1,
        average=True,
    )

    model = Pipeline(
        steps=[
            ("preprocess", preprocess),
            ("clf", clf),
        ]
    )

    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    accuracy = accuracy_score(y_test, preds)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# - Uses HashingVectorizer to avoid storing a growing vocabulary, minimizing memory and speeding up training/inference.
# - Employs a linear SGDClassifier (logistic regression via SGD) which is CPU-friendly and efficient for sparse text.
# - Lightweight text cleaning with vectorized pandas string ops; no deep learning or embeddings.
# - Sparse pipeline end-to-end to reduce compute and memory footprint.
# - Single-threaded (n_jobs=1) for predictable, energy-aware CPU execution.