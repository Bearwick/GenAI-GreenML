# Generated by generate_llm_code.py
# LLM: groq
# Mode: autonomous

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import joblib

# --------------------------
# Energy‑efficient spam classifier
# --------------------------
# 1. Lightweight preprocessing: replace NaNs with empty strings.
# 2. TF‑IDF vectorization with a limited feature set (max_features=5000) to keep the model small.
# 3. LogisticRegression with the 'liblinear' solver is fast and works well on sparse data.
# 4. No deep learning or large embeddings; training is done on CPU only.
# 5. Model and vectorizer are persisted for future inference.
# --------------------------

# Load data
data = pd.read_csv('mail_data.csv')

# Replace missing values
data = data.where(pd.notnull(data), '')

# Encode labels: spam → 0, ham → 1
data['Category'] = data['Category'].map({'spam': 0, 'ham': 1}).astype(int)

# Split features and labels
X = data['Message']
y = data['Category']

# Train‑test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Vectorize text
vectorizer = TfidfVectorizer(
    stop_words='english',
    lowercase=True,
    max_features=5000,
    min_df=2
)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train logistic regression
model = LogisticRegression(solver='liblinear', random_state=42)
model.fit(X_train_vec, y_train)

# Evaluate
y_pred = model.predict(X_test_vec)
accuracy = accuracy_score(y_test, y_pred)

# Persist model and vectorizer
joblib.dump((vectorizer, model), 'spam_classifier.joblib')

print(f"ACCURACY={accuracy:.6f}")