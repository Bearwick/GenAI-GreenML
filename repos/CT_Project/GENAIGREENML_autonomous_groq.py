# Generated by generate_llm_code.py
# LLM: groq
# Mode: autonomous

"""
Energy‑efficient spam email classifier.

- TF‑IDF with min_df=2 and sublinear_tf reduces the feature space.
- LogisticRegression with the liblinear solver works directly on sparse matrices and
  converges quickly for binary classification.
- No large embeddings or deep learning components are used.
- The script prints only the final accuracy, keeping I/O minimal.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load the dataset
df = pd.read_csv('mail_data.csv')
df = df.fillna('')

# Encode labels: spam → 0, ham → 1
df['Category'] = df['Category'].map({'spam': 0, 'ham': 1}).astype(int)

X = df['Message']
y = df['Category']

# Train / test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Vectorize text with TF‑IDF (sparse representation)
vectorizer = TfidfVectorizer(
    min_df=2,
    stop_words='english',
    lowercase=True,
    sublinear_tf=True
)

X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train a lightweight logistic regression model
clf = LogisticRegression(
    solver='liblinear',
    penalty='l2',
    C=1.0,
    max_iter=1000
)
clf.fit(X_train_vec, y_train)

# Evaluate on the test set
y_pred = clf.predict(X_test_vec)
acc = accuracy_score(y_test, y_pred)

print(f"ACCURACY={acc:.6f}")