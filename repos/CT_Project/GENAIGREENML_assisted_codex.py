# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import random
import warnings
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

DATASET_HEADERS = "Category,Message"
SEED = 42

def read_csv_with_fallback(path, headers):
    try:
        df = pd.read_csv(path)
    except Exception:
        return pd.read_csv(path, sep=";", decimal=",")
    if needs_fallback(df, headers):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df

def needs_fallback(df, headers):
    if df.shape[1] == 1:
        return True
    cols_lower = [str(c).strip().lower() for c in df.columns]
    expected_lower = [h.strip().lower() for h in headers]
    if not set(expected_lower).issubset(cols_lower):
        if any(";" in str(c) for c in df.columns):
            return True
    return False

def resolve_columns(df, headers):
    cols_lower = {str(c).strip().lower(): c for c in df.columns}
    resolved = [cols_lower.get(h.strip().lower()) for h in headers]
    used = {c for c in resolved if c is not None}
    if any(c is None for c in resolved):
        for i, c in enumerate(resolved):
            if c is None:
                for col in df.columns:
                    if col not in used:
                        resolved[i] = col
                        used.add(col)
                        break
    if any(c is None for c in resolved):
        raise ValueError("Required columns not found")
    return resolved

def main():
    warnings.filterwarnings("ignore")
    np.random.seed(SEED)
    random.seed(SEED)
    headers = [h.strip() for h in DATASET_HEADERS.split(",") if h.strip()]
    df = read_csv_with_fallback("mail_data.csv", headers)
    category_col, message_col = resolve_columns(df, headers)
    df[category_col] = df[category_col].fillna("")
    df[message_col] = df[message_col].fillna("")
    df[category_col] = df[category_col].map({"spam": 0, "ham": 1}).astype("int64")
    X_train, X_test, y_train, y_test = train_test_split(
        df[message_col], df[category_col], test_size=0.2, random_state=3
    )
    vectorizer = TfidfVectorizer(stop_words="english", lowercase=True)
    X_train_features = vectorizer.fit_transform(X_train)
    model = LogisticRegression(random_state=SEED)
    model.fit(X_train_features, y_train)
    y_pred_test = model.predict(vectorizer.transform(X_test))
    accuracy = accuracy_score(y_test, y_pred_test)
    input_mail = ["I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times"]
    _ = model.predict(vectorizer.transform(input_mail))
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed nonessential outputs and redundant computations to lower runtime overhead.
# - Limited missing-value handling to required columns and resolved schema dynamically to reduce data movement.
# - Predicted directly from transformed test data to avoid storing extra feature matrices.
# - Added robust CSV parsing with fallback and fixed seeds for reproducibility.