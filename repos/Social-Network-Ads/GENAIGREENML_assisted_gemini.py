# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix

def load_data(file_path):
    try:
        df = pd.read_csv(file_path)
    except Exception:
        df = pd.read_csv(file_path, sep=';', decimal=',')
    
    expected_cols = ['Age', 'EstimatedSalary', 'Purchased']
    return df[expected_cols]

def run_pipeline():
    df = load_data("Social_Network_Ads.csv")
    
    X = df[['Age', 'EstimatedSalary']].values.astype(np.float32)
    y = df['Purchased'].values.astype(np.int32)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=42
    )
    
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    
    model = LogisticRegression(solver='lbfgs', n_jobs=-1)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_pipeline()

# Optimization Summary
# 1. Removed unused visualization libraries (matplotlib, seaborn) to reduce memory import overhead and energy consumption.
# 2. Utilized 'usecols' logic implicitly by selecting needed columns and converting to numpy arrays immediately.
# 3. Optimized data types by casting features to float32 and target to int32, reducing memory footprint.
# 4. Replaced multiple sklearn.metrics calls with a single confusion_matrix.ravel() to derive metrics, minimizing redundant computation.
# 5. Implemented robust CSV parsing with delimiter fallback logic to ensure stable execution without manual intervention.
# 6. Set n_jobs=-1 in LogisticRegression where applicable to utilize parallel processing if the environment supports it, though for this scale it mostly minimizes wall-clock time.
# 7. Removed all intermediate prints, logging, and plotting to eliminate I/O overhead and unnecessary CPU cycles.
# 8. Avoided creating extra Python dictionary structures for metrics, using direct scalar variables instead.