# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score

# Robust CSV loading
try:
    df = pd.read_csv("Social_Network_Ads.csv")
    if df.shape[1] < 2:
        df = pd.read_csv("Social_Network_Ads.csv", sep=';', decimal=',')
except Exception:
    df = pd.read_csv("Social_Network_Ads.csv", sep=';', decimal=',')

# Normalize column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# Identify target and features
target_col = None
feature_cols = []

# Prefer 'Purchased' as target
for c in df.columns:
    if c.lower() == 'purchased':
        target_col = c
        break

# If no 'Purchased' column, pick last numeric column as target
if target_col is None:
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if len(numeric_cols) >= 1:
        target_col = numeric_cols[-1]

assert target_col is not None, "No suitable target column found."

# Identify feature columns: prefer Age and EstimatedSalary
desired_features = ['Age', 'EstimatedSalary']
for f in desired_features:
    for c in df.columns:
        if c.lower().replace(' ', '') == f.lower().replace(' ', '') and c != target_col:
            feature_cols.append(c)
            break

# Fallback: use all numeric columns except target
if len(feature_cols) == 0:
    feature_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != target_col]

assert len(feature_cols) > 0, "No feature columns available."

# Coerce numeric
for c in feature_cols + [target_col]:
    df[c] = pd.to_numeric(df[c], errors='coerce')

# Drop rows with NaN/inf
df = df.replace([np.inf, -np.inf], np.nan)
df = df.dropna(subset=feature_cols + [target_col])

assert len(df) > 0, "Dataset empty after preprocessing."

X = df[list(feature_cols)]
y = df[target_col]

# Check classification viability
n_classes = y.nunique()
is_classification = n_classes >= 2 and n_classes <= 20

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

assert len(X_train) > 0 and len(X_test) > 0, "Train/test split has no samples."

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

if is_classification:
    model = LogisticRegression(max_iter=200, random_state=42)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    # Confusion matrix metrics
    def compute_metrics(y_true, y_pred):
        cm = confusion_matrix(y_true, y_pred)
        if cm.shape == (2, 2):
            TP = cm[1][1]
            FP = cm[0][1]
            TN = cm[0][0]
            FN = cm[1][0]
            return {"TP": TP, "FP": FP, "TN": TN, "FN": FN}