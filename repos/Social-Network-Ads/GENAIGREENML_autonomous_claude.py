# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score

DATASET_PATH = "Social_Network_Ads.csv"

# Robust CSV loading
try:
    df = pd.read_csv(DATASET_PATH)
    if df.shape[1] < 2:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')
except Exception:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')

# Strip and normalize column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df.loc[:, ~df.columns.str.startswith('Unnamed')]

# Identify columns based on expected schema
expected_target = 'Purchased'
expected_features_numeric = ['Age', 'EstimatedSalary']
expected_features_cat = ['Gender']
expected_drop = ['User ID']

# Drop User ID if present (not predictive)
for col in expected_drop:
    if col in df.columns:
        df = df.drop(columns=[col])

# Determine target
if expected_target in df.columns:
    target_col = expected_target
else:
    # Fallback: pick last column if it looks binary/categorical
    target_col = df.columns[-1]

# Coerce numeric columns
for col in df.columns:
    if col == target_col and df[col].dtype == object:
        continue
    if col in expected_features_cat:
        continue
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Drop rows with NaN in target
df = df.dropna(subset=[target_col])

# Encode target if needed
y = df[target_col].copy()
if y.dtype == object:
    le = LabelEncoder()
    y = pd.Series(le.fit_transform(y), index=y.index)
else:
    y = y.astype(int)

assert y.nunique() >= 2, "Target must have at least 2 classes"

# Identify available feature columns
feature_cols = [c for c in df.columns if c != target_col]

num_features = [c for c in feature_cols if c in expected_features_numeric and df[c].dtype in ['float64', 'int64', 'float32', 'int32']]
cat_features = [c for c in feature_cols if c in expected_features_cat and df[c].dtype == object]

# If expected columns missing, fallback to available numeric
if not num_features:
    num_features = [c for c in feature_cols if df[c].dtype in ['float64', 'int64', 'float32', 'int32']]
if not cat_features:
    cat_features = [c for c in feature_cols if df[c].dtype == object and c not in num_features]

all_features = num_features + cat_features
assert len(all_features) > 0, "No features available"

X = df[list(all_features)].copy()

# Handle NaN/inf in numeric features
for col in num_features:
    X[col] = pd.to_numeric(X[col], errors='coerce')
    X[col] = X[col].replace([np.inf, -np.inf], np.nan)
    median_val = X[col].median()
    X[col] = X[col].fillna(median_val)

# Encode categorical features simply with label encoding (lightweight)
for col in cat_features:
    X[col] = X[col].fillna('missing')
    le_cat = LabelEncoder()
    X[col] = le_cat.fit_transform(X[col])

# Now all features are numeric
all_feature_names = list(all_features)