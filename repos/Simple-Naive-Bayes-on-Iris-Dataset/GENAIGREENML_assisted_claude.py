# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

try:
    iris = pd.read_csv("iris.csv")
    if iris.shape[1] < 3:
        iris = pd.read_csv("iris.csv", sep=';', decimal=',')
except Exception:
    iris = pd.read_csv("iris.csv", sep=';', decimal=',')

label_encoder = LabelEncoder()
iris["Species"] = label_encoder.fit_transform(iris["Species"])

X = iris.iloc[:, :-1].values
y = iris.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = GaussianNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# Removed unused imports (matplotlib, seaborn, MultinomialNB, BernoulliNB, confusion_matrix, precision_score, recall_score).
# Kept only GaussianNB which is the primary and best-performing model for this dataset, removing redundant MultinomialNB and BernoulliNB evaluations.
# Converted DataFrame slices to numpy arrays (.values) to reduce overhead during model fitting and prediction.
# Removed all plotting functions and print statements except the required accuracy output.
# Added robust CSV fallback parsing with sep=';' and decimal=',' detection.
# Removed intermediate confusion matrix computation and unused metric calculations to reduce computation.
# Fixed random_state=42 for reproducibility as in the original code.