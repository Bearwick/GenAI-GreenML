# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder


SEED = 42


def set_reproducibility(seed: int = SEED) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def align_and_validate_schema(df: pd.DataFrame, dataset_headers: list[str]) -> pd.DataFrame:
    header_set = set(dataset_headers)
    df_cols = list(df.columns)

    if not header_set.issubset(set(df_cols)):
        renamed = {}
        for col in df_cols:
            stripped = str(col).strip()
            if stripped in header_set:
                renamed[col] = stripped
        if renamed:
            df = df.rename(columns=renamed)

    missing = [h for h in dataset_headers if h not in df.columns]
    if missing:
        raise ValueError(f"Missing required columns: {missing}")

    return df


def prepare_xy(df: pd.DataFrame, target_col: str) -> tuple[np.ndarray, np.ndarray]:
    le = LabelEncoder()
    y = le.fit_transform(df[target_col].to_numpy())

    feature_cols = [c for c in df.columns if c != target_col]
    X_df = df[feature_cols]

    X = X_df.to_numpy()
    return X, y


def evaluate_three_models(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray) -> float:
    models = (GaussianNB(), MultinomialNB(), BernoulliNB())
    last_acc = 0.0
    for model in models:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        last_acc = accuracy_score(y_test, y_pred)
    return float(last_acc)


def main() -> None:
    set_reproducibility(SEED)

    dataset_path = "iris.csv"
    dataset_headers = ["Id", "SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm", "Species"]

    df = read_csv_robust(dataset_path)
    df = align_and_validate_schema(df, dataset_headers)

    target_col = "Species"
    X, y = prepare_xy(df, target_col)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=SEED
    )

    accuracy = evaluate_three_models(X_train, y_train, X_test, y_test)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed plotting/visualization and all intermediate prints to reduce overhead and runtime while keeping the ML workflow intact.
# - Avoided pandas column slicing with iloc and reused a single NumPy-backed feature matrix/label vector to reduce data movement.
# - Used a compact loop to evaluate the three Naive Bayes models without duplicating evaluation code.
# - Implemented robust CSV parsing with a fallback delimiter/decimal configuration to prevent costly downstream failures/retries.
# - Enforced reproducibility by setting fixed seeds for Python and NumPy and using a fixed random_state in train_test_split.
# - Performed schema validation against provided headers and actual df.columns to avoid hard-coded assumptions and extra preprocessing passes.