# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
import random
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB

DATASET_HEADERS = [
    "Id",
    "SepalLengthCm",
    "SepalWidthCm",
    "PetalLengthCm",
    "PetalWidthCm",
    "Species",
]

def load_dataset(path):
    expected_lower = {h.lower() for h in DATASET_HEADERS}

    def looks_wrong(df):
        if df.shape[1] <= 1:
            return True
        cols_lower = {c.lower() for c in df.columns}
        if len(expected_lower.intersection(cols_lower)) == 0:
            return True
        obj_cols = df.select_dtypes(include=["object"]).columns
        for col in obj_cols:
            if df[col].astype(str).str.contains(",").any():
                return True
        return False

    df = pd.read_csv(path)
    if looks_wrong(df):
        try:
            alt = pd.read_csv(path, sep=";", decimal=",")
            if not looks_wrong(alt) or alt.shape[1] > df.shape[1]:
                df = alt
        except Exception:
            pass
    return df

def prepare_data(df):
    cols = list(df.columns)
    lower_map = {c.lower(): c for c in cols}
    target_col = lower_map.get("species")
    if target_col is None:
        target_col = cols[-1]

    y = df[target_col]
    if not pd.api.types.is_numeric_dtype(y):
        y = pd.factorize(y)[0]

    X = df.drop(columns=[target_col])
    if X.select_dtypes(include=["object"]).shape[1] > 0:
        X = X.replace(",", ".", regex=True)
        X = X.apply(pd.to_numeric, errors="coerce")

    X = X.to_numpy()
    y = np.asarray(y)
    return X, y

def evaluate_models(X_train, X_test, y_train, y_test):
    models = (GaussianNB(), MultinomialNB(), BernoulliNB())
    accuracy = None
    for idx, model in enumerate(models):
        model.fit(X_train, y_train)
        preds = model.predict(X_test)
        acc = float((preds == y_test).mean())
        if idx == 0:
            accuracy = acc
    return accuracy

def main():
    seed = 42
    random.seed(seed)
    np.random.seed(seed)

    df = load_dataset("iris.csv")
    X, y = prepare_data(df)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=seed
    )
    accuracy = evaluate_models(X_train, X_test, y_train, y_test)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed plotting and verbose metric computation to cut unnecessary processing and I/O.
# - Evaluated models in a loop with a single train/test split to avoid redundant data handling.
# - Converted features to NumPy once to prevent repeated DataFrame-to-array conversions.
# - Added robust CSV parsing with delimiter/decimal fallback to avoid mis-parsing and rework.
# - Applied lightweight label encoding only when needed using pandas.factorize.
# - Fixed random seeds for deterministic, reproducible results.