# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
from typing import Tuple, Optional

import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier

from src.preprocessing import preprocess_data


SEED = 42


def _set_reproducible(seed: int = SEED) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path, header=None)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, header=None, sep=";", decimal=",")
    return df


def _fit_pca(X_train: np.ndarray, X_test: np.ndarray, seed: int = SEED) -> Tuple[np.ndarray, np.ndarray, PCA]:
    pca = PCA(n_components=0.95, random_state=seed, svd_solver="full")
    X_train_pca = pca.fit_transform(X_train)
    X_test_pca = pca.transform(X_test)
    return X_train_pca, X_test_pca, pca


def _train_model(X: np.ndarray, y: np.ndarray, seed: int = SEED) -> XGBClassifier:
    model = XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        eval_metric="logloss",
        random_state=seed,
        n_jobs=1,
        tree_method="hist",
        verbosity=0,
    )
    model.fit(X, y)
    return model


def main() -> None:
    _set_reproducible(SEED)

    train_df = _read_csv_robust("data/raw/Train.txt")
    test_df = _read_csv_robust("data/raw/Test.txt")

    X_train_scaled, y_train, scaler, train_columns = preprocess_data(train_df, fit=True)
    X_test_scaled, y_test = preprocess_data(test_df, fit=False, scaler=scaler, columns=train_columns)

    X_train_pca, X_test_pca, _ = _fit_pca(X_train_scaled, X_test_scaled, seed=SEED)

    model = _train_model(X_train_pca, y_train, seed=SEED)

    y_pred = model.predict(X_test_pca)
    accuracy = float(accuracy_score(y_test, y_pred))
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed artifact saving (joblib.dump) and all plotting/extra metrics to eliminate I/O and visualization overhead while keeping the ML task intact.
# - Avoided predict_proba/ROC computations since only final accuracy output is required, reducing unnecessary inference and memory use.
# - Added robust CSV parsing fallback (default read_csv, then retry with sep=';' and decimal=',') to prevent costly downstream failures.
# - Enforced reproducibility with fixed seeds (PYTHONHASHSEED, random, numpy) and deterministic single-thread settings (n_jobs=1) to stabilize results.
# - Used XGBoost 'hist' tree_method (same model family/behavior intent) to reduce training energy/runtime on CPU without changing inputs/outputs.
# - Modularized into small functions to minimize repeated work and keep data flow explicit, reducing accidental redundant computation/data movement.