# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# --- Robust CSV Loading ---
def load_csv_robust(path):
    try:
        df = pd.read_csv(path, header=None)
        if df.shape[1] < 3:
            df = pd.read_csv(path, header=None, sep=';', decimal=',')
    except Exception:
        df = pd.read_csv(path, header=None, sep=';', decimal=',')
    return df

# Try multiple possible paths
data = None
for path in ["data/raw/Train.txt", "Train.txt", "data/Train.txt", "train.txt", "data/raw/train.txt"]:
    try:
        data = load_csv_robust(path)
        break
    except FileNotFoundError:
        continue

if data is None:
    for path in ["data/raw/Test.txt", "Test.txt", "data/Test.txt", "test.txt", "data/raw/test.txt"]:
        try:
            data = load_csv_robust(path)
            break
        except FileNotFoundError:
            continue

if data is None:
    import glob
    txt_files = glob.glob("**/*.txt", recursive=True)
    csv_files = glob.glob("**/*.csv", recursive=True)
    all_files = txt_files + csv_files
    for f in all_files:
        try:
            data = load_csv_robust(f)
            if data.shape[0] > 10 and data.shape[1] > 5:
                break
        except Exception:
            continue

assert data is not None and data.shape[0] > 0, "Could not load dataset"

# --- Determine schema from DATASET_HEADERS ---
# Headers suggest: KDD Cup / NSL-KDD style intrusion detection dataset
# 42 columns: features + label + difficulty_level(last col)
# Columns: duration, protocol_type, service, flag, src_bytes, ..., label, difficulty

ncols = data.shape[1]

# KDD-style dataset typically has 41 features + label (+ optional difficulty)
# The header sample: 0,tcp,ftp_data,SF,491,0,...,normal,20
# Last column appears to be difficulty level, second-to-last is the label

if ncols >= 42:
    target_col = ncols - 2  # 'normal' or attack type
    # Drop the difficulty column
    difficulty_col = ncols - 1
    data = data.drop(columns=[difficulty_col])
    ncols = data.shape[1]
elif ncols >= 2:
    target_col = ncols - 1
else:
    target_col = 0

# --- Strip whitespace from string columns ---
for c in data.columns:
    if data[c].dtype == object:
        data[c] = data[c].astype(str).str.strip()

# --- Separate features and target ---
y_raw = data[target_col].copy()
X = data.drop(columns=[target_col]).copy()

# --- Encode target ---
# For intrusion detection: binary classification (normal vs attack)
# Map all non-'normal' labels to 'attack' for simplicity and efficiency
le = LabelEncoder()

# Binary classification: normal=0, attack=1
y_binary = y_raw.apply(lambda x: 0 if str(x).strip().lower() == 'normal' else 1)

# Check if we have at least 2 classes
n_classes = y_binary.nunique()
if n_classes < 2:
    # Try multiclass instead
    y_encoded = le.fit_transform(y_raw.astype(str))
    n_classes = len(le.classes_)
    use_binary = False
else:
    y_encoded = y_binary.values