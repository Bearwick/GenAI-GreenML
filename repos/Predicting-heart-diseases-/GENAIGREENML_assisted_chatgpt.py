# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
from typing import Tuple

import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split


SEED = 0
DATASET_PATH = "heart/heart_dataset_.csv"
DATASET_HEADERS = [
    "age",
    "sex",
    "cp",
    "trestbps",
    "chol",
    "fbs",
    "restecg",
    "thalach",
    "exang",
    "oldpeak",
    "slope",
    "ca",
    "thal",
    "target",
]


def set_reproducible(seed: int = SEED) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def read_csv_robust(path: str, expected_headers: list) -> pd.DataFrame:
    df = pd.read_csv(path)
    looks_wrong = (df.shape[1] == 1) or (len(set(expected_headers).intersection(df.columns)) < 2)
    if looks_wrong:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def align_schema(df: pd.DataFrame, expected_headers: list) -> pd.DataFrame:
    cols = list(df.columns)
    if "target" not in cols:
        if df.shape[1] == len(expected_headers):
            df.columns = expected_headers
        else:
            raise ValueError("Could not find 'target' column and schema could not be aligned.")
    return df


def minmax_scale_trainstyle(X: pd.DataFrame) -> pd.DataFrame:
    X_min = X.min(axis=0)
    X_max = X.max(axis=0)
    denom = X_max - X_min
    denom = denom.replace(0, 1)
    return (X - X_min) / denom


def prepare_xy(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
    y = df["target"].to_numpy()
    X = df.drop(columns=["target"])
    X_scaled = minmax_scale_trainstyle(X)
    return X_scaled.to_numpy(dtype=np.float64, copy=False), y


def train_and_eval_logreg(X: np.ndarray, y: np.ndarray, seed: int = SEED) -> float:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)
    model = LogisticRegression(solver="lbfgs", random_state=seed, max_iter=1000)
    model.fit(X_train, y_train)
    return float(model.score(X_test, y_test))


def main() -> None:
    set_reproducible(SEED)
    df = read_csv_robust(DATASET_PATH, DATASET_HEADERS)
    df = align_schema(df, DATASET_HEADERS)

    X, y = prepare_xy(df)
    accuracy = train_and_eval_logreg(X, y, SEED)

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed all plotting/EDA and auxiliary models to eliminate heavy, redundant computation while preserving the trained/evaluated model behavior (logistic regression on min-max scaled features with the same split seed).
# - Avoided unnecessary transposes by keeping data in (n_samples, n_features) layout throughout, reducing data movement and memory overhead.
# - Implemented lightweight, vectorized min-max scaling with safe handling for constant columns to prevent extra preprocessing objects and copies.
# - Added robust CSV parsing fallback (default read_csv, then retry with sep=';' and decimal=',') to prevent misparsing without manual intervention.
# - Enforced reproducibility via fixed seeds for Python/NumPy and model/split random_state, and set PYTHONHASHSEED for stable hashing behavior.
# - Reduced imports to only required libraries to lower startup time and memory footprint.