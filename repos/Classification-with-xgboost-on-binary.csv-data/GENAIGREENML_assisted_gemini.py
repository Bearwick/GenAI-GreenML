# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

df = pd.read_csv('xgboost_on _binary.csv')

df_encoded = pd.get_dummies(df, columns=['rank'], drop_first=True)

X = df_encoded.drop('admit', axis=1)
y = df_encoded['admit']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = XGBClassifier(
    random_state=42, 
    n_jobs=1, 
    use_label_encoder=False, 
    eval_metric='logloss'
)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Removed redundant EDA (head, info, describe, pairplots, boxplots) to minimize compute and memory usage.
# 2. Eliminated unused library imports (seaborn, matplotlib, os) to reduce runtime overhead.
# 3. Consolidated preprocessing by removing redundant LabelEncoder calls before using pd.get_dummies.
# 4. Reduced data movement by avoiding multiple intermediate DataFrame copies and unnecessary prints.
# 5. Set n_jobs=1 in XGBClassifier to prevent CPU threading overhead on a small-scale dataset.
# 6. Simplified the target variable extraction by avoiding one-hot encoding the binary label.
# 7. Optimized memory footprint by dropping unused columns early in the pipeline.