# Generated by generate_llm_code_2.py
# LLM: gemini
# Mode: autonomous

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

def run_pipeline():
    try:
        df = pd.read_csv('xgboost_on _binary.csv')
    except FileNotFoundError:
        return

    df = df.dropna()

    X = df[['gre', 'gpa', 'rank']]
    y = df['admit']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = LogisticRegression(
        solver='lbfgs',
        max_iter=1000,
        tol=1e-4,
        n_jobs=1
    )
    
    model.fit(X_train_scaled, y_train)
    
    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_pipeline()

"""
DESIGN JUSTIFICATION FOR ENERGY EFFICIENCY:

1. Algorithm Choice: Logistic Regression was selected over XGBoost or Deep Learning. 
   It is a linear model with extremely low computational complexity (O(n_features * n_samples)), 
   minimizing CPU cycles and memory usage during both training and inference.

2. Feature Engineering: Avoided high-cardinality transformations. By treating 'rank' 
   as a numerical/ordinal feature and scaling continuous inputs (GRE/GPA), 
   we ensure rapid convergence of the optimization algorithm (L-BFGS).

3. Hardware Utilization: The model runs natively on a single CPU core. It avoids 
   the overhead of GPU initialization or multi-process management, which often 
   consumes more energy than the computation itself for datasets of this scale.

4. Library Efficiency: Used scikit-learn's optimized C-based implementations 
   rather than custom loops or heavy frameworks like TensorFlow/PyTorch, 
   reducing the overall software footprint.
"""