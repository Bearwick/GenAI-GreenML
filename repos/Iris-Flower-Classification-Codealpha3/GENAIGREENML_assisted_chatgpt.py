# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder


SEED = 42
DATASET_PATH = "Iris.csv"
DATASET_HEADERS = ["Id", "SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm", "Species"]


def _read_csv_with_fallback(path: str, expected_cols: int) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] != expected_cols:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def load_and_prepare_data(path: str) -> tuple[pd.DataFrame, np.ndarray]:
    df = _read_csv_with_fallback(path, expected_cols=len(DATASET_HEADERS))

    cols = df.columns
    if "Id" in cols:
        df = df.drop(columns=["Id"])

    if "Species" not in df.columns:
        raise ValueError("Target column 'Species' not found in dataset.")

    df = df.copy()
    le = LabelEncoder()
    y = le.fit_transform(df["Species"].to_numpy())
    X = df.drop(columns=["Species"])

    return X, y


def train_and_evaluate(X: pd.DataFrame, y: np.ndarray) -> float:
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=SEED,
        stratify=y,
    )

    model = RandomForestClassifier(
        n_estimators=100,
        random_state=SEED,
        n_jobs=-1,
    )
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    return float(accuracy_score(y_test, y_pred))


def main() -> None:
    np.random.seed(SEED)
    X, y = load_and_prepare_data(DATASET_PATH)
    accuracy = train_and_evaluate(X, y)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed plotting/visualization and all non-required logging to reduce runtime and avoid extra compute.
# - Added robust CSV parsing fallback (default read_csv, then retry with sep=';' and decimal=',') to prevent costly failures/retries outside the script.
# - Avoided in-place dataframe mutation patterns that can create hidden copies; performed a single explicit copy only where needed for encoding.
# - Reduced unnecessary data movement by converting the target column directly to a NumPy array before label encoding.
# - Enabled parallelism for RandomForest with n_jobs=-1 to reduce wall-clock time (often lowering energy by finishing sooner for the same work).
# - Centralized seed control (NumPy + model/train_test_split random_state) to ensure reproducible, stable results.