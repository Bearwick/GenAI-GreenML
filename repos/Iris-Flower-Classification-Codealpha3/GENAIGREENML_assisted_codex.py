# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier

DATASET_HEADERS = ["Id", "SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm", "Species"]
SEED = 42


def _normalize(value):
    return str(value).strip().lower()


EXPECTED_HEADERS_NORM = {_normalize(h) for h in DATASET_HEADERS}
ID_KEY = next((h for h in DATASET_HEADERS if _normalize(h) == "id"), "id")
SPECIES_KEY = next((h for h in DATASET_HEADERS if _normalize(h) == "species"), "species")
ID_KEY_NORM = _normalize(ID_KEY)
SPECIES_KEY_NORM = _normalize(SPECIES_KEY)


def _parse_ok(df):
    if df.shape[1] <= 1:
        return False
    cols_norm = {_normalize(c) for c in df.columns}
    return len(cols_norm & EXPECTED_HEADERS_NORM) >= min(3, len(EXPECTED_HEADERS_NORM))


def load_data(path):
    df = pd.read_csv(path)
    if not _parse_ok(df):
        df_alt = pd.read_csv(path, sep=";", decimal=",")
        if _parse_ok(df_alt):
            df = df_alt
    return df


def main():
    np.random.seed(SEED)
    df = load_data("Iris.csv")
    col_map = {_normalize(c): c for c in df.columns}
    id_col = col_map.get(ID_KEY_NORM)
    if id_col in df.columns:
        df.pop(id_col)
    species_col = col_map.get(SPECIES_KEY_NORM)
    if species_col not in df.columns:
        species_col = df.columns[-1]
    y = LabelEncoder().fit_transform(df.pop(species_col))
    X = df.to_numpy()
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=SEED, stratify=y
    )
    model = RandomForestClassifier(n_estimators=100, random_state=SEED)
    model.fit(X_train, y_train)
    accuracy = model.score(X_test, y_test)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Eliminated plotting, classification reports, and cross-validation to avoid non-essential computation and I/O.
# - Reduced imports and used model.score to compute accuracy without storing prediction arrays.
# - Used in-place column removal with pop and a single NumPy conversion to limit data copies.
# - Implemented robust CSV parsing with delimiter/decimal fallback and case-insensitive column mapping.
# - Fixed random seed for deterministic and reproducible results.