# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load dataset - try common paths for Iris dataset
import os
data_path = None
for candidate in ["dataset.csv", "data.csv", "Iris.csv", "iris.csv", "train.csv"]:
    if os.path.exists(candidate):
        data_path = candidate
        break

if data_path is None:
    from sklearn.datasets import load_iris
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=["SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm"])
    df["Species"] = iris.target
    label_already_encoded = True
else:
    df = pd.read_csv(data_path)
    label_already_encoded = False

# Drop Id column if present (not a feature)
if "Id" in df.columns:
    df = df.drop(columns=["Id"])

# Separate features and target
feature_cols = ["SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm"]
X = df[feature_cols].values
y = df["Species"].values

# Encode labels if they are strings
le = LabelEncoder()
if not label_already_encoded:
    y = le.fit_transform(y)

# Train/test split with stratification for balanced evaluation
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# StandardScaler for consistent feature scaling - lightweight O(n) operation
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Logistic Regression: lightweight, interpretable, ideal for small tabular classification
# Using lbfgs solver which is efficient for small datasets with few classes
model = LogisticRegression(
    solver="lbfgs",
    max_iter=200,
    multi_class="multinomial",
    random_state=42,
    C=1.0
)
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Model choice: Logistic Regression - extremely lightweight, trains in milliseconds on CPU,
#    ideal for the small Iris dataset (150 samples, 4 features, 3 classes).
# 2. Preprocessing: StandardScaler is O(n) and ensures features are on comparable scales,
#    improving convergence speed of the linear solver.
# 3. No deep learning or complex ensembles needed - Iris is linearly separable for most classes,
#    so a linear model achieves near-perfect accuracy with minimal energy consumption.
# 4. Solver lbfgs is memory-efficient and well-suited for small multinomial problems.
# 5. Stratified split ensures representative class distribution in both train and test sets.