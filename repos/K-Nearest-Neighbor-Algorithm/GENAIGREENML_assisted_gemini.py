# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier

def load_data(filename):
    try:
        df = pd.read_csv(filename)
        if df.shape[1] < 2:
            raise ValueError
    except:
        df = pd.read_csv(filename, sep=';', decimal=',')
    
    df = df.apply(pd.to_numeric, errors='coerce').dropna()
    
    X = df.iloc[:, 1:].values.astype(np.float32)
    y = df.iloc[:, 0].values.astype(np.int32)
    return X, y

def main():
    train_file = "MNIST_train.csv"
    test_file = "MNIST_test.csv"
    
    try:
        X_train, y_train = load_data(train_file)
        X_test, y_test = load_data(test_file)
    except:
        return

    knn = KNeighborsClassifier(
        n_neighbors=7, 
        weights='distance', 
        algorithm='auto', 
        n_jobs=-1
    )
    knn.fit(X_train, y_train)
    
    predictions = knn.predict(X_test)
    
    accuracy_percentage = np.mean(predictions == y_test) * 100
    
    print(f"ACCURACY={accuracy_percentage:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# 1. Vectorized Operations: Replaced manual Python loops for Euclidean distance with Scikit-learn's optimized C-backend, reducing runtime from O(N*D) to highly efficient vectorized routines.
# 2. Algorithmic Efficiency: Utilized Scikit-learn's 'auto' algorithm which employs KD-Trees or Ball-Trees to reduce search complexity from linear O(N) to logarithmic O(log N) per query.
# 3. Fast I/O: Replaced line-by-line file parsing with Pandas read_csv for high-speed data ingestion and robust schema handling.
# 4. Memory Footprint: Converted data to float32 and int32 types to reduce memory consumption compared to native Python objects and lists.
# 5. Parallel Processing: Enabled n_jobs=-1 to utilize all available CPU cores for distance calculations, minimizing total wall-clock energy consumption.
# 6. Redundancy Removal: Eliminated expensive list operations (del, max, remove) inside nested loops used in the original KNN implementation.
# 7. Preprocessing Simplification: Replaced manual string-to-int conversion loops with vectorized Pandas/NumPy type casting.