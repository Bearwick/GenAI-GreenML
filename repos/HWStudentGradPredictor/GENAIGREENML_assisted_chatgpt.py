# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score


DATASET_PATH = "data/students_graduate_predict.csv"
DATASET_HEADERS = "Marital status;Application mode;Application order;Daytime/evening attendance;Previous qualification;Previous qualification (grade);Nacionality;Mother's qualification;Father's qualification;Mother's occupation;Father's occupation;Admission grade;Displaced;Educational special needs;Debtor;Tuition fees up to date;Gender;Scholarship holder;Age at enrollment;International;Curricular units 1st sem (credited);Curricular units 1st sem (enrolled);Curricular units 1st sem (evaluations);Curricular units 1st sem (approved);Curricular units 1st sem (grade);Curricular units 1st sem (without evaluations);Curricular units 2nd sem (credited);Curricular units 2nd sem (enrolled);Curricular units 2nd sem (evaluations);Curricular units 2nd sem (approved);Curricular units 2nd sem (grade);Curricular units 2nd sem (without evaluations);Unemployment rate;Inflation rate;GDP;Graduated (target)"


def _read_csv_robust(path: str) -> pd.DataFrame:
    df_default = pd.read_csv(path)
    expected_cols = len(DATASET_HEADERS.split(";"))

    def looks_wrong(df: pd.DataFrame) -> bool:
        if df.shape[1] == 1:
            return True
        if df.shape[1] != expected_cols:
            first_col = str(df.columns[0])
            if ";" in first_col:
                return True
        return False

    if looks_wrong(df_default):
        df_alt = pd.read_csv(path, sep=";", decimal=",")
        if df_alt.shape[1] >= 2:
            return df_alt
    return df_default


def _coerce_numeric_inplace(df: pd.DataFrame) -> pd.DataFrame:
    obj_cols = df.select_dtypes(include=["object"]).columns
    if len(obj_cols):
        for c in obj_cols:
            s = df[c]
            if s.notna().any() and s.astype(str).str.contains(",", regex=False).any():
                df[c] = pd.to_numeric(s.astype(str).str.replace(",", ".", regex=False), errors="coerce")
            else:
                df[c] = pd.to_numeric(s, errors="coerce")
    return df


def main() -> None:
    seed = 1
    np.random.seed(seed)

    df = _read_csv_robust(DATASET_PATH)
    df = _coerce_numeric_inplace(df)

    headers = [h.strip() for h in DATASET_HEADERS.split(";")]
    target_col = "Graduated (target)"

    if target_col not in df.columns:
        lower_map = {str(c).strip().lower(): c for c in df.columns}
        if target_col.lower() in lower_map:
            target_col = lower_map[target_col.lower()]
        else:
            candidates = [c for c in df.columns if "graduated" in str(c).lower() and "target" in str(c).lower()]
            if candidates:
                target_col = candidates[0]
            else:
                raise KeyError("Target column not found in dataset.")

    feature_cols = [c for c in df.columns if c != target_col]
    if not feature_cols:
        raise ValueError("No feature columns found after removing target.")

    X = df[feature_cols].to_numpy(dtype=np.float32, copy=False)
    y = df[target_col].to_numpy(copy=False)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.15, random_state=seed
    )

    model = MLPClassifier(hidden_layer_sizes=(5, 7), max_iter=800, random_state=seed)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed all plotting/visualization and intermediate DataFrame displays to eliminate unnecessary CPU/GPU work and memory use.
# - Avoided redundant predictions and metric computations; only compute what is required for final accuracy output.
# - Implemented robust CSV parsing with a fallback delimiter/decimal strategy to prevent costly mis-parse cascades and manual intervention.
# - Converted feature matrix to NumPy float32 with copy=False to reduce memory footprint and data movement while preserving model behavior.
# - Used direct NumPy arrays for train/test split and model training to avoid extra pandas overhead.
# - Set fixed random seeds (NumPy and model) and deterministic split random_state for reproducible results.