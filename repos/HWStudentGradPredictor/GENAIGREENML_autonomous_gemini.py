# Generated by generate_llm_code.py
# LLM: gemini
# Mode: autonomous

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('data.csv', sep=';')

X = df.drop(columns=['Graduated (target)'])
y = df['Graduated (target)']

le = LabelEncoder()
y = le.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

model = HistGradientBoostingClassifier(
    max_iter=100,
    max_depth=6,
    learning_rate=0.1,
    early_stopping=True,
    n_iter_no_change=10,
    random_state=42
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Energy-Efficient Algorithm: HistGradientBoostingClassifier was selected because it uses histogram-based binning, which reduces the number of split points to evaluate, significantly lowering CPU cycles and energy consumption compared to standard Gradient Boosting.
# 2. Avoidance of Heavy Libraries: The solution uses Scikit-Learn and Pandas, avoiding deep learning frameworks (PyTorch/TensorFlow) that incur high initialization costs and require more computational resources.
# 3. Early Stopping: Implemented 'early_stopping' and 'n_iter_no_change' to truncate the training process as soon as performance plateaus, preventing unnecessary hardware utilization.
# 4. Memory Management: Target labels were processed using LabelEncoder to maintain a compact numeric representation instead of memory-intensive one-hot encoding.
# 5. Low Computational Overhead: The model is constrained with 'max_depth' to prevent the creation of overly complex trees, which reduces both training time and inference latency on CPU.
# 6. Lightweight Pipeline: The design avoids complex feature engineering and embeddings, ensuring the preprocessing stage is computationally inexpensive and easily reproducible.