# Generated by generate_llm_code.py
# LLM: groq
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

def is_sick(x: int) -> int:
    return 0 if x in (3, 7) else 1

def load_dataset() -> pd.DataFrame:
    cols = [
        "age",
        "sex",
        "chest pain",
        "resting blood pressure",
        "serum cholesterol",
        "fasting blood sugar",
        "resting electrocardiographic results",
        "maximum heart rate achieved",
        "exercise induced angina",
        "ST depression induced by exercise relative to rest",
        "the slope of the peak exercise ST segment",
        "number of major vessels ",
        "thal",
        "last",
    ]
    df = pd.read_csv("heart.csv", delimiter=" ", names=cols, header=None)
    df = df.iloc[:, :13]
    df["label"] = df["thal"].apply(is_sick)
    return df

def main() -> None:
    df = load_dataset()
    X = df.drop(columns=["label", "thal"])
    y = df["label"]

    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.5,
        random_state=12345,
        stratify=y,
    )

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    model = RandomForestClassifier(
        n_estimators=200,
        random_state=12345,
        n_jobs=-1,
    )
    model.fit(X_train, y_train)

    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)

    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()
"""
Optimizations applied:
1. Replaced Spark with scikit-learn and pandas for lightweight data handling.
2. Removed all unnecessary imports, plots, and interactive input.
3. Avoided intermediate Spark DataFrames; used NumPy arrays directly for scaling and modeling.
4. Used a fixed random seed for reproducibility and stratified split to preserve class distribution.
5. Employed `n_jobs=-1` in RandomForest to utilize all CPU cores efficiently, reducing runtime.
6. Eliminated redundant transformations and intermediate variables to lower memory usage.
7. Simplified label creation with a single helper function. 
"""