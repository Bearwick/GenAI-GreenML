# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import numpy as np

FILE_NAME = "iris.csv"
LABEL_MAP = {b"setosa": 0.0, b"versicolor": 1.0, b"virginica": 2.0}


def _label_converter(s, m=LABEL_MAP):
    return m[s.strip()]


def load_iris(file_name):
    data = np.loadtxt(
        file_name,
        delimiter=",",
        skiprows=1,
        usecols=(2, 3, 4),
        converters={4: _label_converter},
    )
    return data[:, :2], data[:, 2]


def compute_centroids(features, labels, num_classes):
    centroids = np.empty((num_classes, features.shape[1]), dtype=features.dtype)
    for i in range(num_classes):
        centroids[i] = features[labels == i].mean(axis=0)
    return centroids


def distance_matrix_sq(features, centroids, centroids_sq):
    features_sq = np.sum(features * features, axis=1, keepdims=True)
    return features_sq + centroids_sq - 2.0 * (features @ centroids.T)


def main():
    features, labels = load_iris(FILE_NAME)
    centroids = compute_centroids(features, labels, 3)
    centroids_sq = np.sum(centroids * centroids, axis=1)
    sample = np.array([3.1, 1.2], dtype=features.dtype)
    sample_dist_sq = float(sample @ sample) + centroids_sq - 2.0 * (sample @ centroids.T)
    predicted_class = int(np.argmin(sample_dist_sq))
    dist_sq = distance_matrix_sq(features, centroids, centroids_sq)
    y_pred = np.argmin(dist_sq, axis=1)
    accuracy = np.mean(y_pred == labels)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# - Loaded only required columns and converted labels during parsing to avoid object arrays and extra casts.
# - Removed plotting and SciPy dependency, using NumPy-only vectorized squared-distance calculations.
# - Reused centroid norms for both sample and dataset distances to reduce redundant computations.