# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import numpy as np
from scipy.spatial.distance import cdist

def main():
    file_path = 'iris.csv'
    
    try:
        data = np.genfromtxt(file_path, delimiter=',', dtype=str, skip_header=1)
        if data.ndim < 2 or data.shape[1] < 5:
            data = np.genfromtxt(file_path, delimiter=';', dtype=str, skip_header=1)
    except:
        data = np.genfromtxt(file_path, delimiter=';', dtype=str, skip_header=1)

    X_str = data[:, 2:4]
    if X_str.size > 0 and ',' in X_str[0, 0]:
        X = np.char.replace(X_str, ',', '.').astype(float)
    else:
        X = X_str.astype(float)

    y_str = np.char.strip(data[:, -1])
    y = np.zeros(len(y_str), dtype=int)
    y[y_str == 'versicolor'] = 1
    y[y_str == 'virginica'] = 2

    centroids = np.array([X[y == i].mean(axis=0) for i in range(3)])

    distances = cdist(X, centroids, metric='euclidean')
    y_pred = np.argmin(distances, axis=1)

    accuracy = np.mean(y_pred == y)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# 1. Replaced memory-intensive 'object' type loading with optimized numpy.genfromtxt for faster I/O and lower memory footprint.
# 2. Eliminated all matplotlib dependencies and visualization logic to remove significant CPU and memory overhead.
# 3. Streamlined feature extraction by directly targeting petal length and width (indices 2, 3) used in the classification task.
# 4. Utilized vectorized numpy operations for label encoding and class mean (centroid) calculations to avoid explicit loops.
# 5. Used scipy.spatial.distance.cdist for efficient, low-level C implementation of Euclidean distance computations across the dataset.
# 6. Removed all intermediate console logging and side-effect file saves to minimize energy consumption.
# 7. Implemented a robust data loading fallback mechanism to handle different CSV separators and decimal formats without redundant checks.