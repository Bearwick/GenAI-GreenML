# Generated by generate_llm_code_2.py
# LLM: groq
# Mode: assisted

import numpy as np
import pandas as pd

def read_and_normalize(path: str):
    df = pd.read_csv(path)
    X = df.iloc[:, :-1].to_numpy(dtype=np.float32)
    y = df.iloc[:, -1].to_numpy()
    mean = X.mean(axis=0)
    std = X.std(axis=0)
    return (X - mean) / std, y

def knn_predict(X_train, y_train, X_test, y_test, k: int):
    n_test = X_test.shape[0]
    output = []
    correct = 0
    for i in range(n_test):
        dist = np.linalg.norm(X_train - X_test[i], axis=1)
        idx = np.argpartition(dist, k)[:k]
        neighbors = y_train[idx]
        pos = np.count_nonzero(neighbors == 'tested_positive')
        neg = k - pos
        assigned = 'tested_positive' if pos >= neg else 'tested_negative'
        output.append([i + 1, neg, pos, assigned])
        if y_test[i] == assigned:
            correct += 1
    return output, correct

def main():
    k = 1
    X_train, y_train = read_and_normalize('Data/Diabetes-Training.csv')
    X_test, y_test = read_and_normalize('Data/Diabetes-Clasification.csv')
    results, correct = knn_predict(X_train, y_train, X_test, y_test, k)
    pd.DataFrame(
        results, columns=['Instance', 'tested_negative', 'tested_positive', 'Assigned class']
    ).to_csv('result_count.csv', index=False)
    accuracy = correct / len(y_test)
    print(f"ACCURACY={accuracy:.6f}")
    print("The file has been generated succesfully!")
    print(f"Percentage of correctly guessed instances: {accuracy*100:.2f} %")

if __name__ == "__main__":
    main()

# Optimizations applied:
# 1. Vectorized distance calculation with np.linalg.norm instead of Python loops.
# 2. argpartition used to find k nearest neighbors in O(n) time rather than full sort.
# 3. Eliminated redundant data structures; all operations performed in-place on numpy arrays.
# 4. Removed interactive input and any printouts unrelated to accuracy.
# 5. Simplified data reading and normalization into a single function.
# 6. Avoided intermediate lists for distances, directly computing counts.
# 7. Used lightweight numpy operations to reduce CPU and memory usage.