# Generated by generate_llm_code.py
# LLM: groq
# Mode: assisted

import numpy as np
import pandas as pd

def load_csv(path: str) -> pd.DataFrame:
    return pd.read_csv(path)

def normalize(df: pd.DataFrame) -> np.ndarray:
    X = df.iloc[:, :-1]
    return (X - X.mean()) / X.std()

def knn_predict(X_train: np.ndarray, y_train: np.ndarray,
                X_test: np.ndarray, k: int = 1) -> list:
    predictions = []
    for x in X_test:
        dists = np.linalg.norm(X_train - x, axis=1)
        idx = np.argpartition(dists, k)[:k]
        neighbors = y_train[idx]
        pos = np.sum(neighbors == 'tested_positive')
        neg = k - pos
        pred = 'tested_positive' if pos >= neg else 'tested_negative'
        predictions.append((neg, pos, pred))
    return predictions

def write_csv(results: list) -> None:
    df = pd.DataFrame(results, columns=[
        "Instance", "tested_negative", "tested_positive", "Assigned class"])
    df.to_csv("result_count.csv", index=False)

def main() -> None:
    k = 1
    train_df = load_csv("Data/Diabetes-Training.csv")
    test_df = load_csv("Data/Diabetes-Clasification.csv")

    X_train = normalize(train_df).astype(np.float32)
    y_train = train_df["class"].values
    X_test = normalize(test_df).astype(np.float32)
    y_test = test_df["class"].values

    pred_data = knn_predict(X_train, y_train, X_test, k)
    results = [(i + 1, neg, pos, pred) for i, (neg, pos, pred) in enumerate(pred_data)]

    correct = sum(1 for (_, _, _, pred), true in zip(pred_data, y_test) if pred == true)
    accuracy = correct / len(y_test)

    write_csv(results)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()