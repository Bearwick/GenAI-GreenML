# Generated by generate_llm_code.py
# LLM: groq
# Mode: autonomous

# Energy‑efficient machine‑learning solution for diabetes classification
# ---------------------------------------------------------------
# Design choices:
# 1. Use a lightweight linear model (LogisticRegression) instead of large neural nets.
# 2. Standardize features with StandardScaler – fast and low‑memory.
# 3. No interactive prompts or visualisations; only a concise accuracy print.
# 4. Persist the trained pipeline with joblib for quick reuse.
# ---------------------------------------------------------------
import pandas as pd
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def load_and_preprocess(train_path: str, test_path: str):
    """Load datasets, encode labels and standardise numeric features."""
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)

    # Separate features and labels
    X_train = train_df.drop(columns=['class']).values
    y_train = train_df['class'].map({'tested_negative': 0, 'tested_positive': 1}).values
    X_test = test_df.drop(columns=['class']).values
    y_test = test_df['class'].map({'tested_negative': 0, 'tested_positive': 1}).values

    # Standardise features using training data statistics
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    return X_train, y_train, X_test, y_test, scaler

def train_and_evaluate(X_train, y_train, X_test, y_test):
    """Train a Logistic Regression model and compute accuracy."""
    model = LogisticRegression(
        solver='liblinear',
        max_iter=200,
        random_state=42
    )
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    acc = accuracy_score(y_test, predictions)
    return model, acc

def main():
    # Paths to the provided datasets
    train_csv = 'Data/Diabetes-Training.csv'
    test_csv = 'Data/Diabetes-Clasification.csv'

    X_train, y_train, X_test, y_test, scaler = load_and_preprocess(train_csv, test_csv)

    model, accuracy = train_and_evaluate(X_train, y_train, X_test, y_test)

    # Persist the scaler and model together for future inference
    joblib.dump({'scaler': scaler, 'model': model}, 'diabetes_model.joblib')

    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()