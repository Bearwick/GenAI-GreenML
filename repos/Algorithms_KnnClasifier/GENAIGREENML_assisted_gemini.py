# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np

def load_data(path):
    try:
        df = pd.read_csv(path)
        if df.shape[1] < 2:
            raise ValueError
    except (ValueError, pd.errors.ParserError):
        df = pd.read_csv(path, sep=';', decimal=',')
    return df

def process_sets(df):
    features = df.iloc[:, :-1]
    labels = df.iloc[:, -1].values
    norm_features = (features - features.mean()) / features.std()
    return norm_features.values, labels

def run_knn():
    np.random.seed(42)
    k = 1

    train_df = load_data('Data/Diabetes-Training.csv')
    test_df = load_data('Data/Diabetes-Clasification.csv')

    x_train, y_train = process_sets(train_df)
    x_test, y_test = process_sets(test_df)

    results = []
    correct = 0
    
    for i in range(len(x_test)):
        distances = np.linalg.norm(x_train - x_test[i], axis=1)
        
        nearest_indices = np.argpartition(distances, k)[:k]
        nearest_labels = y_train[nearest_indices]
        
        neg_count = np.count_nonzero(nearest_labels == 'tested_negative')
        pos_count = np.count_nonzero(nearest_labels == 'tested_positive')
        
        assigned = 'tested_negative' if neg_count > pos_count else 'tested_positive'
        
        results.append([i + 1, neg_count, pos_count, assigned])
        if assigned == y_test[i]:
            correct += 1

    pd.DataFrame(results, columns=["Instance", "tested_negative", "tested_positive", "Assigned class"]).to_csv('result_count.csv', index=False)
    
    accuracy = correct / len(y_test)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_knn()

# Optimization Summary
# 1. Vectorized distance calculation: Replaced the manual loop and custom Euclidean function with NumPy's linalg.norm for significant speedup.
# 2. Optimized neighbor selection: Used np.argpartition instead of full sorting, reducing complexity from O(N log N) to O(N).
# 3. Efficient normalization: Simplified preprocessing using vectorized Pandas operations to reduce computational overhead.
# 4. Memory management: Avoided creating intermediate dictionary structures and large lists of tuples inside the KNN loop.
# 5. Robust IO: Implemented a fallback mechanism for CSV parsing to handle different delimiters and decimal formats automatically.
# 6. Green coding: Reduced CPU cycles and runtime by minimizing Python-level loops and maximizing low-level C-optimized NumPy operations.