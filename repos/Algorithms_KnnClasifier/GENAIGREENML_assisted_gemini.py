# Generated by ./scripts/generate_llm_code.sh
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np

def load_processed_data(file_path):
    df = pd.read_csv(file_path)
    features_df = df.iloc[:, :-1]
    labels = df.iloc[:, -1].values
    
    mean_val = features_df.mean()
    std_val = features_df.std()
    normalized_features = (features_df - mean_val) / std_val
    
    return normalized_features.values, labels

def run_classifier():
    k = 1
    
    try:
        x_train, y_train = load_processed_data('Data/Diabetes-Training.csv')
        x_test, y_test = load_processed_data('Data/Diabetes-Clasification.csv')
    except FileNotFoundError:
        return

    n_test = len(x_test)
    results = []
    correct_hits = 0

    for i in range(n_test):
        test_instance = x_test[i]
        
        distances_sq = np.sum((x_train - test_instance)**2, axis=1)
        
        nearest_indices = np.argpartition(distances_sq, k)[:k]
        nearest_labels = y_train[nearest_indices]
        
        neg_count = np.count_nonzero(nearest_labels == 'tested_negative')
        pos_count = np.count_nonzero(nearest_labels == 'tested_positive')
        
        assigned_class = 'tested_negative' if neg_count > pos_count else 'tested_positive'
        
        results.append([i + 1, neg_count, pos_count, assigned_class])
        
        if assigned_class == y_test[i]:
            correct_hits += 1

    pd.DataFrame(results, columns=["Instance", "tested_negative", "tested_positive", "Assigned class"]).to_csv('result_count.csv', index=False)
    
    accuracy = correct_hits / n_test
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_classifier()

# Applied Optimizations:
# 1. Vectorization: Replaced Python loops for distance calculations with NumPy broadcasting, significantly reducing runtime and energy consumption.
# 2. Algorithmic Efficiency: Switched from a full sort (O(N log N)) to np.argpartition (O(N)) to identify the k-nearest neighbors.
# 3. Mathematical Simplification: Removed the redundant np.sqrt() from Euclidean distance calculations, as squared distances provide the same relative ordering.
# 4. Memory Management: Avoided creating large intermediate lists of tuples for distance storage, reducing the application's memory footprint.
# 5. Preprocessing Streamlining: Consolidated data loading and normalization to minimize redundant data movement and object creation.
