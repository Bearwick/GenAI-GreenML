# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd


RANDOM_SEED = 42


DATASET_HEADERS = ["preg", "plas", "pres", "skin", "insu", "mass", "pedi", "age", "class"]


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] != len(DATASET_HEADERS):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _normalize_features(df: pd.DataFrame, label_col: str) -> np.ndarray:
    feature_cols = [c for c in df.columns if c != label_col]
    x = df.loc[:, feature_cols].to_numpy(dtype=np.float32, copy=False)
    mean = x.mean(axis=0, dtype=np.float64)
    std = x.std(axis=0, ddof=1, dtype=np.float64)
    std = np.where(std == 0, 1.0, std)
    x = (x - mean) / std
    return x.astype(np.float32, copy=False)


def _knn_predict_k1(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    n_test = X_test.shape[0]
    pred = np.empty(n_test, dtype=object)
    neg_count = np.empty(n_test, dtype=np.int32)
    pos_count = np.empty(n_test, dtype=np.int32)

    for i in range(n_test):
        diff = X_train - X_test[i]
        d2 = np.einsum("ij,ij->i", diff, diff, optimize=True)
        nn_idx = int(np.argmin(d2))
        nn_label = y_train[nn_idx]
        if nn_label == "tested_negative":
            neg_count[i] = 1
            pos_count[i] = 0
            pred[i] = "tested_negative"
        else:
            neg_count[i] = 0
            pos_count[i] = 1
            pred[i] = "tested_positive"
    return pred, neg_count, pos_count


def algorithm() -> float:
    np.random.seed(RANDOM_SEED)

    train_df = _read_csv_robust("Data/Diabetes-Training.csv")
    test_df = _read_csv_robust("Data/Diabetes-Clasification.csv")

    label_col = "class" if "class" in train_df.columns else train_df.columns[-1]

    X_train = _normalize_features(train_df, label_col)
    y_train = train_df[label_col].to_numpy(copy=False)
    X_test = _normalize_features(test_df, label_col)
    y_test = test_df[label_col].to_numpy(copy=False)

    pred, neg_count, pos_count = _knn_predict_k1(X_train, y_train, X_test)

    accuracy = float((pred == y_test).mean())

    out_df = pd.DataFrame(
        {
            "Instance": np.arange(1, len(pred) + 1, dtype=np.int32),
            "tested_negative": neg_count,
            "tested_positive": pos_count,
            "Assigned class": pred,
        }
    )
    out_df.to_csv("result_count.csv", index=False)

    return accuracy


if __name__ == "__main__":
    accuracy = algorithm()
    print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Removed per-neighbor Python loops and sorting by specializing to k=1 (original behavior uses k_value=1), using argmin on squared distances.
# - Avoided sqrt in Euclidean distance (argmin of squared distance is equivalent), reducing compute.
# - Reduced redundant data movement by converting features once to NumPy arrays with copy=False and using float32 to lower memory bandwidth/footprint.
# - Used einsum for efficient row-wise squared distance accumulation and kept operations vectorized inside the tight loop.
# - Implemented robust CSV parsing with a fallback delimiter/decimal configuration to prevent mis-parsing without manual intervention.
# - Derived label column from df.columns (prefers 'class' else last column) to avoid hard-coded schema assumptions.
# - Ensured reproducibility by setting a fixed NumPy random seed (even though the algorithm is deterministic).