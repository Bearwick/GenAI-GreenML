# Generated by generate_llm_code.py
# LLM: gemini
# Mode: autonomous

"""
Justification for Energy-Efficient Design:
1. Model Selection: Logistic Regression is utilized instead of KNN. KNN has an inference complexity of O(N*D), 
   requiring the entire dataset to be stored and scanned for every prediction. Logistic Regression 
   has O(D) complexity and only stores a small weight vector, significantly reducing CPU cycles and memory energy.
2. Library Optimization: Scikit-learn is used to leverage vectorized operations and optimized C/Cython backends, 
   which are more energy-efficient than manual Python loops for distance calculations and data normalization.
3. Preprocessing: A streamlined StandardScaler pipeline is used to minimize redundant computations.
4. Hardware: The solution is designed for CPU execution, avoiding the high idle power consumption of GPUs 
   for a task that does not require massive parallelism.
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def run_pipeline():
    try:
        train_data = pd.read_csv('Data/Diabetes-Training.csv')
        test_data = pd.read_csv('Data/Diabetes-Clasification.csv')

        X_train = train_data.iloc[:, :-1]
        y_train = train_data.iloc[:, -1]
        X_test = test_data.iloc[:, :-1]
        y_test = test_data.iloc[:, -1]

        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        model = LogisticRegression(solver='lbfgs', max_iter=1000)
        model.fit(X_train_scaled, y_train)

        predictions = model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, predictions)

        print(f"ACCURACY={accuracy:.6f}")
    except FileNotFoundError:
        pass

if __name__ == "__main__":
    run_pipeline()