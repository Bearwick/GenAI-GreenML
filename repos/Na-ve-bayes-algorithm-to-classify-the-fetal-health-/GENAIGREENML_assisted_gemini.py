# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

try:
    df = pd.read_csv("fetal_health.csv")
except Exception:
    df = pd.read_csv("fetal_health.csv", sep=';', decimal=',')

target_col = df.columns[-1]
X = df.drop(columns=[target_col])
y = df[target_col]

_, x_test, _, y_test = train_test_split(
    X, 
    y, 
    test_size=0.3, 
    random_state=8
)

model = GaussianNB()
model.fit(X, y.values.ravel())
y_pred = model.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# 1. Removed redundant disk I/O operations by eliminating the unnecessary writing and reading of 'TestData.csv'.
# 2. Optimized memory footprint by using existing in-memory data structures for prediction instead of reloading from storage.
# 3. Streamlined data preprocessing by using positional slicing and column dropping to isolate features and targets efficiently.
# 4. Reduced computational overhead by removing unused split variables (x_train, y_train) and intermediate data structures.
# 5. Implemented robust CSV parsing with fallback logic to ensure stable execution without manual adjustments.
# 6. Minimized data movement across the system by processing the entire pipeline within memory, reducing energy consumption.