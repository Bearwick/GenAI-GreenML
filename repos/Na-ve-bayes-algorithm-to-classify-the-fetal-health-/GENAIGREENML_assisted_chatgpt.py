# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import numpy as np
import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


SEED = 8
DATASET_PATH = "fetal_health.csv"
DATASET_HEADERS = [
    "baseline value",
    "accelerations",
    "fetal_movement",
    "uterine_contractions",
    "light_decelerations",
    "severe_decelerations",
    "prolongued_decelerations",
    "abnormal_short_term_variability",
    "mean_value_of_short_term_variability",
    "percentage_of_time_with_abnormal_long_term_variability",
    "mean_value_of_long_term_variability",
    "histogram_width",
    "histogram_min",
    "histogram_max",
    "histogram_number_of_peaks",
    "histogram_number_of_zeroes",
    "histogram_mode",
    "histogram_mean",
    "histogram_median",
    "histogram_variance",
    "histogram_tendency",
    "fetal_health",
]


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if _parsing_looks_wrong(df):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _parsing_looks_wrong(df: pd.DataFrame) -> bool:
    if df.shape[1] <= 2:
        return True
    if df.shape[1] == 1:
        return True
    if df.shape[1] != len(DATASET_HEADERS):
        if df.shape[1] > 0 and any("," in str(c) for c in df.columns):
            return True
    return False


def _resolve_target_column(df: pd.DataFrame) -> str:
    candidates = ["fetal_health", "Fetal_health", "Fetal_Health", "target", "Target", "class", "Class", "label", "Label"]
    for c in candidates:
        if c in df.columns:
            return c
    last_col = df.columns[-1]
    if str(last_col).strip().lower().replace(" ", "_") == "fetal_health":
        return last_col
    return last_col


def main() -> None:
    np.random.seed(SEED)

    if not os.path.exists(DATASET_PATH):
        raise FileNotFoundError(f"Dataset not found at path: {DATASET_PATH}")

    df = _read_csv_robust(DATASET_PATH)

    target_col = _resolve_target_column(df)
    X = df.drop(columns=[target_col], errors="ignore")
    y = df[target_col]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=SEED, shuffle=True
    )

    model = GaussianNB()
    model.fit(X, np.asarray(y).ravel())
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred) * 100.0
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed disk I/O for intermediate test data (no to_csv/read_csv roundtrip); use X_test directly to avoid redundant parsing and data movement.
# - Avoided creating unused train split variables for fitting (kept split only for evaluation) while preserving original behavior of fitting on full dataset.
# - Used y as a Series (instead of a single-column DataFrame) and ravel only once to reduce memory overhead and conversions.
# - Added robust CSV parsing fallback (default read_csv, then retry with sep=';' and decimal=',') to prevent misparsed data and reruns.
# - Centralized target-column resolution based on actual df.columns to avoid hard-coded schema assumptions and prevent extra preprocessing.
# - Set fixed random seeds (numpy + train_test_split random_state) for reproducible splits and stable accuracy output.