# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import numpy as np
import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

RANDOM_SEED = 8
np.random.seed(RANDOM_SEED)

DATASET_HEADERS = [
    "baseline value",
    "accelerations",
    "fetal_movement",
    "uterine_contractions",
    "light_decelerations",
    "severe_decelerations",
    "prolongued_decelerations",
    "abnormal_short_term_variability",
    "mean_value_of_short_term_variability",
    "percentage_of_time_with_abnormal_long_term_variability",
    "mean_value_of_long_term_variability",
    "histogram_width",
    "histogram_min",
    "histogram_max",
    "histogram_number_of_peaks",
    "histogram_number_of_zeroes",
    "histogram_mode",
    "histogram_mean",
    "histogram_median",
    "histogram_variance",
    "histogram_tendency",
    "fetal_health",
]


def _read_csv_robust(path: str) -> pd.DataFrame:
    df_try = pd.read_csv(path)
    if df_try.shape[1] <= 1:
        df_try = pd.read_csv(path, sep=";", decimal=",")
    return df_try


def _resolve_dataset_path() -> str:
    candidates = (
        os.environ.get("DATASET_PATH", "").strip(),
        "fetal_health.csv",
        os.path.join(os.getcwd(), "fetal_health.csv"),
        r"C:\Users\Mazen\Downloads\Bio-Assignment-2\fetal_health.csv",
    )
    for p in candidates:
        if p and os.path.exists(p):
            return p
    for p in candidates:
        if p:
            return p
    return "fetal_health.csv"


def _select_target_column(df: pd.DataFrame) -> str:
    if "fetal_health" in df.columns:
        return "fetal_health"
    for c in DATASET_HEADERS[::-1]:
        if c in df.columns and c == "fetal_health":
            return c
    return df.columns[-1]


def main() -> None:
    dataset_path = _resolve_dataset_path()
    df = _read_csv_robust(dataset_path)

    target_col = _select_target_column(df)
    y = df[target_col].to_numpy()
    X = df.drop(columns=[target_col])

    x_train, x_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=RANDOM_SEED
    )

    model = GaussianNB()
    model.fit(X, y)
    y_pred = model.predict(x_test)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed disk I/O roundtrip (to_csv/read_csv) by predicting directly on the in-memory x_test, reducing energy, runtime, and storage writes.
# - Avoided creating a single-column DataFrame for y; used a 1D NumPy array to reduce memory overhead and conversions (no ravel needed).
# - Dropped the target column with a single vectorized operation and trained/predicted without unnecessary intermediate copies.
# - Implemented robust CSV parsing fallback (default read_csv, then sep=';' and decimal=',') to avoid repeated manual fixes and ensure reliable ingestion.
# - Added deterministic seeding and fixed random_state to ensure reproducible splits and stable results with minimal overhead.
# - Encapsulated logic into small functions (path resolution, robust read, target selection) to keep code modular while avoiding redundant computation.