# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import json
from unidecode import unidecode

SEED = 42

def load_data(path):
    with open(path, "r") as f:
        return json.load(f)

def build_model(data):
    class_dcount = {}
    class_tcount = {}
    corpus = {}
    for doc in data:
        c = doc['cuisine']
        class_dcount[c] = class_dcount.get(c, 0) + 1
        ingredients = doc['ingredients']
        class_tcount[c] = class_tcount.get(c, 0) + len(ingredients)
        for ing in ingredients:
            key = unidecode(ing.lower())
            if key not in corpus:
                corpus[key] = {}
            if c not in corpus[key]:
                corpus[key][c] = 0
            corpus[key][c] += 1
    total_docs = len(data)
    prior_prob = {c: class_dcount[c] / total_docs for c in class_dcount}
    classes = list(class_dcount.keys())
    vocab_size = len(corpus)
    return classes, prior_prob, class_tcount, corpus, vocab_size

def naive_based(queryset, classes, prior_prob, class_tcount, corpus, vocab_size):
    import math
    log_prior = {c: math.log(prior_prob[c]) for c in classes}
    result = {}
    for doc in queryset:
        best_class = None
        best_log_prob = float('-inf')
        ingredients_lower = [unidecode(ing.lower()) for ing in doc['ingredients']]
        for c in classes:
            log_prob = log_prior[c]
            denom = vocab_size + class_tcount[c]
            for key in ingredients_lower:
                count = corpus.get(key, {}).get(c, 0)
                log_prob += math.log((1 + count) / denom)
            if log_prob > best_log_prob:
                best_log_prob = log_prob
                best_class = c
        result[doc['id']] = best_class
    return result

def main():
    train_data = load_data("train.json")
    classes, prior_prob, class_tcount, corpus, vocab_size = build_model(train_data)
    empirical_dict = naive_based(train_data, classes, prior_prob, class_tcount, corpus, vocab_size)
    correctly_classified = sum(
        1 for doc in train_data if doc['cuisine'] == empirical_dict[doc['id']]
    )
    accuracy = correctly_classified / len(empirical_dict)
    print(f"ACCURACY={accuracy:.6f}")

main()

# Optimization Summary
# 1. Replaced storing lists of doc IDs in corpus with simple integer counts, drastically reducing memory and avoiding list append overhead.
# 2. Used log-probabilities instead of multiplying many small floats, avoiding numerical underflow and replacing multiply with addition.
# 3. Pre-computed log(prior_prob) and vocab_size once outside the loop instead of recomputing per document.
# 4. Pre-computed unidecode(ing.lower()) for each document's ingredients once, avoiding redundant string processing per class.
# 5. Removed global variables; passed data through function parameters for clarity and reduced scope.
# 6. Removed file output (result.xlsx), plots, and unnecessary prints.
# 7. Removed test.json processing since accuracy is evaluated on train.json (empirical accuracy as in original).
# 8. Eliminated intermediate data structures (separate vocab list, separate class lists built multiple times).
# 9. Combined document counting and token counting into a single pass over training data.