# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: original_telemetry

#!/usr/bin/env python
# coding: utf-8

import json
import os
import pandas as pd
from unidecode import unidecode


def prior_probability():
    global classes
    global class_dcount
    global prior_prob
    classes = list(class_tcount.keys())
    for i in classes:
        prior_prob[i] = class_dcount[i] / len(data)


def vocab_maker():
    global class_dcount
    global data
    global vocab

    for doc in data:
        class_dcount[doc["cuisine"]] = class_dcount.get(doc["cuisine"], 0)
        class_dcount[doc["cuisine"]] = class_dcount[doc["cuisine"]] + 1

    for doc in data:
        if doc["cuisine"] not in class_tcount:
            class_tcount[doc["cuisine"]] = len(doc["ingredients"])
        else:
            class_tcount[doc["cuisine"]] += len(doc["ingredients"])

        for i in doc["ingredients"]:
            i = unidecode(i.lower())
            if i not in corpus:
                corpus[i] = corpus.get(i, {})
            corpus[i][doc["cuisine"]] = corpus[i].get(doc["cuisine"], [])
            corpus[i][doc["cuisine"]].append(doc["id"])

    vocab = list(corpus.keys())


def file_read():
    global data
    with open("train.json", "r") as handle:
        data = json.load(handle)
    vocab_maker()


def results_storage():
    file_path = "result.xlsx"
    data_local = {"Keys": list(qdoc_class.keys()), "Values": list(qdoc_class.values())}
    if not os.path.exists(file_path):
        df = pd.DataFrame(data_local)
        df.to_excel(file_path, index=False)


def naive_based(queryset):
    qdoc_class_local = {}
    for doc in queryset:
        classes_dprob = {}
        for c in classes:
            p_ingredient = 1
            for i in doc["ingredients"]:
                length = len(corpus.get(i, {}).get(c, []))
                i_ingredient = (1 + length) / (len(vocab) + class_tcount[c])
                p_ingredient = p_ingredient * i_ingredient
            temp = p_ingredient * prior_prob[c]
            classes_dprob[c] = temp
        qdoc_class_local[doc["id"]] = max(classes_dprob, key=lambda k: classes_dprob[k])
    return qdoc_class_local


def testdata():
    global qdoc_class
    with open("test.json", "r") as f:
        queryset = json.load(f)
        qdoc_class = naive_based(queryset)


def empirical_accuracy():
    correctly_classified = 0
    with open("train.json", "r") as f:
        queryset = json.load(f)
    empirical_dict = naive_based(queryset)
    l = len(empirical_dict)
    for doc in queryset:
        if doc["cuisine"] == empirical_dict[doc["id"]]:
            correctly_classified += 1
    accuracy = correctly_classified / l
    print(f"ACCURACY={accuracy:.6f}")


data = []
corpus = {}
class_tcount = {}
class_dcount = {}
vocab = []
prior_prob = {}
qdoc_class = {}
classes = []

file_read()
prior_probability()
testdata()
empirical_accuracy()