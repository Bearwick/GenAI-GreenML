# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import json
import warnings
warnings.filterwarnings("ignore")

# Load the JSON dataset
data = None
try:
    with open("train.json", "r") as f:
        data = json.load(f)
except Exception:
    try:
        data = pd.read_json("train.json")
    except Exception:
        pass

# Convert to DataFrame if loaded as list of dicts
if isinstance(data, list):
    df = pd.DataFrame(data)
elif isinstance(data, pd.DataFrame):
    df = data
else:
    raise RuntimeError("Could not load train.json")

# Strip/normalize column names
df.columns = [str(c).strip() for c in df.columns]
df = df[[c for c in df.columns if not c.startswith("Unnamed")]]

# Identify target and ingredients columns
# Expected schema: id, cuisine, ingredients
target_col = None
ingredients_col = None

for c in df.columns:
    cl = c.lower()
    if cl == "cuisine":
        target_col = c
    elif cl == "ingredients":
        ingredients_col = c

# Fallback: if columns not found by name, guess
if target_col is None:
    # Look for a string/object column with multiple classes as target
    for c in df.columns:
        if df[c].dtype == object and df[c].nunique() > 2 and df[c].nunique() < 1000:
            if c.lower() != "id":
                target_col = c
                break

if ingredients_col is None:
    # Look for a column containing lists
    for c in df.columns:
        if c == target_col:
            continue
        sample = df[c].dropna().iloc[0] if len(df[c].dropna()) > 0 else None
        if isinstance(sample, list):
            ingredients_col = c
            break

assert target_col is not None, "Could not identify target column"
assert ingredients_col is not None, "Could not identify ingredients column"

# Convert ingredient lists to space-separated strings for TF-IDF
df["ingredients_text"] = df[ingredients_col].apply(
    lambda x: " ".join(x) if isinstance(x, list) else str(x)
)

# Encode target
le = LabelEncoder()
df["target_encoded"] = le.fit_transform(df[target_col].astype(str))

# Drop rows with missing values in key columns
df = df.dropna(subset=["ingredients_text", "target_encoded"])
assert len(df) > 0, "Dataset empty after preprocessing"

X_text = df["ingredients_text"].values
y = df["target_encoded"].values

# Check we have at least 2 classes
n_classes = len(np.unique(y))
assert n_classes >= 2, "Need at least 2 classes for classification"

# Train/test split
X_train_text, X_test_text, y_train, y_test = train_test_split(
    X_text, y, test_size=0.2, random_state=42, stratify=y
)

assert len(X_train_text) > 0, "Training set empty"
assert len(X_test_text) > 0, "Test set empty"

# TF-IDF vectorization - energy efficient with limited features
# Using max_features=5000 keeps it lightweight while capturing important ingredient signals
tfidf = TfidfVectorizer(
    max_features=5000,
    sublinear_tf=True,
    strip_accents="unicode",
    token_pattern=r"(?u)\b\w+\b",
    ngram_range=(1, 1),
    dtype=np.float32  # float32 saves memory
)

X_train = tfidf.fit_transform(X_