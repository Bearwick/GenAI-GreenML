# Generated by generate_llm_code.py
# LLM: gemini
# Mode: original_telemetry

import json
from unidecode import unidecode

data = []
corpus = {}
class_tcount = {}
class_dcount = {}
vocab = []
prior_prob = {}
classes = []

def vocab_maker():
    global class_dcount, class_tcount, corpus, vocab
    for doc in data:
        cuisine = doc['cuisine']
        class_dcount[cuisine] = class_dcount.get(cuisine, 0) + 1
        
        if cuisine not in class_tcount:
            class_tcount[cuisine] = len(doc['ingredients'])
        else:
            class_tcount[cuisine] += len(doc['ingredients'])
            
        for i in doc['ingredients']:
            i_norm = unidecode(i.lower())
            if i_norm not in corpus:
                corpus[i_norm] = {}
            if cuisine not in corpus[i_norm]:
                corpus[i_norm][cuisine] = []
            corpus[i_norm][cuisine].append(doc['id'])
    vocab = list(corpus.keys())

def prior_probability():
    global classes, prior_prob
    classes = list(class_tcount.keys())
    for c in classes:
        prior_prob[c] = class_dcount[c] / len(data)

def naive_based(queryset):
    predictions = {}
    for doc in queryset:
        classes_dprob = {}
        for c in classes:
            p_ingredient = 1.0
            for i in doc['ingredients']:
                i_norm = unidecode(i.lower())
                length = len(corpus.get(i_norm, {}).get(c, []))
                i_prob = (1 + length) / (len(vocab) + class_tcount[c])
                p_ingredient *= i_prob
            classes_dprob[c] = p_ingredient * prior_prob[c]
        predictions[doc['id']] = max(classes_dprob, key=classes_dprob.get)
    return predictions

def run_model():
    global data
    with open("train.json", "r") as handle:
        data = json.load(handle)
    
    vocab_maker()
    prior_probability()
    
    predictions = naive_based(data)
    
    correctly_classified = 0
    total_docs = len(data)
    for doc in data:
        if doc['cuisine'] == predictions[doc['id']]:
            correctly_classified += 1
            
    accuracy = correctly_classified / total_docs
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_model()

# OPTIMIZATION SUMMARY
# 1. Standardized variable initialization and scoping to ensure consistency across functions.
# 2. Fixed an ML consistency error by applying unidecode normalization to ingredients in both the training (vocab_maker) and inference (naive_based) phases.
# 3. Merged redundant loops in vocab_maker to improve data processing efficiency.
# 4. Removed unused library imports (pandas, os) and functions (results_storage, testdata) to streamline the execution for the baseline accuracy task.
# 5. Corrected potential reference issues by ensuring vocab is explicitly updated in the global scope.