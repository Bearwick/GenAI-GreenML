# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import numpy as np
import pandas as pd
import random
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from imblearn.over_sampling import SMOTE

DATASET_HEADERS = [h.strip() for h in "Gender,Frequent Flyer,Age,Type of Travel,Class,Flight Distance,Inflight wifi service,Departure/Arrival time convenient,Ease of Online booking,Gate location,Food and drink,Online boarding,Seat comfort,Inflight entertainment,On-board service,Leg room service,Baggage handling,Checkin service,Inflight service,Cleanliness,Departure Delay in Minutes,Arrival Delay in Minutes,satisfaction".split(",")]

def normalize_col(name):
    return name.strip().lower()

def is_parsing_correct(df, expected_headers):
    if df is None or df.empty:
        return False
    if len(df.columns) <= 1:
        return False
    expected_norm = {normalize_col(h) for h in expected_headers}
    cols_norm = {normalize_col(c) for c in df.columns}
    match = len(expected_norm.intersection(cols_norm))
    return match >= max(1, len(expected_headers) // 2)

def read_csv_robust(path, expected_headers):
    try:
        df = pd.read_csv(path)
    except Exception:
        return pd.read_csv(path, sep=";", decimal=",")
    if not is_parsing_correct(df, expected_headers):
        return pd.read_csv(path, sep=";", decimal=",")
    return df

def build_column_map(df_columns, expected_headers):
    norm_df = {normalize_col(c): c for c in df_columns}
    return {normalize_col(h): norm_df[normalize_col(h)] for h in expected_headers if normalize_col(h) in norm_df}

def main():
    np.random.seed(42)
    random.seed(42)

    df = read_csv_robust("EireJet.csv", DATASET_HEADERS)
    col_map = build_column_map(df.columns, DATASET_HEADERS)
    label_header = DATASET_HEADERS[-1]

    cat_mappings = {
        "Gender": {"Female": 1, "Male": 0},
        "Frequent Flyer": {"Yes": 1, "No": 0},
        "Type of Travel": {"Personal Travel": 1, "Business travel": 0},
        "Class": {"Eco": 0, "Eco Plus": 1, "Business": 2},
        label_header: {"neutral or dissatisfied": 0, "satisfied": 1},
    }

    for expected_col, mapping in cat_mappings.items():
        actual_col = col_map.get(normalize_col(expected_col))
        if actual_col is not None:
            df[actual_col] = df[actual_col].map(mapping)

    df.dropna(axis=0, inplace=True)

    label_col = col_map.get(normalize_col(label_header))
    if label_col is None:
        raise ValueError("Label column not found")

    X = df.drop(columns=[label_col])
    y = df[label_col]

    X_scaled = StandardScaler().fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.3, random_state=100
    )

    X_train_res, y_train_res = SMOTE(random_state=101).fit_resample(X_train, y_train)

    model = GradientBoostingClassifier(
        n_estimators=200, max_depth=9, max_leaf_nodes=32, random_state=1
    )
    model.fit(X_train_res, y_train_res)
    accuracy = model.score(X_test, y_test)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed grid searches, duplicate splits, and unused model evaluations to avoid redundant computation.
# - Mapped categorical values once and performed a single dropna to reduce passes over the data.
# - Reused one scaled matrix and one SMOTE resample before fitting the final classifier.
# - Added robust CSV parsing and column normalization for reliable ingestion with minimal retries.
# - Fixed seeds and random_state values to ensure deterministic results.