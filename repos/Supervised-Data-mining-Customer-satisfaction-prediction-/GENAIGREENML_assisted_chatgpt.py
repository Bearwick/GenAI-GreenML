# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

from imblearn.over_sampling import SMOTE


SEED = 100


def set_reproducible_seeds(seed: int = SEED) -> None:
    random.seed(seed)
    np.random.seed(seed)


def read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def resolve_column_map(df_columns, dataset_headers):
    col_map = {}
    df_cols_norm = {str(c).strip().lower(): c for c in df_columns}
    for h in dataset_headers:
        key = str(h).strip().lower()
        if key in df_cols_norm:
            col_map[h] = df_cols_norm[key]
    return col_map


def preprocess(df: pd.DataFrame, dataset_headers):
    df = df.dropna(axis=0, how="any").copy()

    col_map = resolve_column_map(df.columns, dataset_headers)

    required = ["satisfaction"]
    for r in required:
        if r not in col_map:
            raise ValueError(f"Required column missing: {r}")

    gender_col = col_map.get("Gender")
    ff_col = col_map.get("Frequent Flyer")
    travel_col = col_map.get("Type of Travel")
    class_col = col_map.get("Class")
    sat_col = col_map["satisfaction"]

    if gender_col is not None:
        df[gender_col] = df[gender_col].map({"Female": 1, "Male": 0})
    if ff_col is not None:
        df[ff_col] = df[ff_col].map({"Yes": 1, "No": 0})
    if travel_col is not None:
        df[travel_col] = df[travel_col].map({"Personal Travel": 1, "Business travel": 0})
    if class_col is not None:
        df[class_col] = df[class_col].map({"Eco": 0, "Eco Plus": 1, "Business": 2})

    df[sat_col] = df[sat_col].map({"neutral or dissatisfied": 0, "satisfied": 1})

    df = df.dropna(axis=0, how="any")

    y = df[sat_col].astype(np.int64, copy=False)
    X = df.drop(columns=[sat_col])

    return X, y


def train_and_evaluate(X: pd.DataFrame, y: pd.Series) -> float:
    scaler = StandardScaler(copy=False)
    X_scaled = scaler.fit_transform(X.to_numpy(dtype=np.float32, copy=False))

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled,
        y.to_numpy(copy=False),
        test_size=0.3,
        random_state=SEED,
        stratify=y,
    )

    smote = SMOTE(random_state=101)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

    model = RandomForestClassifier(
        n_estimators=150,
        criterion="entropy",
        max_features="sqrt",
        random_state=1,
        n_jobs=1,
    )
    model.fit(X_train_res, y_train_res)

    y_pred = model.predict(X_test)
    return float(accuracy_score(y_test, y_pred))


def main():
    set_reproducible_seeds(SEED)

    dataset_path = "EireJet (1).csv"
    if not os.path.exists(dataset_path):
        dataset_path = "EireJet.csv"

    dataset_headers = [
        "Gender",
        "Frequent Flyer",
        "Age",
        "Type of Travel",
        "Class",
        "Flight Distance",
        "Inflight wifi service",
        "Departure/Arrival time convenient",
        "Ease of Online booking",
        "Gate location",
        "Food and drink",
        "Online boarding",
        "Seat comfort",
        "Inflight entertainment",
        "On-board service",
        "Leg room service",
        "Baggage handling",
        "Checkin service",
        "Inflight service",
        "Cleanliness",
        "Departure Delay in Minutes",
        "Arrival Delay in Minutes",
        "satisfaction",
    ]

    df = read_csv_robust(dataset_path)
    X, y = preprocess(df, dataset_headers)
    accuracy = train_and_evaluate(X, y)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed exploratory prints, plots, and repeated train/test split to cut unnecessary computation and I/O overhead.
# - Eliminated GridSearchCV blocks (not required for the final trained model behavior) to avoid expensive cross-validation.
# - Converted feature matrix to float32 NumPy early and used StandardScaler(copy=False) to reduce memory footprint and data movement.
# - Used a single preprocessing pass with column resolution based on provided headers and df.columns for robust schema handling.
# - Applied SMOTE via fit_resample (modern API) once on the training split only, preserving intent while avoiding redundant work.
# - Set fixed seeds for Python and NumPy, and fixed model/random_state values to improve reproducibility and stability.
# - Set RandomForest max_features="sqrt" (equivalent to prior 'auto' for classifiers) and constrained n_jobs=1 for deterministic execution.