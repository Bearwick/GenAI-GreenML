# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


SEED = 42


def _set_reproducible_seed(seed: int = SEED) -> None:
    random.seed(seed)
    np.random.seed(seed)


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)

    looks_like_single_column = df.shape[1] == 1
    header_mismatch = True
    expected = ["Id", "SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm", "Species"]
    cols = [str(c).strip() for c in df.columns]
    if len(cols) == len(expected):
        header_mismatch = any(c not in expected for c in cols)

    if looks_like_single_column or header_mismatch:
        df2 = pd.read_csv(path, sep=";", decimal=",")
        if df2.shape[1] > df.shape[1]:
            df = df2

    return df


def _resolve_dataset_path() -> str:
    candidates = (
        os.environ.get("DATASET_PATH"),
        os.environ.get("IRIS_CSV_PATH"),
        "Iris.csv",
        os.path.join(os.getcwd(), "Iris.csv"),
        "C:/Users/Lalit Pathak/python2.0/Iris.csv",
    )
    for p in candidates:
        if p and os.path.exists(p):
            return p
    raise FileNotFoundError("Dataset not found in known locations.")


def _prepare_features_and_labels(df: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:
    df = df.copy()

    if "Id" in df.columns:
        df = df.drop(columns=["Id"])

    if "Species" not in df.columns:
        raise KeyError("'Species' column not found in dataset.")

    y = df["Species"].to_numpy()
    X = df.drop(columns=["Species"]).to_numpy(dtype=np.float64, copy=False)

    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    return X, y_encoded


def main() -> None:
    _set_reproducible_seed(SEED)

    dataset_path = _resolve_dataset_path()
    data = _read_csv_robust(dataset_path)

    X, y_encoded = _prepare_features_and_labels(data)

    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y_encoded,
        test_size=0.2,
        random_state=SEED,
        stratify=y_encoded,
    )

    log_reg = LogisticRegression(max_iter=200, random_state=SEED)
    log_reg.fit(X_train, y_train)

    rf_model = RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)
    rf_model.fit(X_train, y_train)

    y_pred_rf = rf_model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred_rf)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed exploratory prints, classification reports, confusion matrix computation, and all plotting to cut unnecessary CPU/GPU work and data movement while preserving the ML task and final evaluation intent.
# - Converted feature/label handling to NumPy arrays early to reduce pandas overhead and intermediate DataFrame copies during training and splitting.
# - Dropped unused imports (matplotlib, seaborn, extra metrics) to reduce startup overhead and memory footprint.
# - Added robust CSV parsing fallback (default read_csv, then retry with sep=';' and decimal=',') to avoid repeated manual fixes and ensure reliable ingestion.
# - Ensured reproducibility via fixed seeds for Python and NumPy and passing random_state into estimators and train/test split.
# - Enabled RandomForest parallelism with n_jobs=-1 to reduce wall-clock runtime for the same model configuration and predictions.