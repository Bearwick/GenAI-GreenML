# Generated by generate_llm_code.py
# LLM: groq
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Load data
df = pd.read_csv("./data/student-mat.csv")

# Rename columns to consistent naming
df.columns = [
    'school', 'sex', 'age', 'address', 'family_size', 'parents_status',
    'mother_education', 'father_education', 'mother_job', 'father_job',
    'reason', 'guardian', 'commute_time', 'study_time', 'failures',
    'school_support', 'family_support', 'paid_classes', 'activities',
    'nursery', 'desire_higher_edu', 'internet', 'romantic', 'family_quality',
    'free_time', 'go_out', 'weekday_alcohol_usage', 'weekend_alcohol_usage',
    'health', 'absences', 'period1_score', 'period2_score', 'final_score'
]

# Convert final_score into categorical grade
df['final_grade'] = 'na'
df.loc[(df['final_score'] >= 15) & (df['final_score'] <= 20), 'final_grade'] = 'good'
df.loc[(df['final_score'] >= 10) & (df['final_score'] <= 14), 'final_grade'] = 'fair'
df.loc[(df['final_score'] >= 0)  & (df['final_score'] <= 9),  'final_grade'] = 'poor'
le = LabelEncoder()
df['final_grade'] = le.fit_transform(df['final_grade'])

# One‑hot encode categorical features
x = pd.get_dummies(df, drop_first=True).drop(columns=['final_score'])
y = df['final_grade']

# Train/test split
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.3, random_state=42, stratify=y
)

# KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(x_train, y_train)
knn_acc = accuracy_score(y_test, knn.predict(x_test))
print(f"ACCURACY=KNN:{knn_acc:.6f}")

# Decision Tree
tree = DecisionTreeClassifier(
    max_depth=5, min_samples_leaf=17, random_state=42, criterion='entropy'
)
tree.fit(x_train, y_train)
tree_acc = accuracy_score(y_test, tree.predict(x_test))
print(f"ACCURACY=DecisionTree:{tree_acc:.6f}")

# Random Forest
rf = RandomForestClassifier(n_estimators=50, random_state=42)
rf.fit(x_train, y_train)
rf_acc = accuracy_score(y_test, rf.predict(x_test))
print(f"ACCURACY=RandomForest:{rf_acc:.6f}")

# SVM with linear kernel
svm = SVC(kernel='linear', random_state=42)
svm.fit(x_train, y_train)
svm_acc = accuracy_score(y_test, svm.predict(x_test))
print(f"ACCURACY=SVM:{svm_acc:.6f}")

# Optional: cross‑validation for the best model (Random Forest)
cv_scores = cross_val_score(rf, x, y, cv=3)
print(f"Cross‑validation accuracy: {cv_scores.mean():.6f}")