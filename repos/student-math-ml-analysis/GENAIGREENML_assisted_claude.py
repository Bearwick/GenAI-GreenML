# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

try:
    df = pd.read_csv("./data/student-mat.csv")
    if df.shape[1] < 5:
        df = pd.read_csv("./data/student-mat.csv", sep=';', decimal=',')
except Exception:
    df = pd.read_csv("./data/student-mat.csv", sep=';', decimal=',')

df.columns = [
    'school', 'sex', 'age', 'address', 'family_size', 'parents_status',
    'mother_education', 'father_education', 'mother_job', 'father_job',
    'reason', 'guardian', 'commute_time', 'study_time', 'failures',
    'school_support', 'family_support', 'paid_classes', 'activities',
    'nursery', 'desire_higher_edu', 'internet', 'romantic', 'family_quality',
    'free_time', 'go_out', 'weekday_alcohol_usage', 'weekend_alcohol_usage',
    'health', 'absences', 'period1_score', 'period2_score', 'final_score'
]

df_encode = pd.get_dummies(df, drop_first=True)

conditions = [
    (df.final_score >= 15) & (df.final_score <= 20),
    (df.final_score >= 10) & (df.final_score <= 14),
    (df.final_score >= 0) & (df.final_score <= 9),
]
choices = ['good', 'fair', 'poor']
df['final_grade'] = np.select(conditions, choices, default='na')

la = LabelEncoder()
df['final_grade'] = la.fit_transform(df['final_grade'])

x = df_encode
y = df['final_grade']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=RANDOM_STATE)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(x_train, y_train)
ac_knn = accuracy_score(y_test, knn.predict(x_test))

tree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=17, random_state=RANDOM_STATE, criterion='entropy')
tree.fit(x_train, y_train)
ac_tree = accuracy_score(y_test, tree.predict(x_test))

rf = RandomForestClassifier(random_state=RANDOM_STATE)
rf.fit(x_train, y_train)
ac_random = accuracy_score(y_test, rf.predict(x_test))

svc = SVC(random_state=RANDOM_STATE)
svc.fit(x_train, y_train)
ac_svc = accuracy_score(y_test, svc.predict(x_test))

accuracy = max(ac_knn, ac_tree, ac_random, ac_svc)
print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# 1. Removed all matplotlib/seaborn imports and plot calls to eliminate visualization overhead.
# 2. Removed all print/logging statements except the final accuracy output.
# 3. Removed redundant .copy() on df_encode since it is not modified after assignment.
# 4. Replaced iterative loc-based grade assignment with np.select for vectorized, single-pass computation.
# 5. Removed unused cross_val_score, confusion_matrix, classification_report computations to reduce CPU time