# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: original_telemetry

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

df = pd.read_csv("./data/student-mat.csv")

df.isna().sum()
df.isnull().any(axis=1)

df.columns = [
    "school",
    "sex",
    "age",
    "address",
    "family_size",
    "parents_status",
    "mother_education",
    "father_education",
    "mother_job",
    "father_job",
    "reason",
    "guardian",
    "commute_time",
    "study_time",
    "failures",
    "school_support",
    "family_support",
    "paid_classes",
    "activities",
    "nursery",
    "desire_higher_edu",
    "internet",
    "romantic",
    "family_quality",
    "free_time",
    "go_out",
    "weekday_alcohol_usage",
    "weekend_alcohol_usage",
    "health",
    "absences",
    "period1_score",
    "period2_score",
    "final_score",
]

numeric_df = df.select_dtypes(include=["int64"])
corr = numeric_df.corr()

df_encode = pd.get_dummies(df, drop_first=True)

df["final_grade"] = "na"
df.loc[(df.final_score >= 15) & (df.final_score <= 20), "final_grade"] = "good"
df.loc[(df.final_score >= 10) & (df.final_score <= 14), "final_grade"] = "fair"
df.loc[(df.final_score >= 0) & (df.final_score <= 9), "final_grade"] = "poor"

la = LabelEncoder()
df.final_grade = la.fit_transform(df.final_grade)

x = df_encode.copy()
y = df["final_grade"]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(x_train, y_train)
y_pred = knn.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

tree = DecisionTreeClassifier(
    max_depth=5, min_samples_leaf=17, random_state=42, criterion="entropy"
)
tree.fit(x_train, y_train)
y_tree_predict = tree.predict(x_test)
ac_tree = accuracy_score(y_test, y_tree_predict)
scores = cross_val_score(tree, x, y, cv=5)

from sklearn.metrics import ConfusionMatrixDisplay, classification_report
from sklearn.metrics import accuracy_score, confusion_matrix

ac_tree_2 = accuracy_score(y_tree_predict, y_test)

cm = confusion_matrix(y_tree_predict, y_test)
cm_display = ConfusionMatrixDisplay(
    confusion_matrix=cm, display_labels=["class=0", "class=1", "class=2"]
)
report = classification_report(y_test, y_tree_predict)

from sklearn.ensemble import RandomForestClassifier

Random = RandomForestClassifier()
R = Random.fit(x_train, y_train)
y_random_predict = Random.predict(x_test)

ac_random = accuracy_score(y_random_predict, y_test)

report = classification_report(y_test, y_random_predict)

cm_random = confusion_matrix(y_random_predict, y_test)
cm_display = ConfusionMatrixDisplay(
    confusion_matrix=cm_random, display_labels=["class=0", "class=1", "class=2"]
)

feature_importance = Random.feature_importances_
features = features = x.columns.tolist()

from sklearn.svm import SVC

svc = SVC()
svc.fit(x_train, y_train)
y_svc_predict = svc.predict(x_test)
ac_svc = accuracy_score(y_test, y_svc_predict)

cm = confusion_matrix(y_test, y_svc_predict)
df_cm = pd.DataFrame(cm, range(3), range(3))
sns.set(font_scale=1.4)
sns.heatmap(df_cm, annot=True, annot_kws={"size": 16})

report_svc = classification_report(y_test, y_svc_predict)

print(f"ACCURACY={accuracy:.6f}")