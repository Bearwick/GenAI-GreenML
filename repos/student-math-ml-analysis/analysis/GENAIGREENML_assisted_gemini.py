# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

def execute_pipeline():
    dataset_path = "data/student-mat.csv"
    try:
        df = pd.read_csv(dataset_path, sep=None, engine='python')
    except Exception:
        df = pd.read_csv(dataset_path, sep=';', decimal=',')

    df.columns = [
        'school', 'sex', 'age', 'address', 'family_size', 'parents_status',
        'mother_education', 'father_education', 'mother_job', 'father_job',
        'reason', 'guardian', 'commute_time', 'study_time', 'failures',
        'school_support', 'family_support', 'paid_classes', 'activities',
        'nursery', 'desire_higher_edu', 'internet', 'romantic', 'family_quality',
        'free_time', 'go_out', 'weekday_alcohol_usage', 'weekend_alcohol_usage',
        'health', 'absences', 'period1_score', 'period2_score', 'final_score'
    ]

    x = pd.get_dummies(df, drop_first=True)

    y_labels = pd.cut(
        df['final_score'], 
        bins=[-1, 9, 14, 20], 
        labels=['poor', 'fair', 'good']
    )
    y = LabelEncoder().fit_transform(y_labels)

    x_train, x_test, y_train, y_test = train_test_split(
        x, y, test_size=0.3, random_state=42
    )

    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(x_train, y_train)

    tree = DecisionTreeClassifier(
        max_depth=5, 
        min_samples_leaf=17, 
        random_state=42, 
        criterion='entropy'
    )
    tree.fit(x_train, y_train)

    rf = RandomForestClassifier(random_state=42)
    rf.fit(x_train, y_train)
    y_pred_rf = rf.predict(x_test)

    svc = SVC(random_state=42)
    svc.fit(x_train, y_train)

    accuracy = accuracy_score(y_test, y_pred_rf)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    execute_pipeline()

# Optimization Summary
# 1. Used pd.cut for vectorized target binning instead of multiple .loc assignments, reducing CPU cycles.
# 2. Implemented robust CSV parsing with sep=None and engine='python' to handle different delimiters efficiently in one pass.
# 3. Removed redundant df_encode.copy() to reduce memory footprint and unnecessary data duplication.
# 4. Eliminated all diagnostic prints, info() calls, and visualization code to minimize I/O overhead and runtime.
# 5. Consolidated preprocessing steps to avoid multiple traversals of the dataframe.
# 6. Set fixed random seeds (random_state=42) across all stochastic models to ensure reproducibility.
# 7. Removed unused imports (StandardScaler, ConfusionMatrixDisplay, cross_val_score) to reduce memory overhead and initialization time.
# 8. Maintained feature set (including final_score) as per original logic to preserve identical model behavior.