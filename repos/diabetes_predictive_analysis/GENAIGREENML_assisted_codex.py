# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
import random
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

DATASET_HEADERS = "Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,Outcome"

def normalize_col(name):
    return "".join(ch for ch in str(name).lower() if ch.isalnum())

def parsing_wrong(df, expected_cols):
    if df.shape[1] <= 1:
        return True
    if expected_cols:
        expected_norm = {normalize_col(c) for c in expected_cols}
        actual_norm = {normalize_col(c) for c in df.columns}
        if len(expected_norm & actual_norm) < max(1, len(expected_norm) // 2):
            return True
        if df.shape[1] > len(expected_cols) and any(str(c).startswith("Unnamed") for c in df.columns):
            return True
    return False

def read_csv_with_fallback(path, expected_cols):
    df = pd.read_csv(path)
    if parsing_wrong(df, expected_cols):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df

def standardize_columns(df, expected_cols):
    df.columns = [str(c).strip() for c in df.columns]
    if expected_cols:
        norm_actual = {normalize_col(c): c for c in df.columns}
        rename_map = {}
        for exp in expected_cols:
            norm_exp = normalize_col(exp)
            if norm_exp in norm_actual:
                rename_map[norm_actual[norm_exp]] = exp
        if rename_map:
            df = df.rename(columns=rename_map)
    return df

def preprocess(df):
    zero_names = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
    norm_zero = {normalize_col(c) for c in zero_names}
    zero_cols = [c for c in df.columns if normalize_col(c) in norm_zero]
    if zero_cols:
        df.loc[:, zero_cols] = df.loc[:, zero_cols].replace(0, np.nan)
        fill_values = {}
        glucose_col = next((c for c in zero_cols if normalize_col(c) == normalize_col("Glucose")), None)
        if glucose_col is not None:
            fill_values[glucose_col] = df[glucose_col].mean()
        median_cols = [c for c in zero_cols if c != glucose_col]
        if median_cols:
            fill_values.update(df[median_cols].median().to_dict())
        if fill_values:
            df.fillna(value=fill_values, inplace=True)
    return df

def main():
    np.random.seed(42)
    random.seed(42)
    expected_cols = [c.strip() for c in DATASET_HEADERS.split(",") if c.strip()]
    df = read_csv_with_fallback("diabetes.csv", expected_cols)
    df = standardize_columns(df, expected_cols)
    df = preprocess(df)
    target_col = None
    if expected_cols:
        target_norm = normalize_col(expected_cols[-1])
        for col in df.columns:
            if normalize_col(col) == target_norm:
                target_col = col
                break
    if target_col is None:
        target_col = df.columns[-1]
    feature_cols = [c for c in df.columns if c != target_col]
    X = df[feature_cols].to_numpy(dtype=np.float64, copy=False)
    y = df[target_col].to_numpy()
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler(copy=False)
    x_train = scaler.fit_transform(x_train)
    x_test = scaler.transform(x_test)
    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(x_train, y_train)
    accuracy = knn.score(x_test, y_test)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed visualization and verbose logging to avoid unnecessary computation and I/O.
# - Preprocessed data in place with vectorized zero handling and single-pass imputation to reduce memory use.
# - Used in-place scaling (copy=False) and direct model scoring to minimize temporary arrays and extra predictions.
# - Eliminated redundant hyperparameter exploration loops not required for the final output.
# - Added robust CSV parsing with fallback and fixed random seeds for reproducibility.