# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import glob
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def find_dataset():
    candidates = ["data.csv", "diabetes.csv", "dataset.csv", "train.csv"]
    for name in candidates:
        if os.path.exists(name):
            return name
    csv_files = glob.glob("*.csv")
    if csv_files:
        return csv_files[0]
    raise FileNotFoundError("No CSV dataset found.")

file_path = find_dataset()
df = pd.read_csv(file_path)

expected_cols = [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age",
    "Outcome",
]

if "Outcome" not in df.columns or len(df.columns) != len(expected_cols):
    df = pd.read_csv(file_path, header=None)
    if df.shape[1] >= len(expected_cols):
        df = df.iloc[:, :len(expected_cols)]
        df.columns = expected_cols

invalid_zero_cols = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
for col in invalid_zero_cols:
    if col in df.columns:
        df[col] = df[col].replace(0, np.nan)

X = df.drop(columns=["Outcome"])
y = df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

model = Pipeline(
    steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(max_iter=200, solver="liblinear")),
    ]
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# Used lightweight preprocessing (median imputation + standardization) within a single pipeline for efficiency and reproducibility.
# Selected logistic regression with a small iteration budget and liblinear solver for CPU-friendly training on tabular data.
# Avoided complex models and kept operations simple to minimize energy and compute usage.