# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

data = pd.read_csv("diabetes.csv")

cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
data[cols] = data[cols].replace(0, np.nan)

data['Glucose'] = data['Glucose'].fillna(data['Glucose'].mean())
data[['BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = data[['BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].fillna(data[['BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].median())

X = data.drop('Outcome', axis=1).values
y = data['Outcome'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

param_dist = {
    'n_neighbors': np.arange(1, 16),
    'weights': ['uniform', 'distance']
}

search = RandomizedSearchCV(
    KNeighborsClassifier(),
    param_dist,
    n_iter=10,
    cv=5,
    random_state=42,
    n_jobs=-1
)
search.fit(X_train, y_train)

accuracy = search.best_estimator_.score(X_test, y_test)

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Removed redundant data copying (data.copy()) to save memory.
# 2. Consolidated missing value imputation using vectorized pandas operations instead of a loop.
# 3. Eliminated redundant manual loops for k-value evaluation and cross-validation.
# 4. Replaced multiple redundant model fits with a single RandomizedSearchCV to find the optimal parameters.
# 5. Used fit_transform() on the training set to reduce redundant computations during scaling.
# 6. Utilized n_jobs=-1 in RandomizedSearchCV to exploit parallel processing and reduce runtime.
# 7. Converted DataFrames to NumPy arrays using .values to minimize the overhead of Pandas metadata during training.
# 8. Removed all visualization libraries and plotting calls to reduce energy consumption and dependency overhead.
# 9. Ensured reproducibility by setting random_state in both split and search operations.