# Generated by generate_llm_code.py
# LLM: gemini
# Mode: original_telemetry

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

data = pd.read_csv("diabetes.csv")
data_copy = data.copy()

cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
data_copy[cols] = data_copy[cols].replace(0, np.nan)

data_copy['Glucose'] = data_copy['Glucose'].fillna(data_copy['Glucose'].mean())
data_copy['BloodPressure'] = data_copy['BloodPressure'].fillna(data_copy['BloodPressure'].median())
data_copy['SkinThickness'] = data_copy['SkinThickness'].fillna(data_copy['SkinThickness'].median())
data_copy['Insulin'] = data_copy['Insulin'].fillna(data_copy['Insulin'].median())
data_copy['BMI'] = data_copy['BMI'].fillna(data_copy['BMI'].median())

x = data_copy.drop('Outcome', axis=1).values
y = data_copy['Outcome'].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
scaler.fit(x_train)
x_train_scaled = scaler.transform(x_train)
x_test_scaled = scaler.transform(x_test)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(x_train_scaled, y_train)
y_pred = knn.predict(x_test_scaled)

precision_score(y_test, y_pred)
recall_score(y_test, y_pred)
f1_score(y_test, y_pred)

test_f1 = []
test_pre = []
test_rec = []
test_score = []

for i in range(1, 16):
    knn = KNeighborsClassifier(i)
    knn.fit(x_train_scaled, y_train)
    y_pred = knn.predict(x_test_scaled)
    
    test_f1.append(round(f1_score(y_test, y_pred, average='weighted') * 100, 2))
    test_pre.append(round(precision_score(y_test, y_pred, average='weighted') * 100, 2))
    test_rec.append(round(recall_score(y_test, y_pred, average='weighted') * 100, 2))
    test_score.append(round(knn.score(x_test_scaled, y_test) * 100, 2))

for i in range(1, 16):
    knn = KNeighborsClassifier(i)
    scores = cross_val_score(knn, x_train, y_train, cv=5)
    
param_dist = {
    'n_neighbors': np.arange(1, 16), 
    'weights': ['uniform', 'distance']
}

knn = KNeighborsClassifier()
random_search = RandomizedSearchCV(knn, param_dist, n_iter=10, cv=5)
random_search.fit(x_train, y_train)

best_model = random_search.best_estimator_
accuracy = accuracy_score(y_test, best_model.predict(x_test))

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# - Removed all original print statements, data summaries (head, info, describe), and visualizations.
# - Fixed a critical ML coding error: in the range loop (k=1 to 15), the original code attempted to calculate knn.score() using unscaled x_test data while the model was trained on x_train_scaled. This has been corrected to use x_test_scaled.
# - Maintained original algorithmic flow, including the specific imputation strategies (mean for Glucose, median for others).
# - Preserved the use of unscaled data for cross_val_score and RandomizedSearchCV to remain faithful to the provided source code's logic.
# - Calculated final accuracy using the best estimator derived from RandomizedSearchCV on the hold-out test set.