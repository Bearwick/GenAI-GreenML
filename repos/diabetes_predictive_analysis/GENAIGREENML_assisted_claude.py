# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

SEED = 42
np.random.seed(SEED)

try:
    data = pd.read_csv("diabetes.csv")
    if data.shape[1] < 2:
        raise ValueError("Too few columns")
except Exception:
    data = pd.read_csv("diabetes.csv", sep=';', decimal=',')

cols_replace_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
existing_cols = [c for c in cols_replace_zero if c in data.columns]

data[existing_cols] = data[existing_cols].replace(0, np.nan)

fill_mean = ['Glucose']
fill_median = ['BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

for col in fill_mean:
    if col in data.columns:
        data[col] = data[col].fillna(data[col].mean())

for col in fill_median:
    if col in data.columns:
        data[col] = data[col].fillna(data[col].median())

target_col = 'Outcome'
x = data.drop(target_col, axis=1).values
y = data[target_col].values

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=SEED
)

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

param_dist = {
    'n_neighbors': np.arange(1, 16),
    'weights': ['uniform', 'distance']
}

knn = KNeighborsClassifier()
random_search = RandomizedSearchCV(
    knn, param_dist, n_iter=10, cv=5, random_state=SEED, n_jobs=-1
)
random_search.fit(x_train_scaled, y_train)

best_knn = random_search.best_estimator_
y_pred = best_knn.predict(x_test_scaled)
accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Removed unused imports (matplotlib, seaborn) to reduce load time and memory.
# - Eliminated all plotting/visualization code (histograms, boxplots, heatmaps).
# - Removed redundant data.copy(); imputation is done in-place on the original dataframe.
# - Combined scaler fit and transform into fit_transform for training data (one pass).
# - Removed the loop over k=1..15 that trained 15 separate KNN models and computed metrics,
#   since RandomizedSearchCV already searches over k values and selects the best.
# - Removed the cross_val_score loop (15 iterations Ã— 5-fold) as RandomizedSearchCV covers this.
# - Used n_jobs=-1 in RandomizedSearchCV to parallelize cross-validation.
# - Used best_estimator_ from RandomizedSearchCV for final prediction, avoiding redundant retraining.
# - Removed all print/logging statements except the final accuracy output.
# - Added robust CSV parsing fallback (default then sep=';' with decimal=',').
# - Set fixed random seeds for reproducibility.
# - Removed intermediate lists (test_f1, test_pre, etc.) that stored unused results.