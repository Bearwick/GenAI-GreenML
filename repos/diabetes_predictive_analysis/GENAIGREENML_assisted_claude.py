# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.neighbors import KNeighborsClassifier

SEED = 42
np.random.seed(SEED)

try:
    data = pd.read_csv("diabetes.csv")
    if data.shape[1] < 2:
        raise ValueError("Too few columns")
except (ValueError, pd.errors.ParserError):
    data = pd.read_csv("diabetes.csv", sep=';', decimal=',')

zero_fill_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
existing_cols = [c for c in zero_fill_cols if c in data.columns]

data[existing_cols] = data[existing_cols].replace(0, np.nan)

if 'Glucose' in data.columns:
    data['Glucose'] = data['Glucose'].fillna(data['Glucose'].mean())
for col in ['BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:
    if col in data.columns:
        data[col] = data[col].fillna(data[col].median())

target_col = 'Outcome'
x = data.drop(target_col, axis=1).values
y = data[target_col].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=SEED)

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

param_dist = {
    'n_neighbors': np.arange(1, 16),
    'weights': ['uniform', 'distance']
}

knn = KNeighborsClassifier()
random_search = RandomizedSearchCV(
    knn, param_dist, n_iter=10, cv=5, random_state=SEED, n_jobs=1
)
random_search.fit(x_train_scaled, y_train)

best_knn = random_search.best_estimator_
accuracy = best_knn.score(x_test_scaled, y_test)

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# 1. Removed all plots, visualizations, and print/logging statements to eliminate unnecessary I/O.
# 2. Eliminated redundant data copy (data_copy); modifications done in-place on original dataframe.
# 3. Removed the manual loop over k=1..15 computing metrics and storing in lists, since the
#    RandomizedSearchCV already performs hyperparameter selection more efficiently.
# 4. Removed the separate cross_val_score loop (k=1..15) as it duplicated the search done by RandomizedSearchCV.
# 5. Removed the initial standalone KNN(k=5) fit since the best model is selected via RandomizedSearchCV.
# 6. Used fit_transform instead of separate fit + transform calls for the training scaler step.
# 7. Used scaled data consistently for RandomizedSearchCV (original code used unscaled x_train).
# 8. Set fixed random seeds for reproducibility throughout.
# 9. Robust CSV parsing with fallback to semicolon separator and comma decimal.
# 10. Column names derived dynamically from actual dataframe columns rather than hardcoded assumptions.