# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: autonomous

import os
import sys
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression


def _load_dataset() -> pd.DataFrame:
    candidates = []
    for root, _, files in os.walk("."):
        for f in files:
            lf = f.lower()
            if lf.endswith(".csv"):
                candidates.append(os.path.join(root, f))

    best_path = None
    best_score = -1

    expected_cols = {
        "animal_name", "hair", "feathers", "eggs", "milk", "airborne", "aquatic",
        "predator", "toothed", "backbone", "breathes", "venomous", "fins", "legs",
        "tail", "domestic", "catsize", "class_type"
    }

    for path in sorted(candidates):
        try:
            df = pd.read_csv(path)
        except Exception:
            continue
        cols = set(map(str, df.columns))
        score = len(expected_cols.intersection(cols))
        if score > best_score:
            best_score = score
            best_path = path

    if best_path is None:
        raise FileNotFoundError("No suitable CSV dataset found.")

    df = pd.read_csv(best_path)
    return df


def _prepare(df: pd.DataFrame):
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    if "class_type" not in df.columns:
        raise ValueError("Target column 'class_type' not found.")

    y = df["class_type"]
    X = df.drop(columns=["class_type"])

    for col in ["animal_name"]:
        if col in X.columns:
            X = X.drop(columns=[col])

    numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
    categorical_cols = [c for c in X.columns if c not in numeric_cols]

    numeric_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median"))
    ])

    categorical_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=True))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, numeric_cols),
            ("cat", categorical_transformer, categorical_cols),
        ],
        remainder="drop",
        sparse_threshold=0.3
    )

    model = LogisticRegression(
        solver="saga",
        penalty="l2",
        C=1.0,
        max_iter=2000,
        n_jobs=1,
        random_state=42
    )

    pipe = Pipeline(steps=[
        ("preprocess", preprocessor),
        ("model", model)
    ])

    return X, y, pipe


def main():
    df = _load_dataset()
    X, y, pipe = _prepare(df)

    y_values = y.to_numpy()
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_values,
            test_size=0.2,
            random_state=42,
            stratify=y_values if len(np.unique(y_values)) > 1 else None
        )
    except ValueError:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_values,
            test_size=0.2,
            random_state=42
        )

    pipe.fit(X_train, y_train)
    preds = pipe.predict(X_test)
    accuracy = accuracy_score(y_test, preds)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()