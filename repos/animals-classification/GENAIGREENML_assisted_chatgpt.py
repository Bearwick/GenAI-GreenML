# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd

from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC


RANDOM_SEED = 0
DATASET_PATH = "zoo.csv"
DATASET_HEADERS = [
    "animal_name",
    "hair",
    "feathers",
    "eggs",
    "milk",
    "airborne",
    "aquatic",
    "predator",
    "toothed",
    "backbone",
    "breathes",
    "venomous",
    "fins",
    "legs",
    "tail",
    "domestic",
    "catsize",
    "class_type",
]


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] == 1 or (df.columns.size == 1 and ";" in str(df.columns[0])):
        df = pd.read_csv(path, sep=";", decimal=",")
    if df.columns.size == 1 and df.shape[0] > 0 and "," in str(df.iloc[0, 0]):
        df = pd.read_csv(path, sep=",")
    return df


def _resolve_columns(df: pd.DataFrame) -> tuple[list[str], str]:
    cols = list(df.columns)
    class_candidates = [c for c in cols if c.lower() == "class_type"]
    y_col = class_candidates[0] if class_candidates else (DATASET_HEADERS[-1] if DATASET_HEADERS[-1] in cols else cols[-1])

    animal_candidates = [c for c in cols if c.lower() == "animal_name"]
    animal_col = animal_candidates[0] if animal_candidates else (DATASET_HEADERS[0] if DATASET_HEADERS[0] in cols else cols[0])

    feature_cols = [c for c in cols if c not in (animal_col, y_col)]
    return feature_cols, y_col


def main() -> None:
    np.random.seed(RANDOM_SEED)

    dataset = _read_csv_robust(DATASET_PATH)
    feature_cols, y_col = _resolve_columns(dataset)

    X = dataset.loc[:, feature_cols].to_numpy(copy=False)
    y = dataset.loc[:, y_col].to_numpy(copy=False)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=RANDOM_SEED
    )

    classifier = SVC()
    classifier.fit(X_train, y_train)

    y_pred = classifier.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    accuracy = float(np.trace(cm) / cm.sum()) if cm.size else 0.0

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused libraries (seaborn/matplotlib) and all visualization to cut import overhead and runtime.
# - Avoided redundant computations: removed unused head(), score(), and extra predict slice; kept only the prediction needed for evaluation.
# - Replaced manual class-index accuracy computation with trace(cm)/sum(cm), preserving the same intent while handling any number of classes efficiently.
# - Reduced unnecessary data movement by using pandas .to_numpy(copy=False) to avoid copying when possible.
# - Implemented robust CSV parsing with a fallback delimiter/decimal strategy to prevent re-runs and parsing-related failures.
# - Ensured reproducibility by setting a fixed numpy seed and using the same train_test_split random_state as the original.