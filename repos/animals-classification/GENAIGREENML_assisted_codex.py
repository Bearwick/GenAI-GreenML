# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
import random
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

DATASET_PATH = "zoo.csv"
DATASET_HEADERS = "animal_name,hair,feathers,eggs,milk,airborne,aquatic,predator,toothed,backbone,breathes,venomous,fins,legs,tail,domestic,catsize,class_type"

def load_dataset(path):
    df = pd.read_csv(path)
    expected_headers = [h.strip() for h in DATASET_HEADERS.split(",") if h.strip()]
    if df.shape[1] == 1 or (len(expected_headers) > 1 and df.shape[1] < len(expected_headers)):
        df_alt = pd.read_csv(path, sep=";", decimal=",")
        if df_alt.shape[1] > df.shape[1]:
            df = df_alt
    return df

def extract_features_target(df):
    expected_headers = [h.strip() for h in DATASET_HEADERS.split(",") if h.strip()]
    if set(expected_headers).issubset(df.columns):
        ordered_cols = expected_headers
    else:
        ordered_cols = list(df.columns)
    target_col = "class_type" if "class_type" in df.columns else ordered_cols[-1]
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if target_col in numeric_cols:
        feature_cols = [c for c in numeric_cols if c != target_col]
        if not feature_cols:
            feature_cols = [c for c in ordered_cols if c != target_col]
    else:
        feature_cols = [c for c in ordered_cols if c != target_col]
    X = df[feature_cols].values
    y = df[target_col].values
    return X, y

def main():
    np.random.seed(0)
    random.seed(0)
    df = load_dataset(DATASET_PATH)
    X, y = extract_features_target(df)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)
    classifier = SVC()
    classifier.fit(X_train, y_train)
    y_pred = classifier.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused libraries, plotting, and redundant predictions to cut runtime and memory use.
# - Added robust CSV parsing with a lightweight fallback to prevent costly read errors.
# - Derived feature/target columns from actual schema and numeric types to avoid unnecessary data movement.
# - Computed accuracy directly without building a confusion matrix to reduce computation.
# - Fixed random seeds for reproducible, deterministic behavior.