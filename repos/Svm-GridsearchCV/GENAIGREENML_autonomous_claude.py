# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
import warnings
warnings.filterwarnings("ignore")

DATASET_PATH = "bodyPerformance.csv"

# Robust CSV loading
df = None
try:
    df = pd.read_csv(DATASET_PATH)
    if df.shape[1] < 3:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')
except Exception:
    try:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')
    except Exception as e:
        raise RuntimeError(f"Cannot parse CSV: {e}")

# Normalize column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df.loc[:, ~df.columns.str.startswith('Unnamed')]

# Identify columns from expected schema
expected_headers = [
    "age", "height_cm", "weight_kg", "body fat_%", "diastolic", "systolic",
    "gripForce", "sit and bend forward_cm", "sit-ups counts", "broad jump_cm", "Blass"
]

# Map expected to actual columns (case-insensitive fuzzy match)
col_map = {}
actual_lower = {c.lower().strip(): c for c in df.columns}
for eh in expected_headers:
    key = eh.lower().strip()
    if key in actual_lower:
        col_map[eh] = actual_lower[key]

# Determine target column
target_col = None
target_candidates = ["Blass", "class", "Class", "blass"]
for tc in target_candidates:
    tc_lower = tc.lower().strip()
    if tc_lower in actual_lower:
        target_col = actual_lower[tc_lower]
        break

# If no known target found, try to find a categorical column with few unique values
if target_col is None:
    for c in df.columns:
        if df[c].dtype == object and df[c].nunique() < 20:
            target_col = c
            break

# If still no target, use last column
if target_col is None:
    target_col = df.columns[-1]

# Separate features and target
feature_cols = [c for c in df.columns if c != target_col]

# Determine if classification or regression
is_classification = False
if df[target_col].dtype == object or df[target_col].nunique() <= 20:
    is_classification = True

# Coerce numeric columns
for c in feature_cols:
    if df[c].dtype == object:
        try:
            df[c] = pd.to_numeric(df[c].str.replace(',', '.'), errors='coerce')
        except Exception:
            pass

# Identify numeric and categorical features
numeric_features = [c for c in feature_cols if df[c].dtype in [np.float64, np.int64, np.float32, np.int32]]
categorical_features = [c for c in feature_cols if df[c].dtype == object]

# For target: encode if classification
if is_classification:
    le = LabelEncoder()
    df[target_col] = le.fit_transform(df[target_col].astype(str))

# Drop rows with NaN in target
df = df.dropna(subset=[target_col])

# Handle inf values
df = df.replace([np.inf, -np.inf], np.nan)

# For numeric features, coerce and fill NaN with median
for c in numeric_features:
    df[c] = pd.to_numeric(df[c], errors='coerce')
    median_val = df[c].median()
    if pd.isna(median_val):
        median_val =