# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import re
import pickle
import warnings
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.metrics import accuracy_score, r2_score

warnings.filterwarnings("ignore")

path = "dict.pickle"
data_obj = None
ext = os.path.splitext(path)[1].lower()
if ext in [".pickle", ".pkl"]:
    try:
        with open(path, "rb") as f:
            data_obj = pickle.load(f)
    except Exception:
        data_obj = None

if data_obj is None:
    try:
        df_try = pd.read_csv(path)
        if df_try.shape[1] == 1:
            sample = df_try.iloc[:, 0].astype(str).head(5)
            if sample.str.contains(";").any():
                df_try = pd.read_csv(path, sep=";", decimal=",")
        data_obj = df_try
    except Exception:
        try:
            data_obj = pd.read_csv(path, sep=";", decimal=",")
        except Exception:
            try:
                data_obj = pd.read_pickle(path)
            except Exception:
                data_obj = None

def obj_to_df(obj):
    if isinstance(obj, pd.DataFrame):
        return obj
    if hasattr(obj, "data") and hasattr(obj, "target"):
        try:
            df_local = pd.DataFrame(obj.data)
            df_local["target"] = obj.target
            return df_local
        except Exception:
            pass
    if isinstance(obj, dict):
        if "X_train" in obj and "y_train" in obj:
            try:
                df_train = pd.DataFrame(obj["X_train"])
                df_train["target"] = obj["y_train"]
                if "X_test" in obj and "y_test" in obj:
                    df_test = pd.DataFrame(obj["X_test"])
                    df_test["target"] = obj["y_test"]
                    return pd.concat([df_train, df_test], ignore_index=True)
                return df_train
            except Exception:
                pass
        for kx in ["data", "X", "features"]:
            for ky in ["target", "y", "labels", "label"]:
                if kx in obj and ky in obj:
                    try:
                        df_local = pd.DataFrame(obj[kx])
                        df_local["target"] = obj[ky]
                        return df_local
                    except Exception:
                        pass
        try:
            return pd.DataFrame(obj)
        except Exception:
            try:
                return pd.DataFrame(list(obj.items()), columns=["key", "value"])
            except Exception:
                return pd.DataFrame()
    if isinstance(obj, (list, tuple)):
        if isinstance(obj, tuple) and len(obj) == 2:
            try:
                df_local = pd.DataFrame(obj[0])
                df_local["target"] = obj[1]
                return df_local
            except Exception:
                pass
        try:
            return pd.DataFrame(obj)
        except Exception:
            return pd.DataFrame({"value": list(obj)})
    if isinstance(obj, np.ndarray):
        return pd.DataFrame(obj)
    try:
        return pd.DataFrame(obj)
    except Exception:
        return pd.DataFrame()

df = obj_to_df(data_obj)
if df is None:
    df = pd.DataFrame()
df = df.copy()
if df.shape[1] == 0:
    df["feature"] = np.zeros(len(df))
    df["target"] = 0

new_cols = []
for c in df.columns:
    c_str = str(c)
    c_str = re.sub(r"\s+", " ", c_str.strip())
    new_cols.append(c_str)
df.columns = new_cols
df = df.loc[:, ~df.columns.str.match(r"^Unnamed")]
df = df.dropna(axis=1, how="all")
if df.columns.duplicated().any():
    counts = {}
    cols = []
    for c in df.columns:
        if c in counts:
            counts[c] += 1
            cols.append(f"{c}_{counts[c]}")
        else:
            counts[c] = 0
            cols.append(c)
    df.columns = cols

assert df.shape[0] > 0

def select_target_column(df_local):
    candidates = ["target", "label", "labels", "class", "y", "output", "outcome", "result", "prediction"]
    cols_lower = [c.lower() for c in df_local.columns]
    for cand in candidates:
        for col, col_l in zip(df_local.columns, cols_lower):
            if col_l == cand or col_l.endswith(cand) or cand in col_l:
                return col
    numeric_df = df_local.apply(lambda s: pd.to_numeric(s, errors="coerce"))
    numeric_cols = [col for col in df_local.columns if numeric_df[col].notna().sum() > 0]
    if numeric_cols:
        numeric_nunique = numeric_df[numeric_cols].nunique(dropna=True)
        numeric_nunique = numeric_nunique[numeric_nunique > 1]
        if len(numeric_nunique) > 0:
            return numeric_nunique.sort_values().index[0]
    nunique = df_local.nunique(dropna=True)
    nunique = nunique[nunique > 1]
    if len(nunique) > 0:
        return nunique.sort_values().index[0]
    return df_local.columns[-1]

if df.shape[1] == 1:
    target_col = df.columns[0]
    X = pd.DataFrame({"feature": np.zeros(len(df))})
    y = df[target_col]
else:
    target_col = select_target_column(df)
    X = df.drop(columns=[target_col])
    y = df[target_col]
    if X.shape[1] == 0:
        X = pd.DataFrame({"feature": np.zeros(len(df))})

y = y.replace([np.inf, -np.inf], np.nan)
mask = y.notna()
if mask.sum() == 0:
    y = pd.Series(np.zeros(len(y)), index=y.index)
else:
    X = X.loc[mask].copy()
    y = y.loc[mask].copy()

assert len(X) > 0

n_unique = y.nunique(dropna=True)
is_classification = False
if n_unique >= 2:
    if y.dtype == object or y.dtype.name == "category" or y.dtype == bool:
        is_classification = True
    else:
        if n_unique <= 20:
            is_classification = True
if n_unique < 2:
    is_classification = False

if not is_classification:
    y_num = pd.to_numeric(y, errors="coerce")
    if y_num.isna().all():
        y_num = pd.Series(pd.factorize(y)[0], index=y.index).astype(float)
    else:
        if y_num.notna().any():
            y_num = y_num.fillna(y_num.median())
        else:
            y_num = y_num.fillna(0)
    y = y_num

X = X.copy()
numeric_candidate = X.apply(lambda s: pd.to_numeric(s, errors="coerce"))
n_rows = len(X)
numeric_cols = []
categorical_cols = []
for col in X.columns:
    non_na = numeric_candidate[col].notna().sum()
    if non_na > 0 and non_na >= max(1, int(0.5 * n_rows)):
        numeric_cols.append(col)
    else:
        categorical_cols.append(col)

if numeric_cols:
    X[numeric_cols] = numeric_candidate[numeric_cols]
if categorical_cols:
    for col in categorical_cols:
        X[col] = X[col].astype(str)

X.replace([np.inf, -np.inf], np.nan, inplace=True)

n_samples = len(X)
if n_samples < 2:
    X_train = X.copy()
    X_test = X.copy()
    y_train = y.copy()
    y_test = y.copy()
else:
    test_size = 0.2 if n_samples >= 5 else 1
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

assert len(X_train) > 0 and len(X_test) > 0

if is_classification and y_train.nunique(dropna=True) < 2:
    is_classification = False
    y_all = pd.concat([y_train, y_test])
    y_all_num = pd.to_numeric(y_all, errors="coerce")
    if y_all_num.isna().all():
        y_all_num = pd.Series(pd.factorize(y_all)[0], index=y_all.index).astype(float)
    else:
        if y_all_num.notna().any():
            y_all_num = y_all_num.fillna(y_all_num.median())
        else:
            y_all_num = y_all_num.fillna(0)
    y_train = y_all_num.loc[y_train.index]
    y_test = y_all_num.loc[y_test.index]

transformers = []
if numeric_cols:
    numeric_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler(with_mean=False))
    ])
    transformers.append(("num", numeric_transformer, numeric_cols))
if categorical_cols:
    categorical_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse=True))
    ])
    transformers.append(("cat", categorical_transformer, categorical_cols))
if transformers:
    preprocessor = ColumnTransformer(transformers=transformers, remainder="drop")
else:
    preprocessor = FunctionTransformer(lambda x: np.zeros((len(x), 1)))

if is_classification:
    model = LogisticRegression(max_iter=200, solver="liblinear")
else:
    model = Ridge(alpha=1.0)

clf = Pipeline(steps=[("preprocess", preprocessor), ("model", model)])
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
if is_classification:
    accuracy = accuracy_score(y_test, y_pred)
else:
    r2 = r2_score(y_test, y_pred)
    if r2 != r2:
        r2 = 0.0
    accuracy = max(0.0, min(1.0, (r2 + 1.0) / 2.0))

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Used lightweight linear models (LogisticRegression/Ridge) for CPU-efficient training and inference.
# - Applied minimal, reproducible preprocessing (imputation, scaling, one-hot encoding) via ColumnTransformer.
# - Avoided heavy models and mapped R2 to a bounded [0,1] accuracy proxy for regression fallback.