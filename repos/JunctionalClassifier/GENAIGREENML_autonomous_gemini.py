# Generated by generate_llm_code.py
# LLM: gemini
# Mode: autonomous

import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

data = load_breast_cancer()
X, y = data.data, data.target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = LogisticRegression(
    penalty='l2',
    C=0.5,
    solver='lbfgs',
    max_iter=500,
    random_state=42,
    tol=1e-4
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Model Choice: Logistic Regression was selected as it is computationally inexpensive, requiring minimal CPU cycles compared to deep learning or ensemble methods.
# 2. Dataset handling: The Breast Cancer dataset is small and tabular, making lightweight linear solvers ideal for maximizing energy efficiency.
# 3. Feature Scaling: StandardScaler was used to ensure fast convergence of the optimization algorithm, reducing the number of iterations and power consumption.
# 4. Solver Selection: The 'lbfgs' solver is used for its memory-efficient handling of the Hessian matrix, suitable for small to medium datasets on CPU.
# 5. Complexity Reduction: L2 regularization and a moderate 'C' value help prevent overfitting while maintaining a simple model structure that executes in milliseconds.
# 6. Green Coding: By avoiding deep learning frameworks (TensorFlow/PyTorch) and high-dimensional embeddings, the solution minimizes the environmental footprint of the training process.