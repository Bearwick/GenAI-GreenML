# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import SVC


RANDOM_SEED = 1000


def _read_csv_robust(path: str, expected_headers):
    df = pd.read_csv(path)
    cols = [c.strip() for c in df.columns.astype(str)]
    df.columns = cols

    expected = {h.strip() for h in expected_headers}
    if not expected.issubset(set(df.columns)):
        df = pd.read_csv(path, sep=";", decimal=",")
        df.columns = [c.strip() for c in df.columns.astype(str)]
    return df


def _get_required_columns(df: pd.DataFrame, expected_headers):
    cols = {c.strip(): c for c in df.columns.astype(str)}
    required = []
    for h in expected_headers:
        hs = h.strip()
        if hs not in cols:
            raise KeyError(f"Missing required column: {hs}. Found columns: {list(df.columns)}")
        required.append(cols[hs])
    return required


def main():
    DATASET_HEADERS = ["text", "spam"]
    df = _read_csv_robust("emails.csv", DATASET_HEADERS)
    text_col, label_col = _get_required_columns(df, DATASET_HEADERS)

    X = df[text_col].astype(str)
    y = df[label_col]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_SEED
    )

    vectorizer = CountVectorizer()
    X_train_features = vectorizer.fit_transform(X_train)

    model = SVC()
    model.fit(X_train_features, y_train)

    X_test_features = vectorizer.transform(X_test)
    accuracy = model.score(X_test_features, y_test)

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed all intermediate prints and head()/shape calls to avoid extra CPU work and I/O overhead.
# - Eliminated unused predict_email and other non-essential code paths to reduce runtime and memory.
# - Loaded only required columns logically (derived via DATASET_HEADERS/df.columns) and cast text to str once to prevent repeated conversions.
# - Kept sparse matrices from CountVectorizer end-to-end to minimize memory footprint and data movement.
# - Ensured reproducibility with a fixed random seed in train_test_split.
# - Added robust CSV parsing fallback (default, then sep=';' and decimal=',') to avoid costly manual fixes and reruns.