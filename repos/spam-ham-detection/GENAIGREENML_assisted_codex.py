# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
import random
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import svm

SEED = 1000
random.seed(SEED)
np.random.seed(SEED)

DATASET_PATH = "emails.csv"
DATASET_HEADERS = '"text","spam"'
EXPECTED_HEADERS = [h.strip().strip('"').strip("'") for h in DATASET_HEADERS.split(",") if h.strip()]

def _normalize(col):
    c = str(col).strip()
    if (c.startswith('"') and c.endswith('"')) or (c.startswith("'") and c.endswith("'")):
        c = c[1:-1]
    return c.strip().lower()

def _has_expected(df, expected):
    norm_cols = [_normalize(c) for c in df.columns]
    return all(_normalize(h) in norm_cols for h in expected)

def _standardize_columns(df, expected):
    norm_cols = [_normalize(c) for c in df.columns]
    rename_map = {}
    for h in expected:
        hn = _normalize(h)
        if hn in norm_cols:
            idx = norm_cols.index(hn)
            rename_map[df.columns[idx]] = h
    if rename_map:
        df = df.rename(columns=rename_map)
    return df

def _read_csv(path, sep=None, decimal=None):
    try:
        return pd.read_csv(path, sep=sep, decimal=decimal)
    except Exception:
        return None

def read_dataset(path, expected):
    df = _read_csv(path)
    if df is None or not _has_expected(df, expected):
        df_alt = _read_csv(path, sep=";", decimal=",")
        if df_alt is not None:
            if df is None or _has_expected(df_alt, expected):
                df = df_alt
    if df is None:
        raise ValueError("Dataset could not be read")
    df = _standardize_columns(df, expected)
    if not _has_expected(df, expected) and df.shape[1] >= len(expected):
        rename_map = {df.columns[i]: expected[i] for i in range(len(expected))}
        df = df.rename(columns=rename_map)
    return df

def _get_column(df, expected, index):
    if index < len(expected) and expected[index] in df.columns:
        return expected[index]
    if index < len(expected):
        en = _normalize(expected[index])
        for col in df.columns:
            if _normalize(col) == en:
                return col
    if df.shape[1] > index:
        return df.columns[index]
    return df.columns[0]

df = read_dataset(DATASET_PATH, EXPECTED_HEADERS)

text_col = _get_column(df, EXPECTED_HEADERS, 0)
spam_col = _get_column(df, EXPECTED_HEADERS, 1)

x_train, x_test, y_train, y_test = train_test_split(
    df[text_col],
    df[spam_col],
    test_size=0.2,
    random_state=SEED
)

vectorizer = CountVectorizer()
x_train_vec = vectorizer.fit_transform(x_train)

model = svm.SVC()
model.fit(x_train_vec, y_train)

x_test_vec = vectorizer.transform(x_test)
accuracy = model.score(x_test_vec, y_test)

def predict_email(text):
    text_feature = vectorizer.transform([text])
    prediction = model.predict(text_feature)
    return prediction[0]

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Removed all non-essential outputs to reduce I/O overhead while preserving required accuracy reporting.
# - Implemented robust CSV loading with a single fallback and standardized column handling to avoid redundant parsing.
# - Selected columns directly during splitting to reduce intermediate data movement and memory usage.
# - Fixed random seeds for deterministic results without additional computation.