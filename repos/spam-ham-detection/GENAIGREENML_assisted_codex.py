# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
import random
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import svm

SEED = 1000
random.seed(SEED)
np.random.seed(SEED)

EXPECTED_HEADERS = ["text", "spam"]

def parsing_seems_wrong(df, expected_headers):
    if df is None or df.empty:
        return True
    cols = [str(c).strip().lower() for c in df.columns]
    expected = [h.lower() for h in expected_headers]
    if any(h in cols for h in expected):
        return False
    if len(df.columns) < len(expected_headers) or len(df.columns) == 1:
        return True
    return False

def read_csv_robust(path, expected_headers):
    df = pd.read_csv(path)
    if parsing_seems_wrong(df, expected_headers):
        df_alt = pd.read_csv(path, sep=';', decimal=',')
        if not df_alt.empty:
            df = df_alt
    return df

def resolve_columns(df, expected_headers):
    lower_cols = {str(c).strip().lower(): c for c in df.columns}
    used = set()
    resolved = {}
    for idx, h in enumerate(expected_headers):
        col = lower_cols.get(h.lower())
        if col is None:
            if idx < len(df.columns) and df.columns[idx] not in used:
                col = df.columns[idx]
            else:
                col = next((c for c in df.columns if c not in used), df.columns[0])
        resolved[h] = col
        used.add(col)
    return resolved

df = read_csv_robust("emails.csv", EXPECTED_HEADERS)
col_map = resolve_columns(df, EXPECTED_HEADERS)

x = df[col_map["text"]]
y = df[col_map["spam"]]

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=SEED
)

cv = CountVectorizer()
x_train_vec = cv.fit_transform(x_train)

model = svm.SVC(random_state=SEED)
model.fit(x_train_vec, y_train)

x_test_vec = cv.transform(x_test)
accuracy = model.score(x_test_vec, y_test)

def predict_email(text):
    text_feature = cv.transform([text])
    pred = model.predict(text_feature)
    return pred[0]

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Removed verbose output and redundant dataset inspections to cut I/O and CPU overhead.
# - Added robust CSV parsing with fallback to reduce manual preprocessing and ensure correct loading.
# - Reused a single vectorizer instance to avoid repeated feature extraction and data movement.
# - Set deterministic seeds for reproducible results without altering model behavior.
# - Simplified column resolution to minimize unnecessary data copies and keep memory usage low.