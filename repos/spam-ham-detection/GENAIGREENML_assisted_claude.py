# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import svm

df = pd.read_csv("emails.csv")
if df.shape[1] < 2:
    df = pd.read_csv("emails.csv", sep=";", decimal=",")

text_col = df.columns[0]
label_col = df.columns[1]

x = df[text_col]
y = df[label_col]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1000)

cv = CountVectorizer()
features = cv.fit_transform(x_train)

model = svm.SVC()
model.fit(features, y_train)

feature_test = cv.transform(x_test)
accuracy = model.score(feature_test, y_test)

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# Removed all print statements except the required accuracy output.
# Removed interactive user input loop (predict_email + exit loop).
# Removed plots and visualizations (none present originally).
# No artifacts saved to disk.
# Robust CSV fallback: tries default separator, falls back to sep=';' and decimal=','.
# Column names derived from df.columns instead of hardcoded strings.
# Eliminated unused predict_email function to reduce code footprint.
# Fixed random_state for reproducibility.
# Kept same dataset, task, model (SVM with default RBF kernel), and CountVectorizer.
# Removed redundant intermediate variables and duplicate head/shape prints.