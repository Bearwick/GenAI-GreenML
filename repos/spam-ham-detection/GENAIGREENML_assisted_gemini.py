# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import svm

def run_pipeline():
    try:
        df = pd.read_csv('emails.csv')
        if 'text' not in df.columns:
            raise ValueError
    except Exception:
        df = pd.read_csv('emails.csv', sep=';', decimal=',')

    text_col = 'text' if 'text' in df.columns else df.columns[0]
    target_col = 'spam' if 'spam' in df.columns else df.columns[1]

    x_train, x_test, y_train, y_test = train_test_split(
        df[text_col], 
        df[target_col], 
        test_size=0.2, 
        random_state=1000
    )

    cv = CountVectorizer()
    features_train = cv.fit_transform(x_train)

    linear_model = svm.SVC(cache_size=1000)
    linear_model.fit(features_train, y_train)

    features_test = cv.transform(x_test)
    accuracy = linear_model.score(features_test, y_test)

    print(f"ACCURACY={accuracy:.6f}")
    return cv, linear_model

cv, linear_model = run_pipeline()

def predict_email(text):
    text_feature = cv.transform([text])
    prediction = linear_model.predict(text_feature)
    return prediction[0]

# Optimization Summary
# 1. Removed all redundant print statements and I/O operations to reduce CPU wait time and energy consumption.
# 2. Implemented robust CSV loading with a fallback mechanism to handle potential delimiter issues efficiently.
# 3. Eliminated intermediate data structures and duplicate dataframe references to minimize memory footprint.
# 4. Increased SVC cache_size to 1000MB to reduce kernel matrix re-computation during the training phase.
# 5. Preserved the original SVC model and CountVectorizer to maintain the exact behavior and accuracy metrics.
# 6. Encapsulated the main logic into a function to localize variables and allow for better memory management by the garbage collector.
# 7. Fixed the random_state to ensure reproducibility while maintaining the original split logic.
# 8. Optimized the data selection process by dynamically identifying columns based on the provided schema.