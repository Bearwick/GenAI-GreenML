# Generated by generate_llm_code.py
# LLM: groq
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from collections import Counter

# Load data
data = pd.read_csv('heart_failure.csv')

# Target and features
y = data['death_event'].astype(int)
x = data[['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',
          'ejection_fraction', 'high_blood_pressure', 'platelets',
          'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']]
x = pd.get_dummies(x, drop_first=True)

# Train-test split
X_train, X_test, Y_train, Y_test = train_test_split(
    x, y, test_size=0.3, random_state=0, stratify=y)

# Numerical columns for scaling
num_cols = ['age', 'creatinine_phosphokinase', 'ejection_fraction',
            'platelets', 'serum_creatinine', 'serum_sodium', 'time']

# Pipeline: scale numeric features then fit logistic regression
pipe = Pipeline(steps=[
    ('scaler', ColumnTransformer([('num', StandardScaler(), num_cols)])),
    ('clf', LogisticRegression(max_iter=200, n_jobs=-1, solver='lbfgs'))
])

# Fit model
pipe.fit(X_train, Y_train)

# Evaluate
pred = pipe.predict(X_test)
acc = accuracy_score(Y_test, pred)
print(f"ACCURACY={acc:.6f}")

# Optional: class distribution
print("Classes and number of values in the dataset", Counter(y))