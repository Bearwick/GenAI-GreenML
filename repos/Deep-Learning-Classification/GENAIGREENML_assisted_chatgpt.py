# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.layers import Dense, InputLayer
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical


def set_reproducible(seed: int = 0) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    os.environ["TF_DETERMINISTIC_OPS"] = "1"
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)


def load_data(path: str):
    data = pd.read_csv(path)

    y = data["death_event"].to_numpy(dtype=np.int32)
    feature_cols = [
        "age",
        "anaemia",
        "creatinine_phosphokinase",
        "diabetes",
        "ejection_fraction",
        "high_blood_pressure",
        "platelets",
        "serum_creatinine",
        "serum_sodium",
        "sex",
        "smoking",
        "time",
    ]
    x = data[feature_cols]

    return x, y


def split_and_preprocess(x: pd.DataFrame, y: np.ndarray, seed: int = 0):
    X_train, X_test, y_train, y_test = train_test_split(
        x, y, test_size=0.3, random_state=seed
    )

    numeric_features = [
        "age",
        "creatinine_phosphokinase",
        "ejection_fraction",
        "platelets",
        "serum_creatinine",
        "serum_sodium",
        "time",
    ]
    preprocess = ColumnTransformer(
        transformers=[("num", StandardScaler(), numeric_features)],
        remainder="passthrough",
        sparse_threshold=0.0,
    )

    X_train = preprocess.fit_transform(X_train).astype(np.float32, copy=False)
    X_test = preprocess.transform(X_test).astype(np.float32, copy=False)

    y_train_cat = to_categorical(y_train, num_classes=2)
    y_test_cat = to_categorical(y_test, num_classes=2)

    return X_train, X_test, y_train_cat, y_test_cat, y_test


def build_model(input_dim: int) -> Sequential:
    model = Sequential(
        [
            InputLayer(shape=(input_dim,)),
            Dense(12, activation="relu"),
            Dense(2, activation="softmax"),
        ]
    )
    model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
    return model


def main() -> None:
    seed = 0
    set_reproducible(seed)

    x, y = load_data("heart_failure.csv")
    X_train, X_test, Y_train, Y_test, y_test_raw = split_and_preprocess(x, y, seed=seed)

    model = build_model(X_train.shape[1])

    model.fit(X_train, Y_train, epochs=100, batch_size=16, verbose=0)
    y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)

    accuracy = accuracy_score(y_test_raw, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# Removed non-essential prints, reports, plots, and model saving to reduce I/O and runtime overhead.
# Eliminated redundant get_dummies call (all selected features are numeric/binary already), avoiding extra memory and CPU work.
# Used ColumnTransformer with remainder="passthrough" to scale only numeric columns while keeping others without extra dataframe copies.
# Converted features to float32 to reduce memory bandwidth and computation cost while preserving model behavior.
# Dropped LabelEncoder + string casting; labels are already binary ints, so direct one-hot encoding avoids unnecessary conversions.
# Set global seeds and deterministic flags for stable, reproducible results (prevents retraining variability and wasted reruns).
# Set training verbose=0 to reduce console I/O overhead during epochs while keeping the same training procedure.