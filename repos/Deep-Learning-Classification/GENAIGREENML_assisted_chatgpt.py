# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
from typing import List, Tuple

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.layers import Dense, InputLayer
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical
import tensorflow as tf

DATASET_PATH = "heart_failure.csv"
DATASET_HEADERS = [
    "",
    "age",
    "anaemia",
    "creatinine_phosphokinase",
    "diabetes",
    "ejection_fraction",
    "high_blood_pressure",
    "platelets",
    "serum_creatinine",
    "serum_sodium",
    "sex",
    "smoking",
    "time",
    "DEATH_EVENT",
    "death_event",
]


def set_reproducible(seed: int = 0) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    try:
        tf.config.experimental.enable_op_determinism()
    except Exception:
        pass


def _read_csv_with_fallback(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _resolve_target_column(df: pd.DataFrame, headers: List[str]) -> str:
    candidates = [c for c in ["death_event", "DEATH_EVENT"] if c in df.columns]
    if candidates:
        return candidates[0]

    lowered = {c.lower(): c for c in df.columns}
    for c in ["death_event", "death event", "death-event", "death"]:
        if c in lowered:
            return lowered[c]

    header_candidates = [h for h in headers if h and h in df.columns]
    for h in header_candidates[::-1]:
        if "death" in h.lower():
            return h

    raise ValueError(f"Could not resolve target column. Available columns: {list(df.columns)}")


def _resolve_feature_columns(df: pd.DataFrame, target_col: str, headers: List[str]) -> List[str]:
    preferred = [
        "age",
        "anaemia",
        "creatinine_phosphokinase",
        "diabetes",
        "ejection_fraction",
        "high_blood_pressure",
        "platelets",
        "serum_creatinine",
        "serum_sodium",
        "sex",
        "smoking",
        "time",
    ]
    features = [c for c in preferred if c in df.columns and c != target_col]
    if features:
        return features

    header_features = [h for h in headers if h and h in df.columns and h != target_col and "death" not in h.lower()]
    if header_features:
        return header_features

    return [c for c in df.columns if c != target_col]


def _make_preprocessor(numeric_features: List[str]) -> ColumnTransformer:
    return ColumnTransformer(
        transformers=[("numeric", StandardScaler(), numeric_features)],
        remainder="drop",
        sparse_threshold=0.0,
    )


def build_model(input_dim: int) -> Sequential:
    model = Sequential(
        [
            InputLayer(shape=(input_dim,)),
            Dense(12, activation="relu"),
            Dense(2, activation="softmax"),
        ]
    )
    model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
    return model


def main() -> None:
    set_reproducible(seed=0)

    df = _read_csv_with_fallback(DATASET_PATH)
    target_col = _resolve_target_column(df, DATASET_HEADERS)
    feature_cols = _resolve_feature_columns(df, target_col, DATASET_HEADERS)

    X = df.loc[:, feature_cols]
    y = df[target_col]

    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(
        X, y, test_size=0.3, random_state=0
    )

    numeric_features = [c for c in ["age", "creatinine_phosphokinase", "ejection_fraction", "platelets", "serum_creatinine", "serum_sodium", "time"] if c in X_train_raw.columns]
    preprocessor = _make_preprocessor(numeric_features)

    X_train = preprocessor.fit_transform(X_train_raw)
    X_test = preprocessor.transform(X_test_raw)

    le = LabelEncoder()
    y_train_enc = le.fit_transform(y_train_raw.astype(str))
    y_test_enc = le.transform(y_test_raw.astype(str))
    y_train = to_categorical(y_train_enc, num_classes=2)
    y_test = to_categorical(y_test_enc, num_classes=2)

    model = build_model(input_dim=X_train.shape[1])
    model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=0)

    y_prob = model.predict(X_test, verbose=0)
    y_pred = np.argmax(y_prob, axis=1)
    y_true = np.argmax(y_test, axis=1)

    accuracy = accuracy_score(y_true, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed all non-essential prints, reports, and verbose training output to reduce I/O overhead and runtime noise.
# - Dropped pd.get_dummies because selected features are already numeric/binary; avoids unnecessary data expansion and memory use while preserving outputs.
# - Used ColumnTransformer with sparse_threshold=0.0 to return dense arrays directly, avoiding extra conversions and potential sparse overhead for small dense data.
# - Limited preprocessing to the required numeric subset (derived from available columns) to prevent redundant computation on irrelevant/missing columns.
# - Enforced reproducibility via fixed seeds and deterministic TensorFlow ops when available for stable results across runs.
# - Computed only accuracy (the required final output) to avoid generating large intermediate text artifacts (classification_report).