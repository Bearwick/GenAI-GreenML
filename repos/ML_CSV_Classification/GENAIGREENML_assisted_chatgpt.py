# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


SEED = 42
DATASET_HEADERS = None


def _read_csv_robust(file_path: str) -> pd.DataFrame:
    df = pd.read_csv(file_path)
    if df.shape[1] <= 1:
        df = pd.read_csv(file_path, sep=";", decimal=",")
    return df


def load_data(file_path: str):
    df = _read_csv_robust(file_path)

    if df.shape[1] < 2:
        raise ValueError("CSV must contain at least 2 columns (features + label).")

    X = df.iloc[:, :-1].to_numpy(dtype=np.float32, copy=False)
    y = df.iloc[:, -1].to_numpy(copy=False)

    if y.dtype.kind in {"f", "i", "u"}:
        y = y.astype(np.int64, copy=False)
    else:
        y = pd.factorize(y, sort=True)[0].astype(np.int64, copy=False)

    return X, y, df.columns.to_list()


def preprocess_data(X: np.ndarray):
    scaler = StandardScaler(copy=False)
    X_scaled = scaler.fit_transform(X)
    return X_scaled, scaler


def build_model():
    return RandomForestClassifier(
        n_estimators=100,
        class_weight="balanced",
        random_state=SEED,
        n_jobs=-1,
    )


def cross_validate_model(X: np.ndarray, y: np.ndarray):
    model = build_model()
    cross_val_score(model, X, y, cv=5, n_jobs=-1)


def train_model(X_train: np.ndarray, y_train: np.ndarray):
    model = build_model()
    model.fit(X_train, y_train)
    return model


def evaluate_model(model, X_test: np.ndarray, y_test: np.ndarray) -> float:
    y_pred = model.predict(X_test)
    return float(accuracy_score(y_test, y_pred))


def main():
    np.random.seed(SEED)

    file_path = os.environ.get("DATA_PATH", "grafici.csv")
    X, y, columns = load_data(file_path)

    global DATASET_HEADERS
    DATASET_HEADERS = columns

    X_scaled, _ = preprocess_data(X)

    cross_validate_model(X_scaled, y)

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=SEED, stratify=y if len(np.unique(y)) > 1 else None
    )

    model = train_model(X_train, y_train)
    accuracy = evaluate_model(model, X_test, y_test)

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused heavy imports (matplotlib, SVC, joblib, extra metrics) to cut startup time and memory.
# - Implemented robust CSV parsing with a fallback delimiter/decimal to avoid costly manual retries and ensure reliable ingestion.
# - Converted features to float32 to reduce memory footprint and data movement while preserving model behavior.
# - Used StandardScaler(copy=False) to avoid unnecessary array copies during scaling.
# - Centralized model construction and enabled n_jobs=-1 for RandomForest and cross_val_score to reduce wall-clock time.
# - Removed plotting, artifact saving, and verbose logging/printing to avoid extra compute and I/O side effects.
# - Ensured reproducibility via a fixed seed (numpy + model random_state) and deterministic split settings.