# Generated by generate_llm_code.py
# LLM: groq
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
import joblib

def load_data(file_path):
    df = pd.read_csv(file_path)
    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values
    return X, y

def preprocess_data(X):
    scaler = StandardScaler()
    return scaler.fit_transform(X), scaler

def train_model(X_train, y_train):
    clf = RandomForestClassifier(
        n_estimators=100,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    clf.fit(X_train, y_train)
    return clf

def evaluate_model(clf, X_test, y_test):
    y_pred = clf.predict(X_test)
    return np.mean(y_pred == y_test)

def save_model(clf, scaler, path='model.pkl'):
    joblib.dump({'model': clf, 'scaler': scaler}, path)

def load_model(path='model.pkl'):
    data = joblib.load(path)
    return data['model'], data['scaler']

def cross_validate(X, y):
    clf = RandomForestClassifier(
        n_estimators=100,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    cross_val_score(clf, X, y, cv=5, n_jobs=-1)

if __name__ == "__main__":
    X, y = load_data('grafici.csv')
    X_scaled, scaler = preprocess_data(X)
    cross_validate(X_scaled, y)
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42, stratify=y
    )
    clf = train_model(X_train, y_train)
    acc = evaluate_model(clf, X_test, y_test)
    print(f"ACCURACY={acc:.6f}")
    save_model(clf, scaler)

# Optimizations applied:
# 1. Removed matplotlib imports and plotting to avoid GPU/CPU overhead.
# 2. Eliminated all print statements except final accuracy to reduce I/O.
# 3. Combined preprocessing into a single function to avoid redundant passes.
# 4. Used n_jobs=-1 for RandomForest and cross-validation to leverage parallelism.
# 5. Simplified evaluation to a single accuracy computation.
# 6. Stripped comments from original code and added minimal explanations at the end.