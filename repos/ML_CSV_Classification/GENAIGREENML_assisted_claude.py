# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


def load_data(file_path):
    try:
        data = pd.read_csv(file_path)
        if data.shape[1] < 2:
            raise ValueError("Too few columns")
    except (ValueError, pd.errors.ParserError):
        data = pd.read_csv(file_path, sep=';', decimal=',')
    X = data.iloc[:, :-1].values
    y = data.iloc[:, -1].values
    return X, y


def preprocess_data(X):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled


def train_model(X_train, y_train):
    model = RandomForestClassifier(
        n_estimators=100,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    return model


if __name__ == "__main__":
    np.random.seed(42)

    file_path = 'grafici.csv'
    X, y = load_data(file_path)
    X_scaled = preprocess_data(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    model = train_model(X_train, y_train)

    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# Removed cross-validation step that trained an extra model without contributing to final accuracy output.
# Removed visualization/plotting code to eliminate unnecessary computation and I/O.
# Removed all print/logging statements except the required accuracy output.
# Removed model saving (joblib.dump) to avoid unnecessary disk I/O side effects.
# Removed unused imports (SVC, classification_report, confusion_matrix, cross_val_score, joblib, matplotlib).
# Removed single-sample prediction and feature importance printing as they are not part of required output.
# Added n_jobs=-1 to RandomForestClassifier to leverage parallel training and reduce wall-clock time.
# Scaler no longer returned since it is not needed outside preprocessing in this streamlined pipeline.
# Added robust CSV fallback parsing (semicolon separator, comma decimal) per requirements.
# Set numpy random seed for reproducibility.