# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: autonomous

import os
import re
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import FunctionTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


def _find_dataset_path() -> str:
    candidates = [
        "train.csv",
        "data.csv",
        "dataset.csv",
        "news.csv",
        "input.csv",
        os.path.join("data", "train.csv"),
        os.path.join("data", "data.csv"),
        os.path.join("data", "dataset.csv"),
        os.path.join("input", "train.csv"),
        os.path.join("input", "data.csv"),
        os.path.join("input", "dataset.csv"),
    ]
    for p in candidates:
        if os.path.isfile(p):
            return p
    for root, _, files in os.walk("."):
        for f in files:
            if f.lower().endswith(".csv"):
                return os.path.join(root, f)
    raise FileNotFoundError("No CSV dataset found in the working directory.")


def _read_csv(path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(path)
    except UnicodeDecodeError:
        return pd.read_csv(path, encoding="latin-1")


def _normalize_text(s: str) -> str:
    if s is None:
        return ""
    s = str(s)
    s = s.lower()
    s = re.sub(r"\s+", " ", s).strip()
    return s


def _build_text_series(X: pd.DataFrame) -> np.ndarray:
    if not isinstance(X, (pd.DataFrame, pd.Series)):
        X = pd.DataFrame(X)
    if isinstance(X, pd.Series):
        X = X.to_frame()

    cols = list(X.columns)
    title_col = None
    text_col = None
    for c in cols:
        lc = str(c).strip().lower()
        if lc == "title":
            title_col = c
        elif lc == "text":
            text_col = c

    if title_col is None and len(cols) > 0:
        title_col = cols[0]
    if text_col is None and len(cols) > 1:
        text_col = cols[1]

    title = X[title_col].astype(str) if title_col in X.columns else pd.Series([""] * len(X))
    body = X[text_col].astype(str) if text_col in X.columns else pd.Series([""] * len(X))

    combined = (title.fillna("") + " " + body.fillna("")).map(_normalize_text)
    return combined.to_numpy(dtype=object)


def _ensure_required_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    required = {"title", "text", "subject"}
    missing = required - set([c.lower() for c in df.columns])
    if missing:
        if "subject" in missing:
            raise ValueError("Missing required target column 'subject'.")
        for col in missing:
            df[col] = ""
    return df


def main():
    path = _find_dataset_path()
    df = _read_csv(path)
    df = _ensure_required_columns(df)

    cols_lower = {str(c).strip().lower(): c for c in df.columns}
    title_col = cols_lower.get("title", "title")
    text_col = cols_lower.get("text", "text")
    target_col = cols_lower.get("subject", "subject")

    X = df[[title_col, text_col]].copy()
    y = df[target_col].astype(str).fillna("")

    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=42,
        stratify=y if y.nunique() > 1 else None,
    )

    text_builder = FunctionTransformer(_build_text_series, validate=False)

    preprocessor = ColumnTransformer(
        transformers=[
            ("text", Pipeline(steps=[
                ("join", text_builder),
                ("tfidf", TfidfVectorizer(
                    ngram_range=(1, 2),
                    min_df=2,
                    max_df=0.95,
                    max_features=25000,
                    sublinear_tf=True,
                    strip_accents="unicode",
                )),
            ]), [title_col, text_col]),
        ],
        remainder="drop",
        sparse_threshold=0.3,
    )

    clf = LogisticRegression(
        solver="saga",
        penalty="l2",
        C=2.0,
        max_iter=200,
        n_jobs=1,
        random_state=42,
    )

    model = Pipeline(steps=[
        ("prep", preprocessor),
        ("clf", clf),
    ])

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()


# OPTIMIZATION SUMMARY
# - Uses TF-IDF with capped max_features and min_df to limit dimensionality and CPU/memory usage.
# - LogisticRegression(saga) is a lightweight linear classifier suitable for sparse text; avoids deep learning.
# - Simple deterministic preprocessing via Pipeline/ColumnTransformer ensures reproducibility and prevents data leakage.
# - Joins title+text once in a transformer to avoid duplicating vectorizers, reducing compute.
# - No model saving, plots, interactive inputs, or extraneous output to keep runtime lean and scriptable.
# - n_jobs=1 avoids oversubscription and can reduce energy spikes on shared/limited CPU environments.