# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import numpy as np

RANDOM_SEED = 42

def load_csv_robust(path):
    df = pd.read_csv(path, engine="c", low_memory=False)
    if df.shape[1] < 2:
        df = pd.read_csv(path, sep=";", decimal=",", engine="c", low_memory=False)
    return df

def train_and_evaluate():
    np.random.seed(RANDOM_SEED)

    df_fake = load_csv_robust("Fake.csv")
    df_real = load_csv_robust("True.csv")

    text_col = "text"
    if text_col not in df_fake.columns:
        text_col = df_fake.columns[1]

    fake_texts = df_fake[text_col]
    real_texts = df_real[text_col]

    n_fake = len(fake_texts)
    n_real = len(real_texts)

    texts = pd.concat([fake_texts, real_texts], ignore_index=True)
    labels = np.concatenate([np.zeros(n_fake, dtype=np.int8), np.ones(n_real, dtype=np.int8)])

    X_train, X_test, y_train, y_test = train_test_split(
        texts, labels, test_size=0.2, random_state=RANDOM_SEED
    )

    vectorizer = TfidfVectorizer(
        stop_words="english",
        max_df=0.7,
        dtype=np.float32,
        sublinear_tf=False,
    )
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)

    model = LogisticRegression(
        random_state=RANDOM_SEED,
        max_iter=200,
        solver="lbfgs",
    )
    model.fit(X_train_tfidf, y_train)

    accuracy = model.score(X_test_tfidf, y_test)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    train_and_evaluate()

# Optimization Summary
# - Removed all debug prints, plots, and logging per requirements.
# - Removed joblib model/vectorizer saving to avoid unnecessary disk I/O side effects.
# - Used np.int8 for labels to reduce memory footprint.
# - Used dtype=np.float32 in TfidfVectorizer to halve memory for the sparse TF-IDF matrix.
# - Set fixed random_state/seed everywhere for reproducibility.
# - Avoided creating intermediate DataFrame with both columns; only extracted the text column needed.
# - Used pd.concat only on the text Series rather than full DataFrames, reducing memory.
# - Used engine="c" for faster CSV parsing.
# - Added robust CSV fallback with sep=";" and decimal="," if initial parse yields too few columns.
# - Specified solver="lbfgs" explicitly for LogisticRegression to avoid deprecation overhead.
# - Added accuracy evaluation on test set and printed in required format.