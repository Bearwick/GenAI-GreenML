# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

DATASET_HEADERS = "title,text,subject,date"
RANDOM_STATE = 42


def _needs_fallback(df, expected_headers):
    if df is None or df.shape[1] <= 1:
        return True
    expected = {h.strip().lower() for h in expected_headers if h.strip()}
    if expected and not any(c.strip().lower() in expected for c in df.columns):
        return True
    return False


def _read_csv(path, expected_headers):
    try:
        df = pd.read_csv(path)
        if _needs_fallback(df, expected_headers):
            df = pd.read_csv(path, sep=";", decimal=",")
    except Exception:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _select_text_col(df, expected_headers):
    lower_cols = {c.strip().lower(): c for c in df.columns}
    if "text" in lower_cols:
        return lower_cols["text"]
    for h in expected_headers:
        key = h.strip().lower()
        if key in lower_cols:
            return lower_cols[key]
    return df.columns[0]


def _load_texts(path, expected_headers):
    df = _read_csv(path, expected_headers)
    col = _select_text_col(df, expected_headers)
    series = df[col].fillna("").astype(str)
    return series.to_numpy()


def train_and_evaluate():
    expected_headers = [h.strip() for h in DATASET_HEADERS.split(",") if h.strip()]
    fake_text = _load_texts("Fake.csv", expected_headers)
    real_text = _load_texts("True.csv", expected_headers)

    X = np.concatenate([fake_text, real_text])
    y = np.concatenate(
        [
            np.zeros(fake_text.shape[0], dtype=np.int8),
            np.ones(real_text.shape[0], dtype=np.int8),
        ]
    )

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_STATE
    )

    vectorizer = TfidfVectorizer(stop_words="english", max_df=0.7)
    X_train_tfidf = vectorizer.fit_transform(X_train)

    model = LogisticRegression()
    model.fit(X_train_tfidf, y_train)

    X_test_tfidf = vectorizer.transform(X_test)
    preds = model.predict(X_test_tfidf)

    accuracy = (preds == y_test).mean()
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    np.random.seed(RANDOM_STATE)
    train_and_evaluate()

# Optimization Summary
# - Loaded only the necessary text column and converted directly to NumPy arrays to reduce memory usage.
# - Avoided DataFrame concatenations by merging NumPy arrays for features and labels.
# - Implemented a lightweight CSV parsing fallback to prevent incorrect parsing and rework.
# - Fixed random seeds for deterministic behavior without additional computation.
# - Removed model persistence and debug output to eliminate unnecessary I/O and logging.