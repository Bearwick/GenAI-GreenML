# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
import os
import warnings
warnings.filterwarnings("ignore")

# --- Step 1: Load datasets with robust parsing ---
fake_path = "Fake.csv"
true_path = "True.csv"

def robust_read_csv(path):
    try:
        df = pd.read_csv(path, encoding='utf-8')
        if df.shape[1] < 2:
            df = pd.read_csv(path, sep=';', decimal=',', encoding='utf-8')
        return df
    except Exception:
        try:
            df = pd.read_csv(path, sep=';', decimal=',', encoding='utf-8')
            return df
        except Exception:
            return pd.DataFrame()

df_fake = robust_read_csv(fake_path)

# Try to load True.csv as well
df_true = None
if os.path.exists(true_path):
    df_true = robust_read_csv(true_path)

# --- Step 2: Normalize column names ---
def normalize_columns(df):
    df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]
    return df

df_fake = normalize_columns(df_fake)
if df_true is not None and not df_true.empty:
    df_true = normalize_columns(df_true)

# --- Step 3: Construct labeled dataset ---
# If both files exist, fake=1, true=0
# If only Fake.csv exists, try to find a label column or use 'subject' as proxy
if df_true is not None and not df_true.empty:
    df_fake['label'] = 1
    df_true['label'] = 0
    # Align columns
    common_cols = list(set(df_fake.columns) & set(df_true.columns))
    df = pd.concat([df_fake[common_cols], df_true[common_cols]], ignore_index=True)
else:
    # Fallback: if only Fake.csv, we need a target
    # Check if there's a label-like column
    df = df_fake.copy()
    possible_label_cols = [c for c in df.columns if c.lower() in ('label', 'class', 'target', 'fake', 'is_fake')]
    if possible_label_cols:
        df['label'] = df[possible_label_cols[0]]
    elif 'subject' in df.columns:
        # Use subject as a binary proxy: encode the two most common subjects as 0/1
        top2 = df['subject'].value_counts().index[:2]
        df = df[df['subject'].isin(top2)].copy()
        df['label'] = (df['subject'] == top2[0]).astype(int)
    else:
        # Last resort: create a dummy label (won't be meaningful)
        df['label'] = 0

# --- Step 4: Build text feature ---
# Combine title and text if both exist
text_cols = [c for c in ['title', 'text'] if c in df.columns]
if len(text_cols) > 0:
    df['combined_text'] = df[text_cols].fillna('').astype(str).agg(' '.join, axis=1)
else:
    # Use the first object column available
    obj_cols = df.select_dtypes(include='object').columns.tolist()
    obj_cols = [c for c in obj_cols if c != 'label']
    if obj_cols:
        df['combined_text'] = df[obj_cols[0]].fillna('').astype(str)
    else:
        df['combined_text'] = ''

# --- Step