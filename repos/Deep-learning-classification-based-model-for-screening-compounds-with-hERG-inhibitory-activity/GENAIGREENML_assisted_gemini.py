# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, BatchNormalization
from tensorflow.keras.models import Sequential
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score

np.random.seed(100)
tf.random.set_seed(1)

def load_robust_csv(path):
    try:
        df = pd.read_csv(path)
        if df.shape[1] <= 1:
            raise ValueError
    except:
        df = pd.read_csv(path, sep=';', decimal=',')
    return df

train_df = load_robust_csv("herg_train_activity.csv")
test_df = load_robust_csv("herg_test_activity.csv")
predict_df = load_robust_csv("cas.csv")

target_col = 'Activity_value'
X = train_df.drop(target_col, axis=1).values
Y = train_df[[target_col]].values
X_test = test_df.drop(target_col, axis=1).values
Y_test = test_df[[target_col]].values

scaler = MinMaxScaler(feature_range=(0, 1))
X = scaler.fit_transform(X)
X_test = scaler.transform(X_test)
X_new = scaler.transform(predict_df.values)

pca = PCA(n_components=2, random_state=0)
iso = IsolationForest(contamination=0.1, n_estimators=100, random_state=0)

X_pca_train = pca.fit_transform(X)
mask_train = iso.fit_predict(X_pca_train) != -1
X, Y = X[mask_train], Y[mask_train]

X_pca_test = pca.fit_transform(X_test)
mask_test = iso.fit_predict(X_pca_test) != -1
X_test, Y_test = X_test[mask_test], Y_test[mask_test]

model = Sequential([
    BatchNormalization(input_shape=(8,)),
    Dense(200, activation='relu', kernel_initializer='random_uniform', kernel_constraint=tf.keras.constraints.MaxNorm(3)),
    BatchNormalization(),
    Dense(200, activation='relu'),
    Dense(200, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(
    X, Y,
    epochs=200,
    batch_size=100,
    shuffle=True,
    verbose=0,
    validation_data=(X_test, Y_test)
)

_, test_acc = model.evaluate(X_test, Y_test, verbose=0)

y_new_pred = (model.predict(X_new, verbose=0) > 0.5).astype(int)
pd.DataFrame(y_new_pred, columns=['prediction']).to_csv('CAS_full_herg.csv', index=False)

print(f"ACCURACY={test_acc:.6f}")

# Optimization Summary
# 1. Removed redundant calls to model.predict() for training and test sets by consolidating evaluations.
# 2. Replaced manual fit/transform sequences with fit_transform() where applicable to minimize data passes.
# 3. Eliminated unused MinMaxScaler instance (scaler1) and redundant variable assignments.
# 4. Streamlined data loading with a robust helper function to handle different CSV formats efficiently.
# 5. Removed high-overhead visualization and diagnostic prints to reduce I/O and runtime.
# 6. Used vectorized numpy/tensorflow operations for thresholding instead of iterative loops.
# 7. Set fixed global seeds to ensure reproducibility with minimal computational overhead.
# 8. Optimized memory footprint by slicing arrays directly using boolean masks from outlier detection.
# 9. Reduced logging overhead by setting verbosity levels to zero during inference and training.
# 10. Simplified the model construction into a single Sequential call for better readability and internal graph optimization.