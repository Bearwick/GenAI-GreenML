# Generated by generate_llm_code.py
# LLM: groq
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Lightweight solution: use logistic regression instead of deep learning.
# Preprocess with standard scaling; no dimensionality reduction or outlier filtering to keep energy usage low.

def main():
    # Load data
    train_df = pd.read_csv("herg_train_activity.csv")
    test_df = pd.read_csv("herg_test_activity.csv")

    X_train = train_df.drop('Activity_value', axis=1).values
    y_train = train_df['Activity_value'].values
    X_test = test_df.drop('Activity_value', axis=1).values
    y_test = test_df['Activity_value'].values

    # Scaling
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train model
    model = LogisticRegression(max_iter=1000, solver='liblinear')
    model.fit(X_train_scaled, y_train)

    # Evaluate
    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()