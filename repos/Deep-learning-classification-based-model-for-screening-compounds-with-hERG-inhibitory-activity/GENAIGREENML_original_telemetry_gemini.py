# Generated by generate_llm_code.py
# LLM: gemini
# Mode: original_telemetry

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, BatchNormalization
from tensorflow.keras.models import Sequential
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn import metrics
from numpy.random import seed

tf.random.set_seed(1)
np.random.seed(100)
seed(0)

training_data_df = pd.read_csv("herg_train_activity.csv")
X = training_data_df.drop('Activity_value', axis=1).values
Y = training_data_df[['Activity_value']].values

test_data_df = pd.read_csv("herg_test_activity.csv")
X_test = test_data_df.drop('Activity_value', axis=1).values
Y_test = test_data_df[['Activity_value']].values

scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)
X = scaler.transform(X)
X_test = scaler.transform(X_test)

pca = PCA(n_components=2)
iso = IsolationForest(contamination=0.1, n_estimators=100, random_state=0, verbose=0)

pca1 = pca.fit_transform(X)
yhat_train = iso.fit_predict(pca1)
mask_train = yhat_train != -1
X = X[mask_train, :]
Y = Y[mask_train]

pca2 = pca.fit_transform(X_test)
yhat_test = iso.fit_predict(pca2)
mask_test = yhat_test != -1
X_test = X_test[mask_test, :]
Y_test = Y_test[mask_test]

model = Sequential()
model.add(BatchNormalization(input_shape=(X.shape[1],)))
model.add(Dense(200, activation='relu', kernel_initializer='random_uniform', kernel_constraint='MaxNorm'))
model.add(BatchNormalization())
model.add(Dense(200, activation='relu'))
model.add(Dense(200, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(
    X,
    Y,
    epochs=200,
    batch_size=100,
    shuffle=True,
    verbose=0,
    validation_data=(X_test, Y_test)
)

y_pred_test = model.predict(X_test, verbose=0)
y_prediction_test = np.where(y_pred_test > 0.5, 1, 0)
accuracy = metrics.accuracy_score(Y_test, y_prediction_test)

Xnew = pd.read_csv("cas.csv").values
Xnew_scaled = scaler.transform(Xnew)
prediction = model.predict(Xnew_scaled, verbose=0)

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# - Removed all original print statements, comments, and interactive visualizations.
# - Removed model saving and CSV output (CAS_full_herg.csv).
# - Consolidated imports and used tensorflow.keras for better compatibility.
# - Fixed data scaling logic by removing the unused 'scaler1' and ensuring X_test is scaled using the training scaler.
# - Adjusted model definition to use dynamic input shape (X.shape[1]) instead of hardcoded input_dim.
# - Maintained original outlier detection logic (PCA followed by IsolationForest fitting independently on train and test).
# - Added final accuracy print for the test set in the required format.