# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from sklearn.metrics import accuracy_score

SEED = 0
np.random.seed(SEED)
tf.random.set_seed(SEED)

def robust_read_csv(path):
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=';', decimal=',')
    return df

training_data_df = robust_read_csv("herg_train_activity.csv")
target_col = 'Activity_value'
feature_cols = [c for c in training_data_df.columns if c != target_col]

X = training_data_df[feature_cols].values
Y = training_data_df[[target_col]].values

test_data_df = robust_read_csv("herg_test_activity.csv")
X_test = test_data_df[feature_cols].values
Y_test = test_data_df[[target_col]].values

scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)
X = scaler.transform(X)
X_test = scaler.transform(X_test)

pca = PCA(n_components=2)
pca1 = pca.fit_transform(X)
iso = IsolationForest(contamination=0.1, n_estimators=100, random_state=0, verbose=0)
yhat = iso.fit_predict(pca1)
pca2 = pca.fit_transform(X_test)
yhat_1 = iso.fit_predict(pca2)

mask_train = yhat != -1
X, Y = X[mask_train], Y[mask_train]

mask_test = yhat_1 != -1
X_test, Y_test = X_test[mask_test], Y_test[mask_test]

input_dim = X.shape[1]

model = tf.keras.Sequential([
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(200, input_dim=input_dim, activation='relu',
                          kernel_initializer='random_uniform',
                          kernel_constraint='MaxNorm'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(200, activation='relu'),
    tf.keras.layers.Dense(200, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X, Y, epochs=200, batch_size=100, shuffle=True, verbose=0,
          validation_data=(X_test, Y_test))

y_pred_test = model.predict(X_test, verbose=0)
y_pred_class_test = (y_pred_test > 0.5).astype(int).ravel()
Y_test_flat = Y_test.ravel()

accuracy = accuracy_score(Y_test_flat, y_pred_class_test)

cas_df = robust_read_csv("cas.csv")
Xnew = scaler.transform(cas_df.values)
prediction = model.predict(Xnew, verbose=0)
y_prediction = (prediction > 0.5).astype(int)
pd.DataFrame(y_prediction, columns=['prediction']).to_csv('CAS_full_herg.csv', index=False)

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# Removed unused scaler1 (MinMaxScaler fitted on test data but never used for transform).
# Eliminated redundant duplicate model.predict calls (y_pred and y_pred_class were identical).
# Removed all print/logging statements, plots, and verbose outputs.
# Removed unused metric computations (precision, recall, f1, AUC, confusion matrix) that were only printed.
#