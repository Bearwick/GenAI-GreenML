# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: original_telemetry

import os
import sys
import numpy as np
import pandas as pd
import lightgbm as lgb
import sklearn
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score


data_path = "./datasets//"
train = pd.read_csv(os.path.join(data_path, "train.csv"))
test = pd.read_csv(os.path.join(data_path, "test.csv"))

ycol = "label"
features = [x for x in train.columns if x not in [ycol, "id"]]

NFOLD = 5
num_class = 9
random_state = 2021
KF = StratifiedKFold(n_splits=NFOLD, shuffle=True, random_state=random_state)


def custom_accuracy_eval(y_hat, data, num_class=num_class):
    y_true = data.get_label()
    y_hat = y_hat.reshape(num_class, -1).T
    return "accuracy", accuracy_score(y_true, np.argmax(y_hat, axis=1)), True


params_lgb = {
    "boosting": "gbdt",
    "objective": "multiclass",
    "num_class": num_class,
    "metric": "multi_logloss",
    "first_metric_only": True,
    "force_row_wise": True,
    "random_state": random_state,
    "learning_rate": 0.05,
    "subsample": 0.8,
    "subsample_freq": 3,
    "colsample_bytree": 0.8,
    "max_depth": 6,
    "num_leaves": 31,
    "n_jobs": -1,
    "verbose": -1,
}

oof_lgb = np.zeros([len(train), num_class])
predictions_lgb = np.zeros([len(test), num_class])
df_importance_list = []

for fold_, (trn_idx, val_idx) in enumerate(KF.split(train[features], train[ycol])):
    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=train.iloc[trn_idx][ycol])
    val_data = lgb.Dataset(
        train.iloc[val_idx][features],
        label=train.iloc[val_idx][ycol],
        reference=trn_data,
    )

    train_kwargs = dict(
        params=params_lgb,
        train_set=trn_data,
        valid_sets=[trn_data, val_data],
        valid_names=("train", "val"),
        num_boost_round=50000,
        feval=custom_accuracy_eval,
    )

    try:
        clf_lgb = lgb.train(
            **train_kwargs,
            early_stopping_rounds=200,
            verbose_eval=100,
        )
    except TypeError:
        clf_lgb = lgb.train(
            **train_kwargs,
            callbacks=[lgb.early_stopping(200), lgb.log_evaluation(100)],
        )

    oof_lgb[val_idx] = clf_lgb.predict(train.iloc[val_idx][features], num_iteration=clf_lgb.best_iteration)
    predictions_lgb[:] += clf_lgb.predict(test[features], num_iteration=clf_lgb.best_iteration) / NFOLD

    df_importance = pd.DataFrame(
        {
            "column": features,
            "importance_split": clf_lgb.feature_importance(importance_type="split"),
            "importance_gain": clf_lgb.feature_importance(importance_type="gain"),
        }
    )
    df_importance_list.append(df_importance)

valid_accuracy_score = accuracy_score(train[ycol], np.argmax(oof_lgb, axis=1))

df_importance = pd.concat(df_importance_list)
df_importance = df_importance.groupby("column").agg("mean").reset_index()
df_importance.sort_values("importance_gain", ascending=False)

test["label"] = np.argmax(predictions_lgb, axis=1)
test[["id", "label"]].to_csv("./submit.csv", index=False)

accuracy = accuracy_score(train[ycol], np.argmax(oof_lgb, axis=1))
precision = precision_score(train[ycol], np.argmax(oof_lgb, axis=1), average="macro")
recall = recall_score(train[ycol], np.argmax(oof_lgb, axis=1), average="macro")
f1 = f1_score(train[ycol], np.argmax(oof_lgb, axis=1), average="macro")
auc = roc_auc_score(train[ycol], oof_lgb, average="macro", multi_class="ovo")
learning_rate = params_lgb["learning_rate"]

evaluation = pd.DataFrame(
    {
        "Model": ["LightGBM"],
        "学习率": [learning_rate],
        "准确率": [accuracy],
        "精确率": [precision],
        "召回率": [recall],
        "F1 值": [f1],
        "AUC值": [auc],
        "5折交叉验证的score": [valid_accuracy_score],
    }
)
evaluation.to_csv("evaluation.csv", index=False)

print(f"ACCURACY={accuracy:.6f}")