# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
from pathlib import Path

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score


SEED = 2021
NFOLD = 5
NUM_CLASS = 9


def set_reproducibility(seed: int) -> None:
    random.seed(seed)
    np.random.seed(seed)


def robust_read_csv(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def infer_feature_columns(df: pd.DataFrame, target: str, id_col: str) -> list[str]:
    cols = df.columns.tolist()
    return [c for c in cols if c not in (target, id_col)]


def custom_accuracy_eval(y_hat: np.ndarray, data: lgb.Dataset) -> tuple[str, float, bool]:
    y_true = data.get_label()
    y_hat = y_hat.reshape(NUM_CLASS, -1).T
    return "accuracy", accuracy_score(y_true, np.argmax(y_hat, axis=1)), True


def main() -> None:
    set_reproducibility(SEED)

    data_path = Path("./datasets")
    train_path = data_path / "train.csv"
    test_path = data_path / "test.csv"

    train = robust_read_csv(str(train_path))
    test = robust_read_csv(str(test_path))

    ycol = "label"
    id_col = "id"
    features = infer_feature_columns(train, ycol, id_col)

    kf = StratifiedKFold(n_splits=NFOLD, shuffle=True, random_state=SEED)

    params_lgb = {
        "boosting": "gbdt",
        "objective": "multiclass",
        "num_class": NUM_CLASS,
        "metric": "multi_logloss",
        "first_metric_only": True,
        "force_row_wise": True,
        "random_state": SEED,
        "learning_rate": 0.05,
        "subsample": 0.8,
        "subsample_freq": 3,
        "colsample_bytree": 0.8,
        "max_depth": 6,
        "num_leaves": 31,
        "n_jobs": -1,
        "verbose": -1,
    }

    X = train.loc[:, features]
    y = train.loc[:, ycol].to_numpy()
    X_test = test.loc[:, features]

    oof = np.zeros((len(train), NUM_CLASS), dtype=np.float64)
    predictions = np.zeros((len(test), NUM_CLASS), dtype=np.float64)

    for trn_idx, val_idx in kf.split(X, y):
        X_trn = X.iloc[trn_idx]
        y_trn = y[trn_idx]
        X_val = X.iloc[val_idx]
        y_val = y[val_idx]

        trn_data = lgb.Dataset(X_trn, label=y_trn, free_raw_data=True)
        val_data = lgb.Dataset(X_val, label=y_val, reference=trn_data, free_raw_data=True)

        train_kwargs = dict(
            params=params_lgb,
            train_set=trn_data,
            valid_sets=[trn_data, val_data],
            valid_names=("train", "val"),
            num_boost_round=50000,
            feval=custom_accuracy_eval,
        )

        try:
            clf = lgb.train(
                **train_kwargs,
                early_stopping_rounds=200,
                verbose_eval=False,
            )
        except TypeError:
            clf = lgb.train(
                **train_kwargs,
                callbacks=[lgb.early_stopping(200, verbose=False)],
            )

        best_iter = clf.best_iteration
        oof[val_idx] = clf.predict(X_val, num_iteration=best_iter)
        predictions += clf.predict(X_test, num_iteration=best_iter) / NFOLD

    accuracy = accuracy_score(y, np.argmax(oof, axis=1))
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused imports, plotting/visualization, and extra metrics to cut runtime and dependencies while preserving the core training/evaluation behavior.
# - Avoided redundant DataFrame slicing by caching X/y/X_test once and reusing them across folds, reducing data movement and overhead.
# - Eliminated feature-importance aggregation, learning-curve training, and file outputs (submit/evaluation/images) to prevent extra training passes and side effects.
# - Used LightGBM early stopping with verbose disabled to reduce logging overhead while keeping the same stopping logic and model behavior.
# - Preallocated NumPy arrays for OOF and test predictions to avoid repeated reallocations and reduce memory churn.
# - Implemented robust CSV parsing fallback (default then ';' + ',' decimal) for reliable ingestion without manual edits.
# - Set fixed random seeds for reproducibility and stable results across runs.