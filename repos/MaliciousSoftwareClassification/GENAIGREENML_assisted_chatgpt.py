# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score


def load_data(data_dir: str):
    train_path = os.path.join(data_dir, "train.csv")
    test_path = os.path.join(data_dir, "test.csv")

    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)
    return train_df, test_df


def get_features(train_df: pd.DataFrame, target_col: str, id_col: str):
    cols = train_df.columns
    return [c for c in cols if c != target_col and c != id_col]


def custom_accuracy_eval(num_class: int):
    def _feval(y_hat, dataset):
        y_true = dataset.get_label()
        y_hat = y_hat.reshape(num_class, -1).T
        return "accuracy", accuracy_score(y_true, np.argmax(y_hat, axis=1)), True

    return _feval


def run_cv_lightgbm(train_df: pd.DataFrame, test_df: pd.DataFrame, features, ycol: str, params: dict, nfold: int):
    X = train_df[features].to_numpy(copy=False)
    y = train_df[ycol].to_numpy(copy=False)
    X_test = test_df[features].to_numpy(copy=False)

    num_class = int(params["num_class"])
    oof = np.zeros((X.shape[0], num_class), dtype=np.float32)
    preds = np.zeros((X_test.shape[0], num_class), dtype=np.float32)

    kf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=params.get("random_state", 2021))
    feval = custom_accuracy_eval(num_class)

    for trn_idx, val_idx in kf.split(X, y):
        trn_data = lgb.Dataset(X[trn_idx], label=y[trn_idx], free_raw_data=True)
        val_data = lgb.Dataset(X[val_idx], label=y[val_idx], reference=trn_data, free_raw_data=True)

        train_kwargs = dict(
            params=params,
            train_set=trn_data,
            valid_sets=[val_data],
            valid_names=("val",),
            num_boost_round=50000,
            feval=feval,
        )

        try:
            model = lgb.train(
                **train_kwargs,
                early_stopping_rounds=200,
                verbose_eval=False,
            )
        except TypeError:
            model = lgb.train(
                **train_kwargs,
                callbacks=[lgb.early_stopping(200), lgb.log_evaluation(period=0)],
            )

        best_iter = model.best_iteration
        oof[val_idx] = model.predict(X[val_idx], num_iteration=best_iter).astype(np.float32, copy=False)
        preds += (model.predict(X_test, num_iteration=best_iter).astype(np.float32, copy=False) / nfold)

    return oof, preds


def main():
    data_path = "./datasets/"
    ycol = "label"
    id_col = "id"
    nfold = 5
    num_class = 9
    random_state = 2021

    train_df, test_df = load_data(data_path)
    features = get_features(train_df, ycol=ycol, id_col=id_col)

    params_lgb = {
        "boosting": "gbdt",
        "objective": "multiclass",
        "num_class": num_class,
        "metric": "multi_logloss",
        "first_metric_only": True,
        "force_row_wise": True,
        "random_state": random_state,
        "learning_rate": 0.05,
        "subsample": 0.8,
        "subsample_freq": 3,
        "colsample_bytree": 0.8,
        "max_depth": 6,
        "num_leaves": 31,
        "n_jobs": -1,
        "verbose": -1,
    }

    oof_lgb, _ = run_cv_lightgbm(
        train_df=train_df,
        test_df=test_df,
        features=features,
        ycol=ycol,
        params=params_lgb,
        nfold=nfold,
    )

    y_true = train_df[ycol].to_numpy(copy=False)
    y_pred = np.argmax(oof_lgb, axis=1)
    accuracy = accuracy_score(y_true, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# - Removed unused imports, plotting, file outputs, and extra metrics to cut runtime and avoid energy-heavy visualization/I/O.
# - Converted feature matrices to NumPy views (to_numpy(copy=False)) once and used index slicing to reduce repeated pandas indexing overhead.
# - Stored OOF and test predictions as float32 to reduce memory footprint and bandwidth without changing argmax outputs.
# - Limited LightGBM validation sets to only the validation fold to reduce evaluation work per iteration while keeping early stopping behavior.
# - Used verbose_eval=False / log_evaluation(period=0) to avoid periodic logging overhead.
# - Enabled free_raw_data in Dataset to allow LightGBM to release raw matrices sooner and reduce peak memory.