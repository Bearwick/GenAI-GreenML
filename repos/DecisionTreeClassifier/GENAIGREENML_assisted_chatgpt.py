# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import numpy as np
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


SEED = 42


def set_reproducible_seed(seed: int) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)


def read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] == 1:
        df2 = pd.read_csv(path, sep=";", decimal=",")
        if df2.shape[1] > 1:
            df = df2
    return df


def select_features_and_target(df: pd.DataFrame, dataset_headers: str):
    expected = [h.strip() for h in dataset_headers.split(",") if h.strip()]
    available = set(df.columns)

    target_col = "genre" if "genre" in available else (expected[-1] if expected and expected[-1] in available else df.columns[-1])

    candidate_feature_cols = [c for c in df.columns if c != target_col]
    if all(h in available for h in expected) and target_col in expected:
        candidate_feature_cols = [h for h in expected if h != target_col]

    X = df.loc[:, candidate_feature_cols]
    y = df.loc[:, target_col]
    return X, y


def main() -> None:
    set_reproducible_seed(SEED)

    dataset_headers = "age,gender,genre"
    df = read_csv_robust("music.csv")

    X, y = select_features_and_target(df, dataset_headers)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=SEED, shuffle=True
    )

    model = DecisionTreeClassifier(random_state=SEED)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Added fixed random seed (PYTHONHASHSEED, random, numpy, and sklearn random_state) for reproducible splits and model results, avoiding reruns to compare inconsistent outputs.
# - Implemented robust CSV parsing with a lightweight fallback (sep=';' and decimal=',') only when initial parsing likely failed, preventing wasted downstream computation on malformed data.
# - Selected features/target via column introspection using DATASET_HEADERS and df.columns, avoiding hard assumptions and preventing corrective reruns due to schema mismatches.
# - Removed non-essential outputs and kept a single final accuracy print, reducing I/O overhead while preserving evaluation intent.
# - Used .loc column selection to avoid unnecessary intermediate copies and keep memory movement minimal.