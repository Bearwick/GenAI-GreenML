# Generated by ./scripts/generate_llm_code.sh
# LLM: gemini
# Mode: autonomous

"""
JUSTIFICATION:
The selection of a Decision Tree classifier ensures maximum energy efficiency for this small-scale tabular dataset. 
Decision Trees have low algorithmic complexity, requiring minimal CPU clock cycles for both training and inference 
compared to ensemble methods or neural networks. No heavy preprocessing (like normalization or vectorization) is 
needed, further reducing the computational overhead. The implementation uses a fixed random state to ensure 
reproducibility, preventing the need for multiple energy-intensive training runs to verify results.
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import io

def run_ml_pipeline():
    data_content = """age,gender,genre
20,1,HipHop
23,1,HipHop
25,1,HipHop
26,1,Jazz
29,1,Jazz
30,1,Jazz
31,1,Classical
33,1,Classical
37,1,Classical
20,0,Dance
21,0,Dance
25,0,Dance
26,0,Acoustic
29,0,Acoustic
30,0,Acoustic
31,0,Classical
34,0,Classical
35,0,Classical"""
    
    music_data = pd.read_csv(io.StringIO(data_content))
    
    X = music_data.drop(columns=['genre'])
    y = music_data['genre']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, 
        y, 
        test_size=0.2, 
        random_state=42
    )
    
    model = DecisionTreeClassifier(random_state=42)
    model.fit(X_train, y_train)
    
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_ml_pipeline()
