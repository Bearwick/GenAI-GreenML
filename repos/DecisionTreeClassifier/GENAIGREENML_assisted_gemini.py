# Generated by ./scripts/generate_llm_code.sh
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def run_efficient_pipeline(file_path):
    music_data = pd.read_csv(
        file_path, 
        dtype={'age': 'int8', 'gender': 'int8', 'genre': 'category'}
    )

    X = music_data[['age', 'gender']]
    y = music_data['genre']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    model = DecisionTreeClassifier()
    model.fit(X_train, y_train)

    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_efficient_pipeline('music.csv')

# OPTIMIZATIONS APPLIED:
# 1. Memory Footprint Reduction: Specified dtypes ('int8' for numeric and 'category' for strings) 
#    during CSV ingestion to reduce RAM usage significantly compared to default 64-bit types.
# 2. Reduced Data Movement: Used direct column selection instead of .drop() to avoid creating 
#    unnecessary intermediate DataFrame copies.
# 3. Reproducibility: Added a fixed random_state to ensure stable, repeatable results, 
#    eliminating the need for multiple runs to verify performance.
# 4. Optimized Preprocessing: Loaded only necessary data and avoided complex transformations 
#    by utilizing the categorical data type directly where supported.
