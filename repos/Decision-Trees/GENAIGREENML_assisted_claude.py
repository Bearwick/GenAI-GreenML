# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import csv
import random
import math


def read_data(csv_path):
    examples = []
    with open(csv_path, 'r') as csv_file:
        csv_reader = csv.DictReader(csv_file)
        for example in csv_reader:
            for k, v in example.items():
                if v == '':
                    example[k] = None
                else:
                    try:
                        example[k] = float(v)
                    except ValueError:
                        example[k] = v
            examples.append(example)
    if len(examples) > 0:
        keys = list(examples[0].keys())
        if len(keys) <= 2:
            examples = []
            with open(csv_path, 'r') as csv_file:
                csv_reader = csv.DictReader(csv_file, delimiter=';')
                for example in csv_reader:
                    for k, v in example.items():
                        if v == '':
                            example[k] = None
                        else:
                            v2 = v.replace(',', '.')
                            try:
                                example[k] = float(v2)
                            except ValueError:
                                example[k] = v
                    examples.append(example)
    return examples


def train_test_split(examples, test_perc):
    test_size = round(test_perc * len(examples))
    shuffled = random.sample(examples, len(examples))
    return shuffled[test_size:], shuffled[:test_size]


class LeafNode:
    __slots__ = ('pred_class', 'pred_class_count', 'total_count', 'prob')

    def __init__(self, pred_class, pred_class_count, total_count):
        self.pred_class = pred_class
        self.pred_class_count = pred_class_count
        self.total_count = total_count
        self.prob = pred_class_count / total_count

    def classify(self, example):
        return self.pred_class, self.prob


class DecisionNode:
    __slots__ = ('test_attr_name', 'test_attr_threshold', 'child_lt', 'child_ge', 'child_miss')

    def __init__(self, test_attr_name, test_attr_threshold, child_lt, child_ge, child_miss):
        self.test_attr_name = test_attr_name
        self.test_attr_threshold = test_attr_threshold
        self.child_ge = child_ge
        self.child_lt = child_lt
        self.child_miss = child_miss

    def classify(self, example):
        test_val = example[self.test_attr_name]
        if test_val is None:
            return self.child_miss.classify(example)
        elif test_val < self.test_attr_threshold:
            return self.child_lt.classify(example)
        else:
            return self.child_ge.classify(example)


def entropy(examples, class_label):
    counts = {}
    for ex in examples:
        c = ex[class_label]
        counts[c] = counts.get(c, 0) + 1
    n = len(examples)
    s = 0.0
    log2 = math.log2
    for count in counts.values():
        p = count / n
        if p > 0:
            s -= p * log2(p)
    return s


def get_predictive_class(examples, class_label):
    counts = {}
    for ex in examples:
        c = ex[class_label]
        counts[c] = counts.get(c, 0) + 1
    best_class = max(counts, key=counts.get)
    return best_class, counts[best_class]


def get_best_attribute_and_split(attribute_set, examples, class_label):
    parent_entropy = entropy(examples, class_label)
    n = len(examples)
    best_gain = 0.0