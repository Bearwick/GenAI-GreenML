# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load the pickle file
DATASET_PATH = "dict.pickle"

with open(DATASET_PATH, "rb") as f:
    data = pickle.load(f, encoding="latin1")

# Inspect what we loaded
if isinstance(data, dict):
    # Try to construct a DataFrame from the dict
    # The dict might have arrays or lists as values
    # Check if it looks like {key: array_of_values}
    keys = list(data.keys())
    # Check if values are arrays/lists of same length
    lengths = {}
    for k, v in data.items():
        if isinstance(v, (list, np.ndarray)):
            lengths[k] = len(v) if hasattr(v, '__len__') else 1
        elif isinstance(v, pd.DataFrame):
            # If any value is a DataFrame, use it directly
            df = v
            break
        elif isinstance(v, dict):
            lengths[k] = 'dict'
        else:
            lengths[k] = 1

    if 'df' not in dir():
        # Check if all values are arrays of the same length
        array_keys = [k for k, v in lengths.items() if isinstance(v, int) and v > 1]
        if array_keys:
            unique_lengths = set(lengths[k] for k in array_keys)
            if len(unique_lengths) == 1:
                # All arrays same length, build DataFrame
                df = pd.DataFrame({k: data[k] for k in array_keys})
            else:
                # Try different approach: maybe data has 'X' and 'y' or 'data' and 'target'
                if 'X' in data and 'y' in data:
                    X_raw = np.array(data['X'])
                    y_raw = np.array(data['y'])
                    if X_raw.ndim == 2:
                        df = pd.DataFrame(X_raw, columns=[f"feat_{i}" for i in range(X_raw.shape[1])])
                    else:
                        df = pd.DataFrame(X_raw)
                    df['target'] = y_raw
                elif 'data' in data and 'target' in data:
                    X_raw = np.array(data['data'])
                    y_raw = np.array(data['target'])
                    if X_raw.ndim == 2:
                        df = pd.DataFrame(X_raw, columns=[f"feat_{i}" for i in range(X_raw.shape[1])])
                    else:
                        df = pd.DataFrame(X_raw)
                    df['target'] = y_raw
                else:
                    # Build what we can
                    max_len = max(v for v in lengths.values() if isinstance(v, int))
                    usable = [k for k in array_keys if lengths[k] == max_len]
                    df = pd.DataFrame({k: data[k] for k in usable})
        else:
            # Maybe nested structure: check for common sklearn-like keys
            if 'X' in data and 'y' in data:
                X_raw = np.array(data['X'])
                y_raw = np.array(data['y']).ravel()
                if X_raw.ndim == 2:
                    df = pd.DataFrame(X_raw, columns=[f"feat_{i}" for i in range(X_raw.shape[1])])
                else:
                    df = pd.DataFrame({'feat_0': X_raw})
                df['target'] = y_raw
            elif 'data' in data and 'target' in data:
                X_raw = np.array(data['data'])
                y_raw = np.array(data['target