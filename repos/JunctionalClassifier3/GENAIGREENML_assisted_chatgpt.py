# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import pickle
from typing import Optional, Tuple

import numpy as np
import pandas as pd
from sklearn import svm
from sklearn.metrics import accuracy_score


RANDOM_SEED = 42
MODEL_PATH = "dict.pickle"
INPUT_CSV_PATH = "input.csv"
TRAIN_CSV_PATH = "14k.csv"


def _robust_read_csv(path: str, has_header: bool = True) -> pd.DataFrame:
    if not os.path.exists(path):
        raise FileNotFoundError(path)

    header = 0 if has_header else None
    df = pd.read_csv(path, header=header)

    def looks_wrong(d: pd.DataFrame) -> bool:
        if d.shape[1] == 1:
            first_val = d.iloc[0, 0]
            if isinstance(first_val, str) and (";" in first_val or "," in first_val):
                return True
        return False

    if looks_wrong(df):
        df = pd.read_csv(path, header=header, sep=";", decimal=",")
    return df


def _coerce_numeric_frame(df: pd.DataFrame) -> pd.DataFrame:
    for c in df.columns:
        if not pd.api.types.is_numeric_dtype(df[c]):
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


def _extract_supervised_xy(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
    df = df.dropna(axis=0, how="all")
    if df.empty:
        raise ValueError("Empty training dataframe.")

    df = _coerce_numeric_frame(df).dropna(axis=0, how="any")
    if df.shape[1] < 2:
        raise ValueError("Training dataframe must have at least 2 columns (features + label).")

    x = df.iloc[:, :-1].to_numpy(dtype=np.float64, copy=False)
    y_raw = df.iloc[:, -1].to_numpy(dtype=np.float64, copy=False)

    y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0)).astype(np.int64, copy=False)
    return x, y


def _extract_unsupervised_x(df: pd.DataFrame) -> np.ndarray:
    df = df.dropna(axis=0, how="all")
    if df.empty:
        return np.empty((0, 0), dtype=np.float64)

    df = _coerce_numeric_frame(df).dropna(axis=0, how="any")
    x = df.to_numpy(dtype=np.float64, copy=False)
    return x


def load_model(model_path: str = MODEL_PATH):
    with open(model_path, "rb") as f:
        return pickle.load(f)


def train_and_test_model(
    train_csv_path: str = TRAIN_CSV_PATH,
    test_size: float = 0.3,
    random_seed: int = RANDOM_SEED,
) -> float:
    df = _robust_read_csv(train_csv_path, has_header=True)
    x, y = _extract_supervised_xy(df)

    n = x.shape[0]
    if n == 0:
        raise ValueError("No training rows after cleaning.")
    if n == 1:
        clf = svm.SVC(kernel="linear")
        clf.fit(x, y)
        pred = clf.predict(x)
        accuracy = float(accuracy_score(y, pred))
        print(f"ACCURACY={accuracy:.6f}")
        return accuracy

    rng = np.random.RandomState(random_seed)
    idx = np.arange(n)
    rng.shuffle(idx)

    n_test = int(round(n * test_size))
    n_test = max(1, min(n - 1, n_test))
    test_idx = idx[:n_test]
    train_idx = idx[n_test:]

    x_train = x[train_idx]
    y_train = y[train_idx]
    x_test = x[test_idx]
    y_test = y[test_idx]

    clf = svm.SVC(kernel="linear")
    clf.fit(x_train, y_train)
    pred = clf.predict(x_test)
    accuracy = float(accuracy_score(y_test, pred))
    print(f"ACCURACY={accuracy:.6f}")
    return accuracy


def predict_from_input_csv(
    model_path: str = MODEL_PATH,
    input_csv_path: str = INPUT_CSV_PATH,
) -> np.ndarray:
    clf = load_model(model_path)
    df = _robust_read_csv(input_csv_path, has_header=True)
    x = _extract_unsupervised_x(df)
    if x.size == 0:
        return np.empty((0,), dtype=np.int64)
    return clf.predict(x)


def main() -> None:
    _ = predict_from_input_csv(MODEL_PATH, INPUT_CSV_PATH)
    accuracy = 0.0
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Replaced row-by-row csv.reader loops and repeated list appends with vectorized pandas/numpy extraction to reduce Python overhead.
# - Avoided redundant conversions by using to_numpy(copy=False) and in-place numeric coercion, reducing memory movement and allocations.
# - Implemented robust CSV parsing fallback (default, then sep=';' and decimal=',') to prevent costly downstream failures and retries.
# - Removed global mutable state (features/labels/pFeatures) and wipe functions; functions now return arrays directly to reduce side effects and improve determinism.
# - Ensured reproducibility by using a fixed seed and a deterministic shuffle-based split instead of non-deterministic defaults.
# - Used context managers for file I/O to minimize resource leakage and improve runtime stability.
# - Kept model loading/prediction minimal with no artifact saving or extraneous output; only final accuracy print remains.