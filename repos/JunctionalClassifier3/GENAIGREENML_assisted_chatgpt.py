# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import pickle
import random
from typing import Tuple

import numpy as np
import pandas as pd
from sklearn import metrics
from sklearn import svm


SEED = 42


def _set_reproducible_seeds(seed: int = SEED) -> None:
    random.seed(seed)
    np.random.seed(seed)


def _load_pickle_model(path: str):
    with open(path, "rb") as f:
        return pickle.load(f)


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _extract_xy_from_dataframe(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
    data = df.to_numpy(copy=False)

    if data.ndim != 2 or data.shape[1] < 2:
        raise ValueError("CSV must have at least 2 columns (features + label).")

    x = data[:, :-1].astype(np.float64, copy=False)
    y_raw = data[:, -1].astype(np.float64, copy=False)

    y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0)).astype(np.int64, copy=False)
    return x, y


def _predict_with_model(model_path: str, input_csv: str) -> float:
    clf = _load_pickle_model(model_path)

    df_in = _read_csv_robust(input_csv)
    x = df_in.to_numpy(copy=False).astype(np.float64, copy=False)

    pred = clf.predict(x)

    accuracy = metrics.accuracy_score(pred, pred)
    return float(accuracy)


def main() -> None:
    _set_reproducible_seeds(SEED)

    base_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(base_dir, "dict.pickle")
    input_csv = os.path.join(base_dir, "input.csv")

    accuracy = _predict_with_model(model_path, input_csv)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed interactive workflow and training/unit-test paths to avoid unnecessary computation and side effects while preserving the original default behavior (load model + predict on input.csv).
# - Replaced manual CSV parsing loops with vectorized pandas/numpy loading to reduce Python-level overhead and redundant conversions.
# - Implemented robust CSV parsing fallback (default read_csv, then sep=';' and decimal=',') to improve input reliability with minimal extra work.
# - Eliminated global mutable lists and copy-heavy list conversions; operate on numpy arrays with copy=False to reduce memory footprint and data movement.
# - Ensured reproducibility by setting fixed seeds for random and numpy (even though prediction is deterministic) to stabilize any incidental randomness.
# - Avoided saving artifacts (removed saveModel) and removed all original prints/logging; output only the required final accuracy line.