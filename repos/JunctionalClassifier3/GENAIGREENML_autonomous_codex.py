# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import re
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.dummy import DummyClassifier, DummyRegressor
from sklearn.metrics import accuracy_score, r2_score

def find_csv_file():
    csv_files = [f for f in os.listdir('.') if f.lower().endswith('.csv')]
    if not csv_files:
        raise FileNotFoundError("No CSV file found.")
    csv_files.sort(key=lambda f: os.path.getsize(f), reverse=True)
    return csv_files[0]

def robust_read_csv(path):
    try:
        df = pd.read_csv(path)
    except Exception:
        df = pd.read_csv(path, sep=';', decimal=',')
        return df
    if df.shape[1] == 1:
        try:
            sample = df.iloc[0, 0]
            if isinstance(sample, str) and (';' in sample):
                df = pd.read_csv(path, sep=';', decimal=',')
        except Exception:
            pass
    return df

def clean_columns(df):
    cols = []
    keep_mask = []
    for i, col in enumerate(df.columns):
        c = str(col)
        c = c.strip()
        c = re.sub(r'\s+', ' ', c)
        if re.match(r'^Unnamed', c, flags=re.IGNORECASE):
            keep_mask.append(False)
            continue
        if c == '':
            c = f"col_{i}"
        cols.append(c)
        keep_mask.append(True)
    df = df.loc[:, keep_mask]
    df.columns = cols
    seen = {}
    new_cols = []
    for c in df.columns:
        if c in seen:
            seen[c] += 1
            new_cols.append(f"{c}_{seen[c]}")
        else:
            seen[c] = 0
            new_cols.append(c)
    df.columns = new_cols
    return df

path = find_csv_file()
df = robust_read_csv(path)
df = clean_columns(df)
df = df.replace(r'^\s*$', np.nan, regex=True)
df = df.dropna(axis=1, how='all')
if df.shape[1] == 0:
    df = pd.DataFrame({'dummy': np.zeros(len(df))})
assert df.shape[0] > 0

target = None
candidate_names = ['target', 'label', 'class', 'y', 'output']
for name in candidate_names:
    for col in df.columns:
        lc = col.lower()
        if lc == name or name in lc:
            target = col
            break
    if target is not None:
        break
if target is None:
    numeric_df = df.apply(pd.to_numeric, errors='coerce')
    numeric_cols_all = [c for c in df.columns if numeric_df[c].notna().sum() > 0]
    if numeric_cols_all:
        non_const = [c for c in numeric_cols_all if numeric_df[c].nunique(dropna=True) > 1]
        target = non_const[-1] if non_const else numeric_cols_all[-1]
    else:
        target = df.columns[-1]

X = df.drop(columns=[target]).copy()
y = df[target].copy()

y_numeric = pd.to_numeric(y, errors='coerce')
y_numeric = y_numeric.replace([np.inf, -np.inf], np.nan)
numeric_ratio = y_numeric.notna().sum() / len(y) if len(y) > 0 else 0
if numeric_ratio >= 0.9:
    unique_vals = y_numeric.nunique(dropna=True)
    task = 'classification' if unique_vals <= 15 else 'regression'
else:
    task = 'classification'

if task == 'regression':
    y_clean = y_numeric
    mask = y_clean.notna()
    if mask.sum() == 0:
        y_clean = pd.Series(np.zeros(len(y)), name=target)
        mask = pd.Series([True] * len(y))
else:
    y_clean = y
    mask = y_clean.notna()
    if mask.sum() == 0:
        y_clean = pd.Series(['unknown'] * len(y), name=target)
        mask = pd.Series([True] * len(y))

X = X.loc[mask].reset_index(drop=True)
y_clean = y_clean.loc[mask].reset_index(drop=True)

if X.shape[0] == 0:
    X = pd.DataFrame({'__constant__': [1]})
    y_clean = pd.Series([0], name=target)

numeric_cols = []
for col in X.columns:
    col_numeric = pd.to_numeric(X[col], errors='coerce')
    non_na = col_numeric.notna().sum()
    ratio = non_na / len(X) if len(X) > 0 else 0
    if ratio >= 0.5:
        numeric_cols.append(col)
        X[col] = col_numeric
categorical_cols = [c for c in X.columns if c not in numeric_cols]

if X.shape[1] == 0:
    X = pd.DataFrame({'__constant__': np.ones(len(y_clean))})
    numeric_cols = ['__constant__']
    categorical_cols = []

if numeric_cols:
    X[numeric_cols] = X[numeric_cols].replace([np.inf, -np.inf], np.nan)

n_samples = len(y_clean)
if n_samples < 2:
    X_train = X
    X_test = X
    y_train = y_clean
    y_test = y_clean
else:
    stratify = None
    if task == 'classification' and y_clean.nunique() >= 2:
        stratify = y_clean
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_clean, test_size=0.2, random_state=42, stratify=stratify
    )
assert len(X_train) > 0 and len(X_test) > 0

transformers = []
if numeric_cols:
    transformers.append((
        'num',
        Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler(with_mean=False))
        ]),
        numeric_cols
    ))
if categorical_cols:
    transformers.append((
        'cat',
        Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))
        ]),
        categorical_cols
    ))
if not transformers:
    transformers = [('num', 'passthrough', X.columns.tolist())]

preprocessor = ColumnTransformer(transformers=transformers, remainder='drop', sparse_threshold=0.3)

if task == 'classification':
    if y_train.nunique() < 2:
        model = DummyClassifier(strategy='most_frequent')
    else:
        model = LogisticRegression(max_iter=200, solver='liblinear')
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])
    pipeline.fit(X_train, y_train)
    preds = pipeline.predict(X_test)
    accuracy = accuracy_score(y_test, preds)
else:
    if y_train.nunique(dropna=True) < 2:
        model = DummyRegressor(strategy='mean')
    else:
        model = Ridge(alpha=1.0)
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])
    pipeline.fit(X_train, y_train)
    preds = pipeline.predict(X_test)
    if len(y_test) > 0:
        try:
            r2 = r2_score(y_test, preds)
        except Exception:
            r2 = 0.0
    else:
        r2 = 0.0
    if not np.isfinite(r2):
        r2 = 0.0
    accuracy = max(0.0, min(1.0, (r2 + 1.0) / 2.0))

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Chose simple linear/Dummy models with minimal preprocessing for CPU and energy efficiency.
# - Used robust but lightweight imputing and one-hot encoding to handle mixed schemas.
# - For regression, converted R2 to a bounded [0,1] accuracy proxy for stable reporting.