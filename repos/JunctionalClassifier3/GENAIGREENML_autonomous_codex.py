# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import re
import pickle
import warnings
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.metrics import accuracy_score, r2_score
from sklearn.dummy import DummyClassifier

warnings.filterwarnings("ignore")

DATASET_PATH = "dict.pickle"

def robust_read_csv(path):
    try:
        df = pd.read_csv(path)
        if df.shape[1] == 1:
            try:
                df_alt = pd.read_csv(path, sep=";", decimal=",")
                if df_alt.shape[1] > 1:
                    df = df_alt
            except Exception:
                pass
    except Exception:
        try:
            df = pd.read_csv(path, sep=";", decimal=",")
        except Exception:
            df = pd.DataFrame()
    return df

def load_data(path):
    obj = None
    if os.path.exists(path):
        lower = path.lower()
        if lower.endswith((".csv", ".txt", ".tsv")):
            obj = robust_read_csv(path)
        elif lower.endswith((".pkl", ".pickle")):
            try:
                obj = pd.read_pickle(path)
            except Exception:
                try:
                    with open(path, "rb") as f:
                        obj = pickle.load(f)
                except Exception:
                    obj = None
        else:
            try:
                obj = pd.read_pickle(path)
            except Exception:
                try:
                    obj = robust_read_csv(path)
                except Exception:
                    obj = None
    df = None
    y = None
    if isinstance(obj, pd.DataFrame):
        df = obj
    elif isinstance(obj, dict):
        if "X" in obj:
            X = obj.get("X")
            if isinstance(X, pd.DataFrame):
                df = X.copy()
            else:
                try:
                    df = pd.DataFrame(X)
                except Exception:
                    df = None
            for key in ["y", "target", "label", "labels", "class"]:
                if key in obj:
                    y = obj.get(key)
                    break
        elif "data" in obj:
            data = obj.get("data")
            if isinstance(data, pd.DataFrame):
                df = data.copy()
            else:
                try:
                    df = pd.DataFrame(data)
                except Exception:
                    df = None
            for key in ["y", "target", "label", "labels", "class"]:
                if key in obj:
                    y = obj.get(key)
                    break
        elif "df" in obj:
            data = obj.get("df")
            if isinstance(data, pd.DataFrame):
                df = data.copy()
            else:
                try:
                    df = pd.DataFrame(data)
                except Exception:
                    df = None
            for key in ["y", "target", "label", "labels", "class"]:
                if key in obj:
                    y = obj.get(key)
                    break
        else:
            try:
                df = pd.DataFrame(obj)
            except Exception:
                df = None
            for key in ["y", "target", "label", "labels", "class"]:
                if key in obj and (df is None or key not in df.columns):
                    y = obj.get(key)
                    break
    elif isinstance(obj, (list, tuple)):
        if len(obj) == 2 and not isinstance(obj[0], (str, bytes, int, float)):
            X = obj[0]
            y = obj[1]
            if isinstance(X, pd.DataFrame):
                df = X.copy()
            else:
                try:
                    df = pd.DataFrame(X)
                except Exception:
                    df = None
        else:
            try:
                df = pd.DataFrame(obj)
            except Exception:
                df = None
    elif isinstance(obj, np.ndarray):
        df = pd.DataFrame(obj)
    return df, y

def normalize_columns(df):
    if df is None or df.shape[1] == 0:
        return df
    cols = []
    keep_mask = []
    seen = {}
    for c in df.columns:
        c_clean = re.sub(r"\s+", " ", str(c).strip())
        if c_clean.lower().startswith("unnamed"):
            keep_mask.append(False)
            cols.append(c_clean)
            continue
        if c_clean in seen:
            seen[c_clean] += 1
            c_clean = f"{c_clean}_{seen[c_clean]}"
        else:
            seen[c_clean] = 0
        cols.append(c_clean)
        keep_mask.append(True)
    df = df.loc[:, keep_mask].copy()
    df.columns = [c for c, k in zip(cols, keep_mask) if k]
    return df

def coerce_numeric_columns(df):
    df = df.copy()
    n_rows = len(df)
    for col in df.columns:
        col_data = df[col]
        if pd.api.types.is_numeric_dtype(col_data):
            df[col] = pd.to_numeric(col_data, errors="coerce")
        else:
            col_numeric = pd.to_numeric(col_data, errors="coerce")
            if col_numeric.notna().sum() >= max(1, int(0.5 * n_rows)):
                df[col] = col_numeric
            else:
                mask = col_data.notna()
                col_obj = col_data.astype(str)
                col_obj = col_obj.where(mask, np.nan)
                df[col] = col_obj
    df = df.replace([np.inf, -np.inf], np.nan)
    return df

def prepare_target(y):
    if isinstance(y, np.ndarray):
        if y.ndim > 1 and y.shape[1] == 1:
            y = y.ravel()
    if isinstance(y, pd.DataFrame):
        if y.shape[1] > 0:
            y = y.iloc[:, 0]
        else:
            y = pd.Series([], dtype=float)
    if isinstance(y, pd.Series):
        y_series = y.copy()
    else:
        y_series = pd.Series(y)
    if pd.api.types.is_numeric_dtype(y_series):
        y_series = pd.to_numeric(y_series, errors="coerce")
    else:
        y_num = pd.to_numeric(y_series, errors="coerce")
        if y_num.notna().sum() >= max(1, int(0.5 * len(y_num))):
            y_series = y_num
        else:
            mask = y_series.notna()
            y_series = y_series.astype(str)
            y_series = y_series.where(mask, np.nan)
    y_series = y_series.replace([np.inf, -np.inf], np.nan)
    return y_series

def choose_target(df):
    if df is None or df.shape[1] == 0:
        return None
    target_like = ["target", "label", "class", "y", "output"]
    for col in df.columns:
        if str(col).strip().lower() in target_like:
            if df[col].nunique(dropna=True) > 1:
                return col
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    candidates = [c for c in numeric_cols if df[c].nunique(dropna=True) > 1]
    if candidates:
        n = len(df)
        threshold = max(20, int(0.05 * n) + 1)
        small_unique = [c for c in candidates if df[c].nunique(dropna=True) <= threshold]
        if small_unique:
            return small_unique[0]
        return candidates[-1]
    for col in df.columns:
        if df[col].nunique(dropna=True) > 1:
            return col
    return df.columns[0]

def is_classification_target(y):
    if y.dtype == object or str(y.dtype).startswith("category"):
        return True
    unique_vals = pd.Series(y).dropna().unique()
    if len(unique_vals) <= max(20, int(0.05 * len(y)) + 1):
        return True
    return False

df, y_external = load_data(DATASET_PATH)
if df is None:
    df = pd.DataFrame()
if not isinstance(df, pd.DataFrame):
    df = pd.DataFrame(df)

df = normalize_columns(df)
df = coerce_numeric_columns(df)

if y_external is not None:
    y = prepare_target(y_external)
    if len(y) != len(df):
        min_len = min(len(y), len(df))
        df = df.iloc[:min_len].copy()
        y = y.iloc[:min_len].copy()
else:
    target_col = choose_target(df)
    if target_col is None:
        df["target"] = 0
        target_col = "target"
    y = df[target_col]
    df = df.drop(columns=[target_col])
    y = prepare_target(y)

if y.notna().sum() == 0:
    y = y.fillna(0)

mask = y.notna().values
df = df.loc[mask].copy()
y = y.loc[mask].copy()

assert len(y) > 0

X = df.copy()
if X.shape[1] == 0:
    X = pd.DataFrame({"dummy": np.zeros(len(y))})
else:
    all_nan_cols = [c for c in X.columns if X[c].isna().all()]
    if all_nan_cols:
        X = X.drop(columns=all_nan_cols)
    if X.shape[1] == 0:
        X = pd.DataFrame({"dummy": np.zeros(len(y))})

numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = [c for c in X.columns if c not in numeric_cols]

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="constant", fill_value=0.0)),
    ("scaler", StandardScaler(with_mean=False))
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="constant", fill_value="missing")),
    ("onehot", OneHotEncoder(handle_unknown="ignore", sparse=True))
])

transformers = []
if numeric_cols:
    transformers.append(("num", numeric_transformer, numeric_cols))
if categorical_cols:
    transformers.append(("cat", categorical_transformer, categorical_cols))
if not transformers:
    transformers.append(("num", numeric_transformer, X.columns.tolist()))

preprocessor = ColumnTransformer(transformers=transformers, remainder="drop", sparse_threshold=0.3)

is_classification = is_classification_target(y)
n_classes = y.nunique(dropna=True)
n_samples = len(y)

if n_samples < 2:
    X_train, X_test, y_train, y_test = X.copy(), X.copy(), y.copy(), y.copy()
else:
    test_size = 0.2 if n_samples >= 5 else 0.5
    stratify = None
    if is_classification and n_classes >= 2:
        class_counts = y.value_counts()
        if class_counts.min() >= 2 and n_samples >= 5:
            stratify = y
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=stratify
        )
    except Exception:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=None
        )

assert len(X_train) > 0 and len(X_test) > 0

if is_classification:
    train_classes = y_train.nunique(dropna=True)
    if train_classes >= 2:
        model = LogisticRegression(max_iter=200, solver="liblinear")
    else:
        model = DummyClassifier(strategy="most_frequent")
else:
    model = Ridge(alpha=1.0)

clf = Pipeline(steps=[("preprocess", preprocessor), ("model", model)])
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

if is_classification:
    accuracy = accuracy_score(y_test, y_pred)
else:
    if len(y_test) < 2:
        accuracy = 1.0 if np.allclose(y_test, y_pred, equal_nan=True) else 0.0
    else:
        r2 = r2_score(y_test, y_pred)
        if np.isnan(r2):
            r2 = 0.0
        accuracy = max(0.0, min(1.0, (r2 + 1.0) / 2.0))

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Used lightweight linear models with constant-value imputers and one-hot encoding in a single pipeline for CPU efficiency and reproducibility.
# - Applied robust schema handling and minimal feature engineering to avoid heavy computation and handle unknown data safely.
# - Converted regression R2 to a bounded [0,1] proxy via (R2+1)/2 for stable accuracy reporting.