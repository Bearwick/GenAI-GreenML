# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

TRAIN_PATH = "movie_review_train.csv"
TEST_PATH = "movie_review_test.csv"


def load_data(path: str) -> pd.DataFrame:
    df = pd.read_csv(path, header=0, names=["Class", "text"], usecols=[0, 1])
    df["label"] = df["Class"].map({"Neg": 0, "Pos": 1}).astype("int8")
    return df


def train_and_evaluate(train_df: pd.DataFrame, test_df: pd.DataFrame) -> float:
    X_train = train_df["text"]
    y_train = train_df["label"]
    X_test = test_df["text"]
    y_test = test_df["label"]

    vect = CountVectorizer(stop_words="english", min_df=0.03, max_df=0.8, dtype="int32")
    X_train_vec = vect.fit_transform(X_train)
    X_test_vec = vect.transform(X_test)

    model = MultinomialNB()
    model.fit(X_train_vec, y_train)

    y_pred = model.predict(X_test_vec)
    return accuracy_score(y_test, y_pred)


def main() -> None:
    train_df = load_data(TRAIN_PATH)
    test_df = load_data(TEST_PATH)
    accuracy = train_and_evaluate(train_df, test_df)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# Dropped unused exploratory operations (head/value_counts/vocabulary inspection) to avoid redundant computation.
# Removed probability prediction, confusion-matrix/ROC computations, and plotting since they were not required for final output.
# Reduced I/O and memory: read only needed columns via usecols and stored labels as int8.
# Avoided repeated metric calls; compute accuracy once and print in the required format.
# Kept sparse matrices throughout (CountVectorizer + MultinomialNB) to minimize memory footprint and data movement.
# Specified CountVectorizer dtype to reduce memory usage and improve cache efficiency without changing behavior.