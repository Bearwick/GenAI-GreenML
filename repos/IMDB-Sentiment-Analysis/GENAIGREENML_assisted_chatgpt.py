# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import MultinomialNB


RANDOM_SEED = 42


def _read_csv_robust(path: str, expected_cols: int = 2) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] != expected_cols:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _standardize_schema(df: pd.DataFrame, dataset_headers: list[str]) -> pd.DataFrame:
    df = df.copy()
    if df.shape[1] >= len(dataset_headers):
        df = df.iloc[:, : len(dataset_headers)]
    df.columns = dataset_headers[: df.shape[1]]

    for col in dataset_headers:
        if col not in df.columns:
            df[col] = np.nan

    df["class"] = df["class"].astype(str)
    df["text"] = df["text"].fillna("").astype(str)
    return df[dataset_headers]


def _encode_labels(series: pd.Series) -> np.ndarray:
    mapped = series.map({"Neg": 0, "Pos": 1})
    return mapped.fillna(-1).astype(np.int8).to_numpy()


def main() -> None:
    np.random.seed(RANDOM_SEED)

    dataset_headers = ["class", "text"]
    train_path = "movie_review_train.csv"
    test_path = "movie_review_test.csv"

    train_raw = _read_csv_robust(train_path, expected_cols=len(dataset_headers))
    test_raw = _read_csv_robust(test_path, expected_cols=len(dataset_headers))

    train_df = _standardize_schema(train_raw, dataset_headers)
    test_df = _standardize_schema(test_raw, dataset_headers)

    y_train = _encode_labels(train_df["class"])
    y_test = _encode_labels(test_df["class"])

    valid_train = y_train != -1
    valid_test = y_test != -1

    X_train = train_df.loc[valid_train, "text"].to_numpy(dtype=object, copy=False)
    y_train = y_train[valid_train]

    X_test = test_df.loc[valid_test, "text"].to_numpy(dtype=object, copy=False)
    y_test = y_test[valid_test]

    vect = CountVectorizer(stop_words="english", min_df=0.03, max_df=0.8)
    X_train_vec = vect.fit_transform(X_train)
    X_test_vec = vect.transform(X_test)

    mnb = MultinomialNB()
    mnb.fit(X_train_vec, y_train)
    y_pred = mnb.predict(X_test_vec)

    accuracy = float(accuracy_score(y_test, y_pred))
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed exploratory/unused computations (value_counts, vocabulary inspection, probability predictions, ROC/AUC, confusion-matrix-derived metrics, extra word counts) to cut CPU work and memory.
# - Eliminated plotting and all intermediate DataFrame constructions for thresholds/ROC to avoid heavy dependencies and unnecessary data movement.
# - Vectorized label encoding and used compact dtype (int8) to reduce memory footprint.
# - Avoided redundant transforms/prints; computed only what is required for final accuracy output.
# - Implemented robust CSV parsing fallback (default read, then retry with sep=';' and decimal=',') to prevent costly downstream failures/retries.
# - Standardized schema by deriving from provided DATASET_HEADERS and actual df columns without assuming exact source column names beyond order.
# - Ensured reproducibility by setting a fixed random seed (even though the pipeline is deterministic, this stabilizes any implicit randomness).