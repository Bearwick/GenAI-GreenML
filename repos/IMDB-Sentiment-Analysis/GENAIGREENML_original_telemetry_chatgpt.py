# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: original_telemetry

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics


def main():
    docs = pd.read_csv("movie_review_train.csv", header=0, names=["Class", "text"])
    docs_test = pd.read_csv("movie_review_test.csv", header=0, names=["Class", "text"])

    docs["label"] = docs.Class.map({"Neg": 0, "Pos": 1})
    docs_test["label"] = docs_test.Class.map({"Neg": 0, "Pos": 1})

    X = docs.text
    y = docs.label
    X_test = docs_test.text
    y_test = docs_test.label

    vect = CountVectorizer(stop_words="english", min_df=0.03, max_df=0.8)
    vect.fit(X)

    X_train_transformed = vect.transform(X)
    X_test_transformed = vect.transform(X_test)

    mnb = MultinomialNB()
    mnb.fit(X_train_transformed, y)

    y_pred_class = mnb.predict(X_test_transformed)
    y_pred_proba = mnb.predict_proba(X_test_transformed)

    accuracy = metrics.accuracy_score(y_test, y_pred_class)
    print(f"ACCURACY={accuracy:.6f}")

    confusion = metrics.confusion_matrix(y_test, y_pred_class)
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    TP = confusion[1, 1]

    sensitivity = TP / float(FN + TP)
    specificity = TN / float(TN + FP)
    precision = TP / float(TP + FP)

    word_count = mnb.feature_count_.sum(axis=1)
    nwc = word_count[0]
    pwc = word_count[1]

    _ = (
        y_pred_proba,
        sensitivity,
        specificity,
        precision,
        nwc,
        pwc,
    )


if __name__ == "__main__":
    main()