# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import glob
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

def find_dataset():
    candidates = []
    env_path = os.getenv("DATASET_PATH")
    if env_path and os.path.isfile(env_path):
        candidates.append(env_path)
    search_paths = [os.getcwd(), "/mnt/data", "/data", "/datasets"]
    for path in search_paths:
        if os.path.isdir(path):
            candidates.extend(glob.glob(os.path.join(path, "*.csv")))
    for file_path in candidates:
        try:
            sample = pd.read_csv(file_path, nrows=5)
        except Exception:
            continue
        cols = [c.lower() for c in sample.columns]
        if "class" in cols and "text" in cols:
            return file_path
    if candidates:
        return candidates[0]
    raise FileNotFoundError("No suitable dataset file found.")

dataset_path = find_dataset()
df = pd.read_csv(dataset_path)

lower_to_original = {c.lower(): c for c in df.columns}
class_col = lower_to_original.get("class")
text_col = lower_to_original.get("text")
if class_col is None or text_col is None:
    raise ValueError("Required columns not found.")

df = df[[class_col, text_col]].dropna().drop_duplicates()
df[class_col] = df[class_col].astype(str)
df[text_col] = df[text_col].astype(str)

X = df[text_col]
y = df[class_col]

counts = y.value_counts()
stratify = y if len(counts) > 1 and counts.min() >= 2 else None

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=stratify
)

vectorizer = TfidfVectorizer(
    lowercase=True,
    max_features=20000,
    min_df=1,
    ngram_range=(1, 1)
)
classifier = MultinomialNB()
model = Pipeline([("vectorizer", vectorizer), ("classifier", classifier)])
model.fit(X_train, y_train)

pred = model.predict(X_test)
accuracy = accuracy_score(y_test, pred)
print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# Used a capped TF-IDF vocabulary to limit feature space and memory use.
# Selected Multinomial Naive Bayes for fast training and inference on sparse text data.
# Applied simple, deterministic preprocessing and a fixed random state for reproducibility.