# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

def load_data(path):
    try:
        df = pd.read_csv(path)
        if df.shape[1] < 2:
            raise ValueError
    except:
        df = pd.read_csv(path, sep=';', decimal=',')
    
    df = df.iloc[:, [0, 1]]
    df.columns = ['Class', 'text']
    return df

train_data = load_data('movie_review_train.csv')
test_data = load_data('movie_review_test.csv')

train_data['label'] = train_data['Class'].map({'Neg': 0, 'Pos': 1})
test_data['label'] = test_data['Class'].map({'Neg': 0, 'Pos': 1})

vect = CountVectorizer(stop_words='english', min_df=0.03, max_df=0.8)
X_train = vect.fit_transform(train_data['text'])
X_test = vect.transform(test_data['text'])

model = MultinomialNB()
model.fit(X_train, train_data['label'])
y_pred = model.predict(X_test)

accuracy = accuracy_score(test_data['label'], y_pred)
print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# - Used fit_transform() to combine fitting and transformation into a single pass, reducing computational overhead.
# - Removed redundant calculations for ROC AUC, precision, recall, and F1 scores that were not required for the final output.
# - Eliminated heavy visualization libraries like Matplotlib and all plotting code to reduce memory usage and energy consumption.
# - Implemented a robust data loading function with fallback parsing logic to handle different CSV formats efficiently.
# - Removed exploratory prints, value counts, and shape logging to minimize runtime and CPU cycles.
# - Optimized memory management by avoiding unnecessary intermediate data structures and selecting only required columns.
# - Simplified the workflow by using the more efficient predict() method instead of predict_proba() when class probabilities were not needed.