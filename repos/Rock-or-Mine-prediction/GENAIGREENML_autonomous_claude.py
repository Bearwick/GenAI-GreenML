# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# --- Robust CSV Loading ---
try:
    df = pd.read_csv("Sonar Data.csv")
    if df.shape[1] < 3:
        df = pd.read_csv("Sonar Data.csv", sep=';', decimal=',')
except Exception:
    df = pd.read_csv("Sonar Data.csv", sep=';', decimal=',')

# --- Column Name Normalization ---
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# --- Schema Detection ---
# The Sonar dataset typically has 60 numeric features and 1 categorical target (R/M)
# Headers may be the first data row if there's no proper header line

# Check if the last column contains class labels
last_col = df.columns[-1]
unique_last = df[last_col].dropna().unique()

# If headers look like data values (numeric strings), the CSV likely has no header row
# Detect this: if most column names look like floats, re-read without header
try:
    float_count = sum(1 for c in df.columns if isinstance(c, str) and c.replace('.', '', 1).replace('-', '', 1).isdigit())
except Exception:
    float_count = 0

if float_count > len(df.columns) * 0.5:
    # Re-read without header; column names are actually the first data row
    df = pd.read_csv("Sonar Data.csv", header=None)
    if df.shape[1] < 3:
        df = pd.read_csv("Sonar Data.csv", header=None, sep=';', decimal=',')
    df.columns = [f"feat_{i}" if i < df.shape[1] - 1 else "target" for i in range(df.shape[1])]
    last_col = "target"

# --- Identify Target and Features ---
# Target is the column with few unique categorical values (likely 'R' and 'M')
target_col = None
for col in df.columns:
    nunique = df[col].dropna().nunique()
    if nunique <= 10 and df[col].dtype == object:
        target_col = col
        break

if target_col is None:
    # Fallback: use last column
    target_col = df.columns[-1]

feature_cols = [c for c in df.columns if c != target_col]

# --- Coerce Features to Numeric ---
for col in feature_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Drop rows where target is NaN
df = df.dropna(subset=[target_col])

# Drop columns that are entirely NaN
valid_features = [c for c in feature_cols if df[c].notna().sum() > 0]
df = df.dropna(subset=valid_features, how='all')

# Fill remaining NaN in features with median
for col in valid_features:
    if df[col].isna().any():
        df[col] = df[col].fillna(df[col].median())

# Replace inf
df[valid_features] = df[list(valid_features)].replace([np.inf, -np.inf], np.nan)
for col in valid_features:
    if df[col].isna().any():
        df[col] = df[col].fillna(df[col].median())

assert len(df) > 0, "Dataset empty after preprocessing"

# --- Encode Target ---
le = LabelEncoder()
y = le.fit_transform(df[target_col].astype(str))
X = df[list(valid_features)].values

assert X.shape