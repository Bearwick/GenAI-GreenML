# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def load_data(file_path):
    try:
        df = pd.read_csv(file_path, header=None)
        if df.shape[1] < 2:
            raise ValueError
    except (pd.errors.ParserError, ValueError):
        df = pd.read_csv(file_path, header=None, sep=';', decimal=',')
    return df

sonar_data = load_data('Sonar Data.csv')

X = sonar_data.iloc[:, :-1]
Y = sonar_data.iloc[:, -1]

X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.7, stratify=Y, random_state=1
)

model = LogisticRegression(random_state=1)
model.fit(X_train, Y_train)

test_preds = model.predict(X_test)
accuracy = accuracy_score(Y_test, test_preds)

print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# 1. Removed redundant exploratory data analysis steps (describe, value_counts, groupby) to eliminate unnecessary computation and memory usage.
# 2. Implemented robust CSV loading with fallback logic to handle different delimiters and decimal separators efficiently.
# 3. Replaced explicit column indexing with iloc slicing to make the code schema-agnostic and reduce index-lookup overhead.
# 4. Removed intermediate variable assignments and training-set accuracy calculations to save CPU cycles and memory.
# 5. Fixed random_state in both data splitting and model initialization to ensure reproducibility without added computational cost.
# 6. Streamlined the execution pipeline by removing all non-essential logging and prints, reducing I/O overhead.
# 7. Minimized data movement by avoiding the creation of unnecessary intermediate data structures.