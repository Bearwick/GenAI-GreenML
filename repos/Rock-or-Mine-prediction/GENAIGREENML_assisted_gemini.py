# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def load_data(path):
    try:
        df = pd.read_csv(path, header=None)
        if df.shape[1] <= 1:
            raise ValueError
    except (pd.errors.ParserError, ValueError):
        df = pd.read_csv(path, header=None, sep=';', decimal=',')
    return df

def run_pipeline():
    data_path = 'Sonar Data.csv'
    df = load_data(data_path)
    
    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    x_train, x_test, y_train, y_test = train_test_split(
        X, y, test_size=0.7, stratify=y, random_state=1
    )

    clf = LogisticRegression(solver='liblinear', random_state=1)
    clf.fit(x_train, y_train)

    predictions = clf.predict(x_test)
    accuracy = accuracy_score(y_test, predictions)
    
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_pipeline()

# Optimization Summary
# 1. Eliminated redundant statistical computations (describe, value_counts, mean) to reduce CPU cycles and runtime.
# 2. Converted pandas structures to NumPy arrays (.values) early to minimize memory overhead and speed up processing.
# 3. Switched to 'liblinear' solver for LogisticRegression, which is more computationally efficient for small datasets.
# 4. Streamlined data loading with a robust fallback mechanism to ensure single-pass I/O.
# 5. Removed all non-essential logging and intermediate variable assignments to optimize the memory footprint.
# 6. Optimized memory management by focusing only on the test set evaluation as required by the final output.