# Generated by generate_llm_code.py
# LLM: groq
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# load dataset (no header row in file)
df = pd.read_csv('Sonar Data.csv', header=None)

# separate features and target
X = df.drop(60, axis=1)
y = df[60]

# split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.7, stratify=y, random_state=1
)

# train a lightweight logistic regression model
model = LogisticRegression(max_iter=200, n_jobs=1)
model.fit(X_train, y_train)

# evaluate on test data
y_pred = model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={test_accuracy:.6f}")

# ---- Optimizations applied ----
# 1. Removed unnecessary data exploration (describe, value_counts, groupby).
# 2. Eliminated all intermediate prints and plots to reduce I/O overhead.
# 3. Set `max_iter=200` to limit training iterations without compromising accuracy.
# 4. Specified `n_jobs=1` to avoid overhead of thread creation.
# 5. Kept only essential imports and operations for minimal memory footprint.