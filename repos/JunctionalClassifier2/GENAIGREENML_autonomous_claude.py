# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

# Load the pickle file
with open('dict.pickle', 'rb') as f:
    data = pickle.load(f, encoding='latin1')

# Inspect what we got and convert to a DataFrame
if isinstance(data, dict):
    # Try to figure out the structure
    # Could be a dict of arrays, a dict with keys like 'data', 'target', etc.
    if 'data' in data and 'target' in data:
        X_raw = np.array(data['data'])
        y_raw = np.array(data['target'])
        if 'feature_names' in data:
            feature_names = list(data['feature_names'])
        else:
            feature_names = [f'f{i}' for i in range(X_raw.shape[1])]
        df = pd.DataFrame(X_raw, columns=feature_names)
        df['target'] = y_raw
    else:
        # Try to convert dict directly to DataFrame
        # Check if values are arrays/lists of equal length
        lengths = {}
        for k, v in data.items():
            if isinstance(v, (list, np.ndarray)):
                lengths[k] = len(v) if hasattr(v, '__len__') else 1
            else:
                lengths[k] = 1

        max_len = max(lengths.values()) if lengths else 0

        if max_len > 1:
            # Filter keys that have the right length
            dict_for_df = {}
            scalar_keys = {}
            for k, v in data.items():
                if isinstance(v, (list, np.ndarray)):
                    arr = np.array(v)
                    if arr.ndim == 1 and len(arr) == max_len:
                        dict_for_df[k] = arr
                    elif arr.ndim == 2 and arr.shape[0] == max_len:
                        for i in range(arr.shape[1]):
                            dict_for_df[f'{k}_{i}'] = arr[:, i]
                    elif arr.ndim == 0:
                        scalar_keys[k] = v
                else:
                    scalar_keys[k] = v
            df = pd.DataFrame(dict_for_df)
        else:
            # Possibly nested structure; flatten
            # Try treating keys as row indices or as feature dicts
            first_val = next(iter(data.values()))
            if isinstance(first_val, dict):
                df = pd.DataFrame.from_dict(data, orient='index')
            else:
                df = pd.DataFrame([data])
elif isinstance(data, pd.DataFrame):
    df = data
elif isinstance(data, (list, np.ndarray)):
    arr = np.array(data)
    if arr.ndim == 2:
        df = pd.DataFrame(arr, columns=[f'f{i}' for i in range(arr.shape[1])])
    else:
        df = pd.DataFrame({'value': arr})
else:
    df = pd.DataFrame(data)

# Clean column names
df.columns = [str(c).strip() for c in df.columns]
df.columns = [' '.join(c.split()) for c in df.columns]
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

assert df.shape[0] > 0, "Dataset is empty after loading"

# Identify target column
# Based on project context: classification of junctional features
# Labels: -1 (remodelling), 0 (mixed/uncertainty), 1 (inactive)
# Look for a target-like column
target_col = None
candidate_target_names = ['target', 'label', 'class', 'labels', 'classes',