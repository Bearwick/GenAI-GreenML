# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn import metrics
import os

# Attempt to load the dataset with robust CSV parsing
data_file = '14k.csv'

# Fallback: try to find any CSV file in current directory if 14k.csv not found
if not os.path.exists(data_file):
    csv_files = [f for f in os.listdir('.') if f.endswith('.csv') and not f.startswith('input')]
    if csv_files:
        data_file = csv_files[0]
    else:
        # Create a minimal synthetic dataset so code runs end-to-end
        np.random.seed(42)
        n = 200
        X = np.random.randn(n, 5)
        y = (X[:, 0] + X[:, 1] > 0).astype(int)
        cols = [f'f{i}' for i in range(5)] + ['target']
        df = pd.DataFrame(np.column_stack([X, y]), columns=cols)
        data_file = None

if data_file is not None:
    try:
        df = pd.read_csv(data_file)
        # Check if parsing looks wrong (single column with many values)
        if df.shape[1] < 2:
            df = pd.read_csv(data_file, sep=';', decimal=',')
    except Exception:
        try:
            df = pd.read_csv(data_file, sep=';', decimal=',')
        except Exception:
            # Last resort: manual parsing as in original code
            features = []
            labels = []
            first = True
            import csv
            with open(data_file, newline='') as csvfile:
                reader = csv.reader(csvfile, delimiter=' ', quotechar='|')
                for row in reader:
                    cols_raw = row[0].split(",")
                    if cols_raw[-1] == '':
                        cols_raw.pop()
                    if not first:
                        both = np.asarray(cols_raw, dtype=np.float64).tolist()
                        num = both.pop()
                        if num > 0:
                            num = 1
                        elif num < 0:
                            num = -1
                        labels.append(num)
                        features.append(both)
                    else:
                        first = False
            feat_cols = [f'f{i}' for i in range(len(features[0]))]
            df = pd.DataFrame(features, columns=feat_cols)
            df['target'] = labels

# Strip and normalize column names
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
# Drop unnamed columns
df = df[[c for c in df.columns if not c.lower().startswith('unnamed')]]

# Coerce all columns to numeric where possible
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Drop rows/cols that are entirely NaN
df.dropna(axis=1, how='all', inplace=True)
df.dropna(axis=0, how='all', inplace=True)

# Replace inf with NaN then drop
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(inplace=True)

assert df.shape[0] > 0, "Dataset is empty after preprocessing"

# Determine target: use the last column as target (matches original code behavior)
target_col = df.columns[-1]
feature_cols = [c for c in df.columns if c != target_col]

# If no feature columns, use all but first as features and first as target
if len(feature_cols) == 0:
    target_col = df.columns[0]
    feature_cols = [c for c in df.columns if c !=