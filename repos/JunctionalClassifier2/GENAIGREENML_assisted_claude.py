# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import numpy as np
import csv
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics

RANDOM_SEED = 42

def load_csv(filename):
    features = []
    labels = []
    with open(filename, newline='') as csvfile:
        reader = csv.reader(csvfile, delimiter=' ', quotechar='|')
        first = True
        for row in reader:
            cols = row[0].split(",")
            if cols[-1] == '':
                cols.pop()
            if not first:
                vals = np.asarray(cols, dtype=np.float64)
                label_val = vals[-1]
                if label_val > 0:
                    label_val = 1.0
                elif label_val < 0:
                    label_val = -1.0
                labels.append(label_val)
                features.append(vals[:-1].tolist())
            else:
                first = False
    return features, labels

def train_and_evaluate():
    features, labels = load_csv('14k.csv')
    feat_arr = np.array(features, dtype=np.float64)
    lab_arr = np.array(labels, dtype=np.float64)
    feat_train, feat_test, lab_train, lab_test = train_test_split(
        feat_arr, lab_arr, test_size=0.3, random_state=RANDOM_SEED
    )
    classifier = KNeighborsClassifier(n_neighbors=4)
    classifier.fit(feat_train, lab_train)
    y_pred = classifier.predict(feat_test)
    accuracy = metrics.accuracy_score(lab_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")

train_and_evaluate()

# Optimization Summary
# - Removed global mutable state; features/labels are returned from the loader function directly.
# - Eliminated redundant pickle save/load cycle and predict() flow that required input.csv.
# - Removed interactive input, plots, print statements, and unittest class.
# - Converted features/labels to numpy arrays before train_test_split to avoid repeated list-to-array conversion.
# - Used slicing (vals[:-1]) instead of list pop to separate features from label, avoiding mutation.
# - Set a fixed random_state in train_test_split for reproducibility.
# - Removed csv module's redundant copy import and unused imports (svm, pickle, copy, unittest).
# - Avoided saving any artifacts (no pickle dump).
# - Kept the same KNN algorithm, same dataset, same task, same CSV parsing logic.