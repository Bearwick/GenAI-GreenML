# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def load_optimized(file_path, labeled=True):
    try:
        data = np.genfromtxt(file_path, delimiter=',', skip_header=1)
        if data.ndim == 1:
            data = data.reshape(1, -1)
        if np.isnan(data[0, -1]):
            data = data[:, :-1]
        
        if labeled:
            return data[:, :-1], np.sign(data[:, -1])
        return data
    except Exception:
        return None

def main():
    features, labels = load_optimized('14k.csv', labeled=True)
    
    if features is not None:
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels, test_size=0.3, random_state=42
        )

        clf = KNeighborsClassifier(n_neighbors=4, n_jobs=-1)
        clf.fit(X_train, y_train)
        
        y_pred = clf.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"ACCURACY={accuracy:.6f}")

        p_features = load_optimized('input.csv', labeled=False)
        if p_features is not None:
            _ = clf.predict(p_features)

if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# 1. Replaced row-by-row manual CSV parsing with NumPy's vectorized genfromtxt to reduce I/O time and CPU overhead.
# 2. Migrated data storage from nested Python lists to contiguous NumPy arrays, significantly reducing memory footprint.
# 3. Vectorized the label binarization process using np.sign, eliminating the need for iterative conditional logic.
# 4. Enabled n_jobs=-1 in the KNeighborsClassifier to utilize multi-core parallelism, shortening the execution runtime.
# 5. Eliminated redundant disk operations by removing unused pickle serialization (save/load) logic.
# 6. Streamlined data cleaning by handling trailing empty columns using vectorized NaN detection instead of per-row string checks.
# 7. Reduced memory and startup overhead by removing unused imports (svm, pickle, unittest, csv, copy).
# 8. Optimized the execution flow by passing variables directly, avoiding expensive global variable lookups and resets.