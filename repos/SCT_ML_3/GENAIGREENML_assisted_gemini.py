# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

try:
    df = pd.read_csv("cat_dog_data.csv")
    if df.shape[1] < 2:
        raise ValueError
except (pd.errors.ParserError, ValueError, Exception):
    df = pd.read_csv("cat_dog_data.csv", sep=";", decimal=",")

target_col = [col for col in df.columns if col.lower() == 'label'][0]
X = df.drop(columns=[target_col])
y = LabelEncoder().fit_transform(df[target_col])

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

model = LinearSVC(random_state=42, dual='auto')
model.fit(X_train, y_train)

accuracy = accuracy_score(y_test, model.predict(X_test))
print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# 1. Replaced SVC(kernel="linear") with LinearSVC, reducing time complexity from O(n^2) to O(n).
# 2. Implemented robust CSV ingestion with automated fallback for different delimiters and decimals.
# 3. Eliminated redundant memory allocation by removing intermediate LabelEncoder objects and classification reports.
# 4. Reduced computational overhead by removing logging, visualizations, and interactive components.
# 5. Optimized training speed by using 'dual=auto' to select the most efficient solver based on dataset shape.
# 6. Ensured deterministic behavior and reproducibility with fixed random seeds for both data splitting and model training.