# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

RANDOM_SEED = 42
DATASET_PATH = "cat_dog_data.csv"
DATASET_HEADERS = ["feature1", "feature2", "feature3", "feature4", "feature5", "label"]


def _read_csv_with_fallback(path: str, expected_headers: list[str]) -> pd.DataFrame:
    df = pd.read_csv(path)

    def looks_wrong(frame: pd.DataFrame) -> bool:
        if frame is None or frame.empty:
            return True
        cols = list(frame.columns)
        if len(cols) <= 1:
            return True
        if len(cols) != len(expected_headers):
            return True
        missing = set(expected_headers) - set(cols)
        if missing:
            return True
        return False

    if looks_wrong(df):
        df = pd.read_csv(path, sep=";", decimal=",")

    if df.columns.tolist() != expected_headers and set(expected_headers).issubset(df.columns):
        df = df[expected_headers]

    return df


def main() -> None:
    df = _read_csv_with_fallback(DATASET_PATH, DATASET_HEADERS)

    label_col = "label" if "label" in df.columns else df.columns[-1]
    feature_cols = [c for c in df.columns if c != label_col]

    X = df[feature_cols]
    y = df[label_col]

    encoder = LabelEncoder()
    y_encoded = encoder.fit_transform(y)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.3, random_state=RANDOM_SEED, shuffle=True
    )

    model = SVC(kernel="linear")
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed classification_report generation/printing to avoid extra metric computation and string formatting while preserving the core evaluation intent (accuracy).
# - Used column selection (df[feature_cols]) instead of df.drop(...) to avoid creating an extra intermediate DataFrame copy.
# - Added robust CSV parsing fallback (default read_csv, then retry with sep=';' and decimal=',') to prevent wasted reruns and ensure correct ingestion with minimal overhead.
# - Centralized constants (seed, paths, headers) and set a fixed random_state for reproducibility and stable results across runs.
# - Kept the model and split logic unchanged (linear SVC, same test_size and seed) to preserve original behavior while avoiding unnecessary additional steps.