# Generated by generate_llm_code.py
# LLM: groq
# Mode: autonomous

"""
Energy‑efficient ML pipeline for the cat/dog feature dataset.
- Uses a linear SGDClassifier (stochastic gradient descent) which is lightweight,
  converges quickly, and has a small memory footprint.
- Features are standardised with StandardScaler.
- No embeddings or deep learning components are used.
- Training and inference are CPU‑only and require minimal memory.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score

# Load data
df = pd.read_csv("cat_dog_data.csv")

# Separate features and target
X = df.drop("label", axis=1).values
y = df["label"].values

# Encode labels to integers
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split with stratification to preserve class balance
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled,
    y_encoded,
    test_size=0.3,
    random_state=42,
    stratify=y_encoded,
)

# Lightweight linear model trained with stochastic gradient descent
model = SGDClassifier(
    loss="log",          # logistic regression
    max_iter=1000,
    tol=1e-3,
    random_state=42,
)
model.fit(X_train, y_train)

# Evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Only accuracy is printed
print(f"ACCURACY={accuracy:.6f}")