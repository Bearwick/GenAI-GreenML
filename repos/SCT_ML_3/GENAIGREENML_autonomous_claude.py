# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# --- Robust CSV loading ---
try:
    df = pd.read_csv("cat_dog_data.csv")
    if df.shape[1] < 2:
        df = pd.read_csv("cat_dog_data.csv", sep=';', decimal=',')
except Exception:
    df = pd.read_csv("cat_dog_data.csv", sep=';', decimal=',')

# --- Column name normalization ---
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# --- Identify target and features ---
expected_target = 'label'
if expected_target in df.columns:
    target_col = expected_target
else:
    # Fallback: pick last column as target
    target_col = df.columns[-1]

feature_cols = [c for c in df.columns if c != target_col]

# --- Separate X and y ---
X = df[list(feature_cols)].copy()
y = df[target_col].copy()

# --- Encode target if categorical ---
is_classification = True
encoder = LabelEncoder()
if y.dtype == object or y.dtype.name == 'category':
    y_encoded = encoder.fit_transform(y.astype(str))
else:
    unique_vals = y.dropna().unique()
    if len(unique_vals) <= 20:
        y_encoded = encoder.fit_transform(y.astype(str))
    else:
        is_classification = False
        y_encoded = pd.to_numeric(y, errors='coerce').values

# --- Coerce numeric features ---
for col in feature_cols:
    X[col] = pd.to_numeric(X[col], errors='coerce')

# --- Drop non-numeric columns that couldn't be coerced ---
numeric_cols = [c for c in feature_cols if X[c].notna().sum() > 0 and X[c].dtype in [np.float64, np.int64, np.float32, np.int32]]
X = X[list(numeric_cols)]

# --- Handle NaN/inf ---
X = X.replace([np.inf, -np.inf], np.nan)
valid_mask = X.notna().all(axis=1) & pd.Series(~np.isnan(y_encoded), index=X.index)
X = X.loc[valid_mask]
y_encoded = y_encoded[valid_mask.values]

# --- Fill remaining NaN with median ---
for col in X.columns:
    if X[col].isna().any():
        X[col] = X[col].fillna(X[col].median())

# --- Defensive checks ---
assert X.shape[0] > 0, "Dataset empty after preprocessing"
assert X.shape[1] > 0, "No features remaining"

n_classes = len(np.unique(y_encoded))
if is_classification and n_classes < 2:
    is_classification = False

# --- Train/test split ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded if is_classification else None
)

assert len(X_train) > 0 and len(X_test) > 0, "Train or test set is empty"

# --- Scaling ---
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- Model selection: Logistic Regression is energy-efficient and sufficient for binary/small classification ---
if is_classification:
    model = LogisticRegression(max_iter=500