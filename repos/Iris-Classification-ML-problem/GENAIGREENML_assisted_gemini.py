# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

SEED = 4096
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

df = pd.read_csv('iris.data', header=None, names=['SLength', 'SWidth', 'PLength', 'PWidth', 'class'])
df['class'] = df['class'].astype('category').cat.codes

n = len(df)
indices = np.random.permutation(n)
df = df.iloc[indices]

x_raw = df.iloc[:, :4].values.astype(np.float32)
y_raw = df.iloc[:, -1].values.astype(np.int64)

mu = x_raw.mean(axis=0)
span = x_raw.max(axis=0) - x_raw.min(axis=0)
x_raw = (x_raw - mu) / span

num_train = int(n * 0.6)
x_train = torch.from_numpy(x_raw[:num_train])
y_train = torch.from_numpy(y_raw[:num_train])
x_test = torch.from_numpy(x_raw[num_train:])
y_test = torch.from_numpy(y_raw[num_train:])

class IrisNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fn1 = nn.Linear(4, 6)
        self.fn2 = nn.Linear(6, 3)
        
    def forward(self, x):
        return self.fn2(F.relu(self.fn1(x)))

model = IrisNN()
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)

for epoch in range(200):
    model.train()
    optimizer.zero_grad(set_to_none=True)
    
    scores = model(x_train)
    loss = loss_fn(scores, y_train)
    loss.backward()
    optimizer.step()
    
    model.eval()
    with torch.no_grad():
        test_scores = model(x_test)
        test_preds = test_scores.argmax(dim=1)
        accuracy = (test_preds == y_test).float().mean().item()

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Removed DataLoader/Dataset overhead: Tiny dataset (150 samples) processed as full-batch tensors to avoid iterator and batching logic overhead.
# 2. CPU execution: Used CPU to avoid the disproportionate energy and latency costs of GPU initialization and data transfers for a small 4-feature model.
# 3. Memory optimization: Employed `set_to_none=True` in `optimizer.zero_grad()` to reduce memory bandwidth usage and slightly speed up execution.
# 4. Vectorized preprocessing: Replaced custom functions with NumPy broadcasting for data normalization, reducing Python-level loop overhead.
# 5. Reduced redundant computation: Eliminated repeated `.to(device)` calls and redundant data splitting/shuffling logic.
# 6. Minimized intermediate structures: Simplified the data pipeline to keep data in contiguous memory blocks, reducing footprint and allocation time.