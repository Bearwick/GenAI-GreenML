# Generated by generate_llm_code.py
# LLM: groq
# Mode: autonomous

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# ------------------------------ ENERGY-EFFICIENT DESIGN ------------------------------
# 1. Use a linear model (LogisticRegression) – far less computationally intensive than deep networks.
# 2. Standardize features with StandardScaler (simple, per‑feature operations).
# 3. Small dataset (iris) allows 60/40 split without overfitting concerns.
# 4. All operations run on CPU; no GPU or heavy libraries are required.
# 5. Random seed ensures reproducibility and stable results across runs.

SEED = 4096
np.random.seed(SEED)

# Load dataset
df = pd.read_csv(
    'iris.data',
    header=None,
    names=['SLength', 'SWidth', 'PLength', 'PWidth', 'class']
)

# Encode class labels as integers
df['class'] = df['class'].astype('category')
df['class'] = df['class'].cat.codes

# Separate features and labels
X = df.iloc[:, :4].values.astype(np.float32)
y = df.iloc[:, -1].values.astype(np.int64)

# Feature scaling to zero mean and unit variance
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train / test split (60% train, 40% test)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled,
    y,
    test_size=0.4,
    shuffle=True,
    random_state=SEED,
    stratify=y
)

# Initialize and train logistic regression model
model = LogisticRegression(
    max_iter=200,
    solver='lbfgs',
    multi_class='multinomial'
)
model.fit(X_train, y_train)

# Evaluate on test set
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={accuracy:.6f}")