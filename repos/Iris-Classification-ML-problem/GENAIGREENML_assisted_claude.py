# Generated by generate_llm_code.py
# LLM: claude
# Mode: assisted

import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F

SEED = 4096
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)
np.random.seed(SEED)

file_path = 'iris.data'
try:
    df = pd.read_csv(file_path, header=None, names=['SLength', 'SWidth', 'PLength', 'PWidth', 'class'])
    if df.shape[1] != 5:
        raise ValueError
except Exception:
    df = pd.read_csv(file_path, header=None, sep=';', decimal=',', names=['SLength', 'SWidth', 'PLength', 'PWidth', 'class'])

df['class'] = df['class'].astype('category').cat.codes

n = len(df.index)
shuffled_indices = np.random.permutation(n)
df = df.iloc[shuffled_indices]

x = df.iloc[:, :4].values.astype(np.float32)
y = df.iloc[:, -1].values.astype(np.int64)

mu = x.mean(axis=0)
span = x.max(axis=0) - x.min(axis=0)
x = (x - mu) / span

num_train = int(n * .6)
num_test = n - num_train

x_train = x[:num_train]
y_train = y[:num_train]
x_test = x[-num_test:]
y_test = y[-num_test:]

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

x_train_t = torch.from_numpy(x_train).to(device)
y_train_t = torch.from_numpy(y_train).long().to(device)
x_test_t = torch.from_numpy(x_test).to(device)
y_test_t = torch.from_numpy(y_test).long().to(device)


class IrisNN(nn.Module):
    def __init__(self):
        super(IrisNN, self).__init__()
        self.fn1 = nn.Linear(4, 6)
        self.fn2 = nn.Linear(6, 3)

    def forward(self, x):
        x = F.relu(self.fn1(x))
        x = self.fn2(x)
        return x


model = IrisNN().to(device)
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)

max_epochs = 200
for epoch in range(max_epochs):
    model.train()
    optimizer.zero_grad()
    score = model(x_train_t)
    loss = loss_fn(score, y_train_t)
    loss.backward()
    optimizer.step()

model.eval()
with torch.no_grad():
    score = model(x_test_t)
    predictions = score.argmax(dim=1)
    num_correct = (predictions == y_test_t).sum().item()

accuracy = num_correct / len(y_test_t)
print(f"ACCURACY={accuracy:.6f}")

# Optimization Summary
# Removed Dataset/DataLoader overhead: data is small enough to process as single tensors, eliminating per-epoch iterator overhead.
# Moved tensors to device once before training instead of per-batch per-epoch transfers, reducing data movement.
# Eliminated redundant per-epoch evaluation; only evaluate once after training since only final accuracy is needed.
# Removed the inline rescale function; normalization is done directly in-place.
# Removed test forward pass during training loop, cutting inference computation in half per epoch.
# Removed all prints, plots, and artifact saves per requirements.
# Used argmax instead of max with keepdim for simpler prediction extraction.