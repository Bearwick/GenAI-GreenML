# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import random
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F


SEED = 4096


def set_reproducible(seed: int) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    torch.use_deterministic_algorithms(True, warn_only=True)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True


def robust_read_csv(file_path: str, dataset_headers=None) -> pd.DataFrame:
    df = pd.read_csv(file_path, header=None)
    if dataset_headers is not None and len(df.columns) == len(dataset_headers):
        df.columns = list(dataset_headers)
        return df

    if df.shape[1] == 1:
        df2 = pd.read_csv(file_path, header=None, sep=";", decimal=",")
        if df2.shape[1] > 1:
            df = df2
            if dataset_headers is not None and len(df.columns) == len(dataset_headers):
                df.columns = list(dataset_headers)
                return df

    if dataset_headers is not None and len(df.columns) == len(dataset_headers):
        df.columns = list(dataset_headers)
        return df

    return df


def infer_iris_schema(df: pd.DataFrame, dataset_headers=None):
    if dataset_headers is None:
        dataset_headers = []

    if dataset_headers and len(df.columns) == len(dataset_headers):
        cols = list(dataset_headers)
        feature_cols = cols[:4]
        label_col = cols[-1]
        return feature_cols, label_col

    cols = list(df.columns)
    label_col = cols[-1]
    feature_cols = cols[:4]
    return feature_cols, label_col


def to_numpy_xy(df: pd.DataFrame, feature_cols, label_col):
    labels = df[label_col].astype("category").cat.codes.to_numpy(dtype=np.int64, copy=False)
    features = df[feature_cols].to_numpy(dtype=np.float32, copy=True)
    return features, labels


def rescale_inplace(x: np.ndarray) -> np.ndarray:
    mu = x.mean(axis=0, dtype=np.float32)
    x_max = x.max(axis=0)
    x_min = x.min(axis=0)
    span = x_max - x_min
    span = np.where(span == 0.0, 1.0, span).astype(np.float32, copy=False)
    x -= mu
    x /= span
    return x


class IrisNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fn1 = nn.Linear(4, 6)
        self.fn2 = nn.Linear(6, 3)

    def forward(self, x):
        x = F.relu(self.fn1(x))
        x = self.fn2(x)
        return x


def accuracy_last_batch(model, x: torch.Tensor, y: torch.Tensor) -> float:
    logits = model(x)
    preds = logits.argmax(dim=1)
    correct = (preds == y).sum().item()
    return correct / y.numel()


def main():
    set_reproducible(SEED)

    file_path = "iris.data"
    dataset_headers = ["SLength", "SWidth", "PLength", "PWidth", "class"]

    df = robust_read_csv(file_path, dataset_headers=dataset_headers)
    feature_cols, label_col = infer_iris_schema(df, dataset_headers=dataset_headers)

    n = len(df)
    shuffled_indices = np.random.permutation(n)
    df = df.take(shuffled_indices, axis=0)

    x_np, y_np = to_numpy_xy(df, feature_cols, label_col)
    rescale_inplace(x_np)

    num_train = int(n * 0.6)
    x_train = x_np[:num_train]
    y_train = y_np[:num_train]
    x_test = x_np[num_train:]
    y_test = y_np[num_train:]

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    x_train_t = torch.from_numpy(x_train).to(device=device, non_blocking=True)
    y_train_t = torch.from_numpy(y_train).to(device=device, non_blocking=True)
    x_test_t = torch.from_numpy(x_test).to(device=device, non_blocking=True)
    y_test_t = torch.from_numpy(y_test).to(device=device, non_blocking=True)

    model = IrisNN().to(device)
    loss_fn = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)

    max_epochs = 200
    for _ in range(max_epochs):
        model.train()
        optimizer.zero_grad(set_to_none=True)
        logits = model(x_train_t)
        loss = loss_fn(logits, y_train_t)
        loss.backward()
        optimizer.step()

        model.eval()
        with torch.no_grad():
            _ = loss_fn(model(x_test_t), y_test_t)

    model.eval()
    with torch.no_grad():
        accuracy = accuracy_last_batch(model, x_test_t, y_test_t)

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Replaced DataLoader/Dataset iteration with single full-batch tensors to eliminate Python-level batching overhead (original batch_size exceeded dataset size, so behavior is equivalent).
# - Avoided redundant data movement by transferring train/test tensors to the target device once (instead of per-iteration .to(device)).
# - Simplified training/evaluation loops: kept the same optimizer/loss/epochs while removing per-batch bookkeeping that previously only reflected the last batch.
# - Performed feature normalization in-place to reduce intermediate allocations and memory footprint.
# - Added robust CSV parsing fallback (default read_csv, then retry with sep=';' and decimal=',') to improve input reliability without extra dependencies.
# - Enforced reproducibility via fixed seeds and deterministic algorithm settings where feasible.