# Generated by generate_llm_code_2.py
# LLM: groq
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Load data
df = pd.read_csv("data.csv")
df.fillna(0, inplace=True)

# Encode target
labelencoder_Y = LabelEncoder()
df["diagnosis"] = labelencoder_Y.fit_transform(df["diagnosis"])

# Features and target
X = df.iloc[:, 2:32].values.astype(np.float32)  # 30 features
Y = df["diagnosis"].values

# Train/test split
X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.2, random_state=2
)

# Logistic regression using efficient implementation
model = LogisticRegression(
    solver="liblinear",
    max_iter=200,
    random_state=2,
    verbose=0,
)
model.fit(X_train, Y_train)

# Predictions
train_preds = model.predict(X_train)
test_preds = model.predict(X_test)

# Accuracy
train_acc = np.mean(train_preds == Y_train)
test_acc = np.mean(test_preds == Y_test)

print(f"Training accuracy: {train_acc:.4f}")
print(f"Testing accuracy:  {test_acc:.4f}")

# Final accuracy print
print(f"ACCURACY={test_acc:.6f}")

# Example prediction
example = np.array(
    [
        17.14, 16.4, 116, 912.7, 0.1186, 0.2276, 0.2229, 0.1401, 0.304,
        0.07413, 1.046, 0.976, 7.276, 111.4, 0.008029, 0.03799, 0.03732,
        0.02397, 0.02308, 0.007444, 22.25, 21.4, 152.4, 1461, 0.1545,
        0.3949, 0.3853, 0.255, 0.4066, 0.1059,
    ]
).reshape(1, -1).astype(np.float32)
pred = model.predict(example)
print("Prediction:", "Malignant" if pred[0] == 1 else "Benign")