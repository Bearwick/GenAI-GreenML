# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

from sklearn.model_selection import train_test_split
from sklearn.ensemble import ExtraTreesClassifier
import pandas as pd
import numpy as np
import random

DATASET_PATH = "data/wine_dataset.csv"
DATASET_HEADERS = [
    "fixed_acidity",
    "volatile_acidity",
    "citric_acid",
    "residual_sugar",
    "chlorides",
    "free_sulfur_dioxide",
    "total_sulfur_dioxide",
    "density",
    "pH",
    "sulphates",
    "alcohol",
    "quality",
    "style",
]
SEED = 42


def _parsed_correctly(df, headers):
    if df.shape[1] <= 1:
        return False
    cols = {c.strip().lower() for c in df.columns}
    return "style" in cols


def _load_dataset(path, headers):
    df = pd.read_csv(path)
    if not _parsed_correctly(df, headers):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _normalize_columns(df, headers):
    header_map = {h.lower(): h for h in headers}
    rename_map = {}
    for col in df.columns:
        key = col.strip().lower()
        if key in header_map and col != header_map[key]:
            rename_map[col] = header_map[key]
    if rename_map:
        df = df.rename(columns=rename_map)
    return df


def _prepare_features(df, headers):
    df = _normalize_columns(df, headers)
    header_map = {h.lower(): h for h in headers}
    style_col = header_map.get("style", "style")
    if style_col not in df.columns:
        candidates = [c for c in df.columns if c.strip().lower() == "style"]
        if candidates:
            style_col = candidates[0]
        else:
            raise ValueError("Style column not found in dataset.")
    style_series = df[style_col].astype(str).str.strip().str.lower()
    mask_style = style_series.isin(["red", "white"])
    df = df.loc[mask_style].copy()
    df[style_col] = style_series.loc[mask_style].map({"red": 0, "white": 1}).astype("int64")
    X = df.drop(columns=[style_col])
    y = df[style_col]
    for col in X.columns:
        X[col] = pd.to_numeric(X[col], errors="coerce")
    mask_numeric = X.notna().all(axis=1)
    X = X.loc[mask_numeric]
    y = y.loc[mask_numeric]
    return X, y


def main():
    np.random.seed(SEED)
    random.seed(SEED)
    df = _load_dataset(DATASET_PATH, DATASET_HEADERS)
    X, y = _prepare_features(df, DATASET_HEADERS)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=SEED, stratify=y
    )
    model = ExtraTreesClassifier(n_estimators=100, random_state=SEED)
    model.fit(X_train, y_train)
    accuracy = model.score(X_test, y_test)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# Used a parsing validation check with a delimiter fallback to avoid unnecessary downstream corrections.
# Normalized column names once using a header map to prevent repeated string operations.
# Combined label cleaning, filtering, and mapping into a single vectorized flow to reduce redundant passes.
# Performed in-place numeric conversion per column to limit full DataFrame copies.
# Removed unused prediction computation and extraneous logging to reduce runtime and overhead.