# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import ExtraTreesClassifier
import numpy as np

RANDOM_STATE = 42
EXPECTED_HEADERS = [
    "fixed_acidity",
    "volatile_acidity",
    "citric_acid",
    "residual_sugar",
    "chlorides",
    "free_sulfur_dioxide",
    "total_sulfur_dioxide",
    "density",
    "pH",
    "sulphates",
    "alcohol",
    "quality",
    "style",
]


def parsing_looks_wrong(df, expected_headers):
    if df.shape[0] == 0 or df.shape[1] == 1:
        return True
    expected_lower = {h.lower() for h in expected_headers}
    cols_lower = {str(c).strip().lower() for c in df.columns}
    return len(cols_lower & expected_lower) == 0


def read_csv_with_fallback(path, expected_headers):
    df = pd.read_csv(path)
    if parsing_looks_wrong(df, expected_headers):
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def standardize_columns(df, expected_headers):
    expected_map = {h.lower(): h for h in expected_headers}
    rename_map = {}
    for col in df.columns:
        key = str(col).strip().lower()
        if key in expected_map:
            rename_map[col] = expected_map[key]
    return df.rename(columns=rename_map) if rename_map else df


def main():
    np.random.seed(RANDOM_STATE)
    path = "data/wine_dataset.csv"
    df = read_csv_with_fallback(path, EXPECTED_HEADERS)
    df = standardize_columns(df, EXPECTED_HEADERS)

    style_col = None
    for col in df.columns:
        if str(col).strip().lower() == "style":
            style_col = col
            break
    if style_col is None:
        raise ValueError("Style column not found")

    style = df[style_col].astype(str).str.strip().str.lower()
    mask_style = style.isin(["red", "white"])
    y = style.loc[mask_style].map({"red": 0, "white": 1}).astype("int64")

    feature_cols = [c for c in df.columns if c != style_col]
    X = df.loc[mask_style, feature_cols]
    X = X.apply(pd.to_numeric, errors="coerce")

    mask = X.notna().all(axis=1)
    X = X.loc[mask]
    y = y.loc[mask]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y
    )

    model = ExtraTreesClassifier(n_estimators=100, random_state=RANDOM_STATE)
    model.fit(X_train, y_train)
    accuracy = model.score(X_test, y_test)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Added robust CSV parsing fallback to prevent costly downstream errors.
# - Standardized column names once to avoid repeated string operations.
# - Filtered and mapped labels without copying the full DataFrame.
# - Removed unnecessary prediction step to cut extra computation.
# - Centralized fixed random seed for reproducible and deterministic behavior.