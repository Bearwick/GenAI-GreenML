# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import numpy as np
import pandas as pd
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split

SEED = 42
DATASET_PATH = "data/wine_dataset.csv"
EXPECTED_HEADERS = [
    "fixed_acidity",
    "volatile_acidity",
    "citric_acid",
    "residual_sugar",
    "chlorides",
    "free_sulfur_dioxide",
    "total_sulfur_dioxide",
    "density",
    "pH",
    "sulphates",
    "alcohol",
    "quality",
    "style",
]


def _read_csv_robust(path: str, expected_headers: list[str]) -> pd.DataFrame:
    def looks_wrong(df: pd.DataFrame) -> bool:
        if df is None or df.empty:
            return True
        cols = [c.strip() for c in df.columns.astype(str)]
        if len(cols) == 1:
            return True
        expected = set(expected_headers)
        present = sum(1 for c in cols if c in expected)
        return present < max(1, len(expected_headers) // 2)

    df = pd.read_csv(path)
    if looks_wrong(df):
        df = pd.read_csv(path, sep=";", decimal=",")
    df.columns = df.columns.astype(str).str.strip()
    return df


def main() -> None:
    np.random.seed(SEED)

    df = _read_csv_robust(DATASET_PATH, EXPECTED_HEADERS)

    if "style" not in df.columns:
        raise KeyError("Required target column 'style' not found in dataset.")

    style = df["style"].astype("string").str.strip().str.lower()
    is_valid_style = style.isin(("red", "white"))

    feature_cols = [c for c in df.columns if c != "style"]
    X = df.loc[is_valid_style, feature_cols].apply(pd.to_numeric, errors="coerce")
    y = style.loc[is_valid_style].map({"red": 0, "white": 1}).astype("int64")

    valid_rows = X.notna().all(axis=1)
    X = X.loc[valid_rows]
    y = y.loc[valid_rows]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=SEED, stratify=y
    )

    model = ExtraTreesClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)
    model.fit(X_train, y_train)

    accuracy = model.score(X_test, y_test)
    _ = model.predict(X_test.iloc[300:600])

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Implemented robust CSV parsing with a fallback delimiter/decimal configuration to avoid repeated manual fixes and reruns.
# - Reduced data movement by computing the cleaned 'style' series once and using boolean masks to filter both X and y without extra DataFrame copies.
# - Avoided .copy() and redundant intermediate DataFrames, lowering memory footprint while preserving semantics.
# - Used vectorized pandas operations and a single NaN-validity mask to drop invalid rows efficiently.
# - Enabled parallel tree building via n_jobs=-1 to reduce wall-clock runtime without changing model behavior or outputs.
# - Ensured reproducibility by fixing the random seed for NumPy and scikit-learn components.