# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import ExtraTreesClassifier

def main():
    path = "data/wine_dataset.csv"
    try:
        df = pd.read_csv(path)
        if len(df.columns) < 2:
            raise ValueError
    except Exception:
        df = pd.read_csv(path, sep=';', decimal=',')

    target_col = next((c for c in df.columns if c.lower() == 'style'), 'style')
    
    df[target_col] = df[target_col].astype(str).str.strip().str.lower()
    df = df[df[target_col].isin(['red', 'white'])]
    mapping = {'red': 0, 'white': 1}
    df[target_col] = df[target_col].map(mapping).astype('int8')

    features = [c for c in df.columns if c != target_col]
    X = df[features].apply(pd.to_numeric, errors='coerce')
    
    valid_mask = X.notna().all(axis=1)
    X = X[valid_mask].astype('float32')
    y = df.loc[valid_mask, target_col]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    model = ExtraTreesClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    accuracy = model.score(X_test, y_test)
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# 1. Memory Reduction: Downcasted numeric features from float64 to float32 and target labels to int8.
# 2. Computational Efficiency: Removed redundant prediction slice and multiple print calls to minimize I/O and CPU overhead.
# 3. Streamlined Preprocessing: Optimized data filtering and mapping using vectorized pandas operations and avoided unnecessary DataFrame copies.
# 4. Robust Data Loading: Implemented a fallback mechanism for CSV parsing (handling different separators and decimals) to prevent execution failure.
# 5. Resource Management: Removed redundant numeric coercion masks and consolidated indexing to reduce memory fragmentation.
# 6. Green Coding: Minimized runtime by eliminating intermediate data structures and keeping the model configuration focused on required metrics only.