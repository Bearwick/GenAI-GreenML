# Generated by generate_llm_code.py
# LLM: gemini
# Mode: original_telemetry

from sklearn.model_selection import train_test_split
from sklearn.ensemble import ExtraTreesClassifier
import pandas as pd

path = "data/wine_dataset.csv"
df = pd.read_csv(path)

df["style"] = df["style"].astype(str).str.strip().str.lower()
df = df[df["style"].isin(["red", "white"])].copy()
df["style"] = df["style"].map({"red": 0, "white": 1}).astype("int64")

X = df.drop(columns=["style"])
y = df["style"]

X = X.apply(pd.to_numeric, errors="coerce")
mask = X.notna().all(axis=1)
X = X[mask]
y = y[mask]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

model = ExtraTreesClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

accuracy = model.score(X_test, y_test)
print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Refactored variable names to standard English conventions (e.g., df instead of arquivo, X_train instead of X_treino).
# 2. Removed original comments and redundant print statements to produce a clean baseline.
# 3. Removed specific slice predictions as they were intended for interactive inspection and do not affect model performance.
# 4. Standardized the final accuracy output to the requested format.
# 5. Maintained the original ML pipeline including data cleaning, numeric coercion, and stratified splitting.