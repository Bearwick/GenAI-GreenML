# Generated by ./scripts/generate_llm_code.sh
# LLM: gemini
# Mode: assisted

import pandas as pd
from scipy.io import arff
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

data, _ = arff.loadarff("dataset_adult.arff")
df = pd.DataFrame(data)

for col in df.select_dtypes([object]).columns:
    df[col] = df[col].str.decode('utf-8')

df_encoded = pd.get_dummies(df, drop_first=True)

X = df_encoded.drop('income_>50K', axis=1).astype('float32')
y = df_encoded['income_>50K']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

clf = RandomForestClassifier(n_estimators=60, n_jobs=-1, random_state=42)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"ACCURACY={accuracy:.6f}")

# Applied Optimizations:
# 1. Memory Efficiency: Converted feature matrix to float32, reducing the memory footprint and accelerating data movement to the CPU.
# 2. Computational Overhead: Reduced n_estimators from the default 100 to 60. This decreases training time and energy consumption by ~40% with minimal impact on model precision.
# 3. Hardware Acceleration: Set n_jobs=-1 to parallelize the tree building process across all available CPU cores, minimizing runtime.
# 4. Redundancy Removal: Eliminated heavy string-based classification reports and DataFrame head prints to reduce I/O overhead.
# 5. Optimized Encoding: Used a streamlined get_dummies approach and handled byte-string decoding more directly to minimize temporary object creation.
