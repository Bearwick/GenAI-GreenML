# Generated by generate_llm_code.py
# LLM: gemini
# Mode: autonomous

import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load a representative small-scale tabular dataset
data = load_breast_cancer()
X, y = data.data, data.target

# Split data with a fixed seed for reproducibility
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Standardize features using a linear transformation (low CPU overhead)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Use Logistic Regression: computationally efficient, O(n) inference, low memory footprint
model = LogisticRegression(
    penalty='l2',
    C=1.0,
    solver='lbfgs',
    max_iter=1000,
    random_state=42
)

# Train using a deterministic optimization algorithm
model.fit(X_train_scaled, y_train)

# Evaluate model performance
y_pred = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Model Selection: Logistic Regression was chosen over Deep Learning or Ensembles 
#    to minimize FLOPS during both training and inference.
# 2. Computational Efficiency: The L-BFGS solver is memory-efficient and converges 
#    quickly on small-to-medium datasets without requiring GPU acceleration.
# 3. Preprocessing: StandardScaler is a lightweight operation (z-score normalization) 
#    that improves convergence speed, reducing the number of CPU cycles needed.
# 4. Energy Impact: By avoiding iterative boosting or large-scale matrix multiplications 
#    found in Transformers/CNNs, the carbon footprint of this script is negligible.
# 5. Resource Management: The pipeline relies on NumPy and Scikit-Learn's optimized 
#    C-extensions, ensuring high throughput on standard CPU architectures.