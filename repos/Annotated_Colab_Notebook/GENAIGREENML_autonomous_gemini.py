# Generated by ./scripts/generate_llm_code.sh
# LLM: gemini
# Mode: autonomous

from scipy.io import arff
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import accuracy_score

raw_data, _ = arff.loadarff("dataset_adult.arff")
df = pd.DataFrame(raw_data)

for col in df.columns:
    if df[col].dtype == object:
        df[col] = df[col].str.decode('utf-8')

df = df.replace('?', np.nan)

X = df.iloc[:, :-1].copy()
y = df.iloc[:, -1].apply(lambda x: 1 if '>50K' in str(x) else 0)

categorical_mask = (X.dtypes == object)
categorical_cols = X.columns[categorical_mask].tolist()

encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
X.loc[:, categorical_cols] = encoder.fit_transform(X[categorical_cols])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = HistGradientBoostingClassifier(
    max_iter=100, 
    early_stopping=True, 
    random_state=42
)
model.fit(X_train, y_train)

accuracy = accuracy_score(y_test, model.predict(X_test))
print(f"ACCURACY={accuracy:.6f}")

"""
JUSTIFICATION FOR ENERGY-EFFICIENT DESIGN:
1. Model Choice: HistGradientBoostingClassifier is used instead of RandomForest. It utilizes histogram-based binning, which reduces the complexity of finding splits from O(n_samples) to O(n_bins). This significantly lowers the number of CPU cycles and energy required for training on tabular data.
2. Preprocessing: OrdinalEncoder is used to transform categorical variables. Unlike One-Hot Encoding, it prevents feature explosion, maintaining a low memory footprint and reducing the computational load on the processor during training and inference.
3. Data Handling: The implementation leverages native NaN handling within the HistGradientBoosting algorithm. This avoids the energy cost of running separate imputation algorithms (like IterativeImputer) which require multiple passes over the data.
4. Hardware Optimization: The solution is designed for CPU execution using Scikit-Learn's optimized C++/Cython backends, avoiding the high power draw associated with initializing and running GPU-intensive deep learning frameworks for a simple classification task.
5. Efficiency: Early stopping is enabled to halt training once the model converges, preventing unnecessary calculations and further reducing energy consumption.
"""
