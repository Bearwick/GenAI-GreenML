# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

from scipy.io import arff
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

def run_efficient_pipeline(file_path="dataset_adult.arff"):
    data, _ = arff.loadarff(file_path)
    df = pd.DataFrame(data)

    for col in df.select_dtypes([object]).columns:
        df[col] = df[col].str.decode('utf-8').astype('category')

    df_encoded = pd.get_dummies(df, drop_first=True, dtype='int8')

    X = df_encoded.drop('income_>50K', axis=1)
    y = df_encoded['income_>50K']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)
    clf.fit(X_train, y_train)

    accuracy = accuracy_score(y_test, clf.predict(X_test))
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_efficient_pipeline()

# Applied Optimizations:
# 1. Memory Reduction: Converted object types to 'category' dtypes to optimize data storage and processing speed.
# 2. Storage Efficiency: Used 'int8' for the one-hot encoded variables to minimize the memory footprint compared to default 64-bit types.
# 3. Parallel Processing: Set 'n_jobs=-1' in RandomForestClassifier to use all available CPU cores, reducing execution time and idle energy waste.
# 4. Minimized Overhead: Removed all unnecessary print statements, interactive inputs, and visualizations to reduce CPU and I/O cycles.
# 5. Redundancy Elimination: Streamlined the preprocessing workflow to avoid multiple deep copies of the dataset.