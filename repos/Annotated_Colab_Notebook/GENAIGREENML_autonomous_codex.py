# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier
from sklearn.metrics import accuracy_score

csv_files = [f for f in os.listdir('.') if f.lower().endswith('.csv')]
train_files = [f for f in csv_files if f.lower() == 'train.csv']
if train_files:
    data_file = train_files[0]
elif csv_files:
    data_file = sorted(csv_files)[0]
else:
    raise FileNotFoundError("No CSV data file found.")

df = pd.read_csv(data_file)

target_candidates = [c for c in df.columns if c.lower() in ['target', 'label', 'class', 'y']]
target_col = target_candidates[0] if target_candidates else df.columns[-1]

X = df.drop(columns=[target_col])
y = df[target_col]

le = LabelEncoder()
y_encoded = le.fit_transform(y)

cat_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
num_cols = [c for c in X.columns if c not in cat_cols]

numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

transformers = []
if num_cols:
    transformers.append(('num', numeric_transformer, num_cols))
if cat_cols:
    transformers.append(('cat', categorical_transformer, cat_cols))
preprocess = ColumnTransformer(transformers=transformers, remainder='drop') if transformers else 'passthrough'

n_classes = len(np.unique(y_encoded))
if n_classes < 2:
    model = DummyClassifier(strategy='most_frequent')
else:
    solver = 'liblinear' if n_classes == 2 else 'lbfgs'
    model = LogisticRegression(max_iter=200, n_jobs=1, solver=solver)

clf = Pipeline(steps=[('preprocess', preprocess), ('model', model)])

n_samples = len(df)
test_size = max(1, int(round(0.2 * n_samples)))
if test_size >= n_samples:
    test_size = n_samples - 1
if test_size <= 0:
    test_size = 1

stratify = y_encoded if n_classes > 1 else None

try:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=test_size, random_state=42, stratify=stratify
    )
except ValueError:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=test_size, random_state=42, stratify=None
    )

clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# - Selected lightweight linear models to minimize computation and energy use.
# - Applied a compact preprocessing pipeline with imputation and simple encoding.
# - Limited iterations and avoided parallelism to reduce CPU overhead.
# - Used automatic target detection for a reproducible, minimal setup.