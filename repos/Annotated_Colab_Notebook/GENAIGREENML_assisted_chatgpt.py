# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

from scipy.io import arff
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


def load_arff_to_dataframe(file_path: str) -> pd.DataFrame:
    data, _ = arff.loadarff(file_path)
    df = pd.DataFrame(data)

    obj_cols = df.select_dtypes(include=["object"]).columns
    if len(obj_cols) > 0:
        df[obj_cols] = df[obj_cols].apply(lambda s: s.str.decode("utf-8"))

    return df


def preprocess(df: pd.DataFrame):
    df_encoded = pd.get_dummies(df, drop_first=True)
    y = df_encoded["income_>50K"]
    X = df_encoded.drop(columns=["income_>50K"])
    return X, y


def train_and_evaluate(X, y, random_state: int = 42):
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.3,
        random_state=random_state,
    )

    clf = RandomForestClassifier(
        random_state=random_state,
        n_estimators=100,
        n_jobs=-1,
    )
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    return accuracy


def main():
    file_path = "dataset_adult.arff"
    df = load_arff_to_dataframe(file_path)
    X, y = preprocess(df)
    accuracy = train_and_evaluate(X, y, random_state=42)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# OPTIMIZATION SUMMARY
# - Removed dataset previews, reports, and all non-required prints to reduce I/O overhead and runtime noise.
# - Decoded only object dtype columns and applied decoding in a vectorized column-wise manner to avoid per-cell loops.
# - Used drop(columns=[...]) instead of axis-based drop for slightly lower overhead and clearer intent.
# - Enabled RandomForest parallelism with n_jobs=-1 to reduce wall-clock time while preserving model behavior.
# - Encapsulated steps into small functions to avoid accidental repeated work and improve maintainability/reproducibility.