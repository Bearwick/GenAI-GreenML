# Generated by generate_llm_code_2.py
# LLM: gemini
# Mode: assisted

import numpy as np
import pandas as pd

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def initialize(dim):
    w = np.zeros((dim, 1))
    b = 0.0
    return w, b

def optimize(w, b, X, Y, num_iters, alpha, print_cost=False):
    m = X.shape[1]
    costs = []
    
    for i in range(num_iters):
        z = np.dot(w.T, X) + b
        A = 1 / (1 + np.exp(-z))
        
        dz = A - Y
        dw = (1 / m) * np.dot(X, dz.T)
        db = (1 / m) * np.sum(dz)
        
        w -= alpha * dw
        b -= alpha * db

        if i % 100 == 0:
            cost = (-1 / m) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))
            costs.append(cost)
            if print_cost:
                print(f"Cost after iteration {i}: {cost:f}")

    return w, b, costs

def predict(w, b, X):
    A = sigmoid(np.dot(w.T, X) + b)
    return (A > 0.5).astype(float)

def calculate_metrics(Y_true, Y_pred, set_name):
    accuracy = 100 - np.mean(np.abs(Y_pred - Y_true)) * 100
    
    tp = np.sum((Y_pred == 1) & (Y_true == 1))
    tn = np.sum((Y_pred == 0) & (Y_true == 0))
    fp = np.sum((Y_pred == 1) & (Y_true == 0))
    fn = np.sum((Y_pred == 0) & (Y_true == 1))
    
    tpr = (tp / (tp + fn) * 100) if (tp + fn) > 0 else 0
    precision = (tp / (tp + fp) * 100) if (tp + fp) > 0 else 0
    fpr = (fp / (fp + tn) * 100) if (fp + tn) > 0 else 0
    
    print(f"\n{set_name} accuracy: {accuracy} %")
    print(f"On {set_name} set:\nTrue Positive:  {tp}")
    print(f"True Negative:  {tn}")
    print(f"False Negative:  {fn}")
    print(f"False Positive:  {fp}")
    print(f"True Positive Rate / Recall: {tpr:.2f}%")
    print(f"Precision: {precision:.2f}%")
    print(f"False Positive Rate / Fallout: {fpr:.2f}%")
    
    return accuracy / 100

def run_model():
    train_x = pd.read_csv("cancer_data.csv").values.T
    train_y = pd.read_csv("cancer_data_y.csv").values.T
    
    num_iters = 190500
    alpha = 0.000000065
    
    w, b = initialize(train_x.shape[0])
    w, b, costs = optimize(w, b, train_x, train_y, num_iters, alpha, print_cost=True)
    
    test_x = pd.read_csv("test_cancer_data.csv").values.T
    test_y = pd.read_csv("test_cancer_data_y.csv").values.T
    
    y_pred_train = predict(w, b, train_x)
    y_pred_test = predict(w, b, test_x)
    
    calculate_metrics(train_y, y_pred_train, "training")
    test_acc = calculate_metrics(test_y, y_pred_test, "Test")
    
    print(f"ACCURACY={test_acc:.6f}")

if __name__ == "__main__":
    run_model()

"""
OPTIMIZATIONS APPLIED:
1. Vectorized thresholding and confusion matrix calculations using NumPy, replacing slow Python loops and list conversions.
2. Inlined the propagation logic within the optimization loop to eliminate 190,500 function call overheads.
3. Implemented lazy evaluation for the cost function, calculating it only every 100 iterations for logging rather than every step.
4. Minimized data movement by reading CSVs directly into NumPy arrays and transposing in place.
5. Removed redundant dictionary packaging and unpacking of gradients and parameters during training.
6. Replaced repeated attribute access and array slicing with local variables to reduce overhead in the tight training loop.
"""