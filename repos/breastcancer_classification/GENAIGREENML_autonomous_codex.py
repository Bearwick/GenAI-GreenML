# Generated by generate_llm_code.py
# LLM: codex
# Mode: autonomous

import os
import pandas as pd
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def read_csv_any():
    csv_files = [f for f in os.listdir('.') if f.lower().endswith('.csv')]
    if not csv_files:
        return None
    best_df = None
    best_rows = 0
    for f in csv_files:
        try:
            df = pd.read_csv(f, header=None)
        except Exception:
            continue
        if df.shape[1] < 2 or df.shape[0] < 5:
            continue
        if df.shape[0] > best_rows:
            best_rows = df.shape[0]
            best_df = df
    return best_df

def detect_header(df):
    if df is None or df.empty:
        return df
    row0 = df.iloc[0]
    numeric_ratio = pd.to_numeric(row0, errors='coerce').notna().mean()
    if numeric_ratio < 0.5:
        df = df.copy()
        df.columns = row0
        df = df.drop(df.index[0]).reset_index(drop=True)
    return df

def select_target(df):
    if df is None or df.empty:
        return None, None
    target_col = None
    for col in df.columns:
        if str(col).lower() in ['target', 'label', 'class', 'diagnosis', 'y']:
            target_col = col
            break
    if target_col is None:
        unique_counts = df.nunique(dropna=True)
        candidates = unique_counts[unique_counts <= 10]
        if not candidates.empty:
            target_col = candidates.idxmin()
        else:
            last_col = df.columns[-1]
            if unique_counts[last_col] <= max(2, int(0.2 * len(df))):
                target_col = last_col
    if target_col is None:
        return None, None
    y = df[target_col]
    X = df.drop(columns=[target_col])
    return X, y

def load_dataset():
    df = read_csv_any()
    if df is None:
        data = load_breast_cancer()
        return pd.DataFrame(data.data, columns=data.feature_names), pd.Series(data.target)
    df = detect_header(df)
    X, y = select_target(df)
    if X is None:
        data = load_breast_cancer()
        return pd.DataFrame(data.data, columns=data.feature_names), pd.Series(data.target)
    return X, y

X, y = load_dataset()
X = pd.DataFrame(X).copy()
y = pd.Series(y).copy()

drop_cols = [col for col in X.columns if 'id' in str(col).lower()]
if drop_cols:
    X = X.drop(columns=drop_cols)

X = X.apply(pd.to_numeric, errors='coerce')
X = X.dropna(axis=1, how='all')

for col in list(X.columns):
    col_series = X[col]
    if col_series.nunique(dropna=True) == len(col_series):
        if col_series.is_monotonic_increasing or col_series.is_monotonic_decreasing:
            X = X.drop(columns=[col])

if X.shape[1] == 0:
    data = load_breast_cancer()
    X = pd.DataFrame(data.data, columns=data.feature_names)
    y = pd.Series(data.target)

y_numeric = pd.to_numeric(y, errors='coerce')
if y_numeric.isna().any():
    le = LabelEncoder()
    y = pd.Series(le.fit_transform(y.astype(str)))
else:
    y = y_numeric

mask = y.notna()
X = X.loc[mask].reset_index(drop=True)
y = y.loc[mask].reset_index(drop=True)

non_empty = ~X.isna().all(axis=1)
X = X.loc[non_empty].reset_index(drop=True)
y = y.loc[non_empty].reset_index(drop=True)

if len(np.unique(y)) < 2 or len(X) < 2:
    accuracy = 0.0
    print(f"ACCURACY={accuracy:.6f}")
else:
    test_ratio = 0.2 if len(X) >= 5 else 0.5
    test_size = int(np.ceil(test_ratio * len(X)))
    if test_size < 1:
        test_size = 1
    if len(X) - test_size < 1:
        test_size = max(1, len(X) // 2)
    unique, counts = np.unique(y, return_counts=True)
    stratify = y if len(unique) > 1 and np.all(counts >= 2) else None
    if stratify is not None and test_size < len(unique):
        stratify = None
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=stratify
    )
    model = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler()),
        ('clf', LogisticRegression(max_iter=500, solver='liblinear'))
    ])
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# Used logistic regression with scaling and median imputation for efficient CPU-friendly training.
# Implemented lightweight dataset loading with simple target detection and fallback to a built-in dataset.
# Avoided heavy models and extensive preprocessing to minimize computation and energy usage.