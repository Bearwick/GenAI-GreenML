# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# --- Robust CSV Loading ---
DATASET_PATH = "cancer_data.csv"

try:
    df = pd.read_csv(DATASET_PATH)
except Exception:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')

# Check if parsing looks wrong (e.g., single column with many values)
if df.shape[1] < 3:
    try:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')
    except Exception:
        pass

# --- Column Name Normalization ---
df.columns = df.columns.str.strip().str.replace(r'\s+', ' ', regex=True)
df = df.loc[:, ~df.columns.str.startswith('Unnamed')]

# --- Detect if header row is actually data ---
# The DATASET_HEADERS suggest the first row might be numeric data (no column names)
# Check if all column names look like floats
all_numeric_headers = True
for col in df.columns:
    try:
        float(col)
    except (ValueError, TypeError):
        all_numeric_headers = False
        break

if all_numeric_headers:
    # Re-read without header; first row is data
    try:
        df = pd.read_csv(DATASET_PATH, header=None)
    except Exception:
        df = pd.read_csv(DATASET_PATH, header=None, sep=';', decimal=',')
    if df.shape[1] < 3:
        try:
            df = pd.read_csv(DATASET_PATH, header=None, sep=';', decimal=',')
        except Exception:
            pass

# --- Identify target and features ---
# Breast Cancer Wisconsin dataset from sklearn/UCI typically has 30 features + 1 target
# The context says: classification of malignant/benign
# The dataset may or may not have an ID column and a diagnosis column

# Try to find a diagnosis/target column
target_col = None
feature_cols = []

# Check if any column has string values like 'M'/'B' or limited unique integer values
for col in df.columns:
    series = df[col]
    if series.dtype == object:
        unique_vals = series.dropna().unique()
        if len(unique_vals) <= 5:
            target_col = col
            break

if target_col is None:
    # Look for a column with very few unique values (likely a label column)
    for col in df.columns:
        series = pd.to_numeric(df[col], errors='coerce')
        nunique = series.dropna().nunique()
        if nunique <= 5 and nunique >= 2:
            # Prefer columns that look like labels (small integers)
            vals = series.dropna().unique()
            if all(v == int(v) for v in vals if not np.isnan(v)):
                target_col = col
                break

if target_col is None:
    # Fallback: use the last column as target
    target_col = df.columns[-1]

# Build feature columns: all columns except target and any ID-like column
for col in df.columns:
    if col == target_col:
        continue
    series = pd.to_numeric(df[col], errors='coerce')
    # Skip columns that look like IDs (all unique integers, very high cardinality)
    if series.dropna().nunique() == len(series.dropna()) and len(series.dropna()) > 100:
        # Likely an ID column if it also has large values
        if series.dropna().mean() > 1e5:
            continue
    feature_cols.append(col)

# --- Prepare data ---
# Coerce features to numeric
X = df[list(feature_cols)].apply(pd.to_numeric, errors='coerce')
y