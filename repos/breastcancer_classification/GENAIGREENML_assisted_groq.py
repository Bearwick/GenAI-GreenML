# Generated by generate_llm_code.py
# LLM: groq
# Mode: assisted

import numpy as np
import pandas as pd
import joblib

def sigmoid(z: np.ndarray) -> np.ndarray:
    return 1.0 / (1.0 + np.exp(-z))

def initialize(dim: int):
    return np.zeros((dim, 1)), 0.0

def propagate(w: np.ndarray, b: float, X: np.ndarray, Y: np.ndarray):
    m = X.shape[1]
    A = sigmoid(np.dot(w.T, X) + b)
    cost = -np.mean(Y * np.log(A) + (1 - Y) * np.log(1 - A))
    dw = np.dot(X, (A - Y).T) / m
    db = np.sum(A - Y) / m
    return {"dw": dw, "db": db}, cost

def optimize(w: np.ndarray, b: float, X: np.ndarray, Y: np.ndarray,
             num_iters: int, alpha: float, print_cost: bool = False):
    costs = []
    for i in range(num_iters):
        grads, cost = propagate(w, b, X, Y)
        w -= alpha * grads["dw"]
        b -= alpha * grads["db"]
        if i % 100 == 0:
            costs.append(cost)
    return {"w": w, "b": b}, costs

def predict(w: np.ndarray, b: float, X: np.ndarray):
    A = sigmoid(np.dot(w.T, X) + b)
    return (A > 0.5).astype(int)

def compute_metrics(pred: np.ndarray, true: np.ndarray):
    tp = np.sum((pred == 1) & (true == 1))
    tn = np.sum((pred == 0) & (true == 0))
    fp = np.sum((pred == 1) & (true == 0))
    fn = np.sum((pred == 0) & (true == 1))
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0
    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    return accuracy, tpr, fpr, precision

def model(X_train: np.ndarray, Y_train: np.ndarray,
          X_test: np.ndarray, Y_test: np.ndarray,
          num_iters: int = 2000, alpha: float = 0.5):
    w, b = initialize(X_train.shape[0])
    params, costs = optimize(w, b, X_train, Y_train, num_iters, alpha)
    w, b = params["w"], params["b"]

    y_pred_train = predict(w, b, X_train)
    y_pred_test  = predict(w, b, X_test)

    train_acc, _, _, _ = compute_metrics(y_pred_train, Y_train)
    test_acc, tpr, fpr, precision = compute_metrics(y_pred_test, Y_test)

    print(f"ACCURACY={test_acc:.6f}")

    model_dict = {"w": w, "b": b, "alpha": alpha,
                  "num_iters": num_iters, "costs": costs}
    joblib.dump(model_dict, "logistic_model.pkl")
    return model_dict

def main():
    train_X = pd.read_csv("cancer_data.csv").to_numpy().T
    train_Y = pd.read_csv("cancer_data_y.csv").to_numpy().T
    test_X  = pd.read_csv("test_cancer_data.csv").to_numpy().T
    test_Y  = pd.read_csv("test_cancer_data_y.csv").to_numpy().T

    model(train_X, train_Y, test_X, test_Y,
          num_iters=190500, alpha=6.5e-8)

if __name__ == "__main__":
    main()

# Optimization notes:
# 1. Replaced loops with vectorized operations to cut CPU usage.
# 2. Removed unnecessary data copies and conversions; data used directly as numpy arrays.
# 3. Simplified predict to a single thresholding operation.
# 4. Calculated metrics using boolean masks for speed and memory efficiency.
# 5. Eliminated matplotlib plotting and interactive prints to avoid I/O overhead.
# 6. Stored model with joblib for lightweight persistence.
# 7. Combined training and testing into a single function call to reduce function overhead.