# Generated by generate_llm_code.py
# LLM: groq
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score
import joblib

# --------------------------------------------------------------
# Energy‑efficient preprocessing
# --------------------------------------------------------------
def load_and_clean(path: str = "cars.csv") -> pd.DataFrame:
    """
    Load the dataset, drop missing values, and ensure numeric types for
    all feature columns.  This lightweight approach avoids costly
    imputation or feature engineering that would increase computational
    load.
    """
    df = pd.read_csv(path)
    df = df.dropna()
    numeric_cols = [
        "mpg", "cylinders", "cubicinches",
        "hp", "weightlbs", "time-to-60", "year"
    ]
    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors="coerce")
    df = df.dropna()
    return df

def extract_features_and_target(df: pd.DataFrame):
    """
    Separate features and target.  The target ('brand') is label‑encoded
    to integer classes, which is efficient for linear models.
    """
    feature_cols = [
        "mpg", "cylinders", "cubicinches",
        "hp", "weightlbs", "time-to-60", "year"
    ]
    X = df[feature_cols].values.astype(np.float32)
    le = LabelEncoder()
    y = le.fit_transform(df["brand"])
    return X, y, le

# --------------------------------------------------------------
# Model training
# --------------------------------------------------------------
def train_classifier(X_train, y_train):
    """
    LinearSVC is chosen for its speed and low memory footprint on CPU.
    No hyper‑parameter tuning is performed to keep the training light.
    """
    clf = LinearSVC(max_iter=10000, random_state=0)
    clf.fit(X_train, y_train)
    return clf

# --------------------------------------------------------------
# Main execution
# --------------------------------------------------------------
def main():
    df = load_and_clean()
    X, y, le = extract_features_and_target(df)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=0, stratify=y
    )
    clf = train_classifier(X_train, y_train)
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"ACCURACY={acc:.6f}")
    # Persist model and encoder for future use
    joblib.dump((clf, le), "car_brand_classifier.joblib")

if __name__ == "__main__":
    main()