# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import pandas as pd
import numpy as np
import random
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix

DATASET_HEADERS = "mpg, cylinders, cubicinches, hp, weightlbs, time-to-60, year, brand"
EXPECTED_COLUMNS = [h.strip() for h in DATASET_HEADERS.split(",")]
FEATURE_COLS = EXPECTED_COLUMNS[:5]
LABEL_COL = EXPECTED_COLUMNS[7]
NUMERIC_COLS = [EXPECTED_COLUMNS[i] for i in (2, 4)]

def read_csv_robust(path, expected_cols):
    expected_set = set(expected_cols)
    def clean(frame):
        frame.columns = [str(c).strip() for c in frame.columns]
        return frame
    df = clean(pd.read_csv(path))
    if df.shape[1] == 1 or (df.shape[1] != len(expected_cols) and not expected_set.issubset(df.columns)):
        df = clean(pd.read_csv(path, sep=";", decimal=","))
    if df.shape[1] == len(expected_cols):
        df.columns = expected_cols
    elif expected_set.issubset(df.columns):
        df = df[expected_cols]
    return df

def prepare_dataset(df, numeric_cols):
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df.dropna()

def main():
    np.random.seed(0)
    random.seed(0)
    dataset = read_csv_robust("cars.csv", EXPECTED_COLUMNS)
    dataset = prepare_dataset(dataset, NUMERIC_COLS)
    X = dataset[FEATURE_COLS].to_numpy()
    y = dataset[LABEL_COL].to_numpy()
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=0
    )
    classifier = SVC()
    classifier.fit(X_train, y_train)
    y_pred = classifier.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    accuracy = float((y_pred == y_test).mean())
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# - Removed unused dataset inspection and visualization steps to cut unnecessary computation and imports.
# - Consolidated missing-value handling and numeric conversions into a single cleaning pass.
# - Eliminated duplicate predictions by reusing y_pred for both accuracy and confusion matrix.
# - Aligned columns once based on DATASET_HEADERS to avoid redundant reordering and data movement.
# - Added deterministic seeding and robust CSV fallback parsing for stable, reproducible execution.