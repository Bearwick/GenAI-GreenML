# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

dataset = pd.read_csv('cars.csv', skipinitialspace=True)
dataset.columns = ['mpg', 'cylinders', 'cubicinches', 'hp', 'weightlbs', 'time-to-60', 'year', 'brand']

for col in ['cubicinches', 'weightlbs']:
    dataset[col] = pd.to_numeric(dataset[col], errors='coerce')

dataset.dropna(inplace=True)

X = dataset.iloc[:, 0:5].values
y = dataset.iloc[:, 7].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

classifier = SVC()
classifier.fit(X_train, y_train)
accuracy = classifier.score(X_test, y_test)

print(f"ACCURACY={accuracy:.6f}")

# OPTIMIZATION SUMMARY
# 1. Removed unused library imports (seaborn, matplotlib, numpy) to reduce memory footprint and startup time.
# 2. Eliminated redundant data introspection methods (head, info, columns) and unused variables (data, da, dataa).
# 3. Streamlined preprocessing by combining numeric conversion and dropping null values, reducing passes over the data.
# 4. Used the 'inplace' parameter for dataframe operations to minimize memory consumption by avoiding unnecessary object copying.
# 5. Removed redundant 'predict' calls and the computation of an unused confusion matrix to save CPU cycles.
# 6. Replaced multiple calls to the model with a single 'score' method to calculate accuracy efficiently.
# 7. Simplified the overall pipeline to focus exclusively on required computation, adhering to green coding principles.