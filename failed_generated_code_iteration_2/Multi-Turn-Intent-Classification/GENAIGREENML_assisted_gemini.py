# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import os
import json
import csv
import torch
from transformers import pipeline

def run_classification():
    input_path = "data/input.json"
    json_out = "data/output/predictions.json"
    csv_out = "data/output/predictions.csv"
    
    if not os.path.exists(input_path):
        return

    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        return

    if not data:
        print(f"ACCURACY={0.0:.6f}")
        return

    intent_options = [
        "Book Appointment",
        "Product Inquiry",
        "Pricing Negotiation",
        "Support Request",
        "Follow-Up"
    ]

    device = 0 if torch.cuda.is_available() else -1
    classifier = pipeline(
        "zero-shot-classification",
        model="cross-encoder/nli-distilroberta-base",
        device=device
    )

    texts = [
        "\n".join([f"{m.get('sender', '').capitalize()}: {m.get('text', '')}" for m in entry.get('messages', [])])
        for entry in data
    ]

    results = classifier(texts, intent_options, batch_size=8)
    
    if not isinstance(results, list):
        results = [results]

    output_data = []
    correct = 0
    for i, res in enumerate(results):
        top_intent = res["labels"][0]
        conv_id = data[i].get('conversation_id')
        
        output_data.append({
            "conversation_id": conv_id,
            "predicted_intent": top_intent,
            "rationale": f"Based on the conversation, the customer is likely interested in '{top_intent.lower()}'."
        })
        
        target = data[i].get('intent') or data[i].get('label')
        if target and top_intent == target:
            correct += 1

    os.makedirs(os.path.dirname(json_out), exist_ok=True)
    
    with open(json_out, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2)

    with open(csv_out, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=["conversation_id", "predicted_intent", "rationale"])
        writer.writeheader()
        writer.writerows(output_data)

    accuracy = correct / len(data) if data else 0.0
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    run_classification()

# Optimization Summary
# 1. Implemented batch inference by passing a list of sequences to the pipeline, significantly reducing overhead compared to sequential processing.
# 2. Added automatic hardware acceleration detection to use GPU (CUDA) when available, reducing runtime and energy per inference.
# 3. Removed unused preprocessing functions and external dependencies (emoji, re) that were defined but never executed in the original pipeline.
# 4. Replaced manual loop-based string building with list comprehensions for more efficient memory allocation and faster execution.
# 5. Minimized I/O overhead by consolidating data transformations and performing single-pass processing of the input dataset.
# 6. Reduced memory footprint by avoiding redundant copies of the conversation data during the transformation stage.