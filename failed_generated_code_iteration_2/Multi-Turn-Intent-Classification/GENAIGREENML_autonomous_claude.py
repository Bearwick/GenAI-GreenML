# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import json
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import warnings
import os

warnings.filterwarnings("ignore")

# Load JSON dataset
data_path = "data/input.json"

with open(data_path, "r", encoding="utf-8") as f:
    raw_data = json.load(f)

# Explore the structure of the JSON to determine how to build a dataframe
# The JSON could be a list of records or a dict with nested structures

if isinstance(raw_data, list):
    records = raw_data
elif isinstance(raw_data, dict):
    # Try to find a list inside the dict
    list_keys = [k for k, v in raw_data.items() if isinstance(v, list)]
    if list_keys:
        # Pick the largest list
        records = max([raw_data[k] for k in list_keys], key=len)
    else:
        # Wrap dict as single record or try to convert
        records = [raw_data]
else:
    records = [raw_data]

# Convert to dataframe for inspection
df = pd.json_normalize(records, sep="_")

# Strip/normalize column names
df.columns = [str(c).strip().replace("  ", " ") for c in df.columns]
df = df[[c for c in df.columns if not c.startswith("Unnamed")]]

# Based on the project context, this is a multi-turn intent classification task
# We need to find: conversation text and intent labels
# Common field names: "conversation", "messages", "text", "intent", "label", "prediction"

# Identify potential text columns and target columns
all_cols = list(df.columns)

# Try to find a target/intent column
target_candidates = [c for c in all_cols if any(kw in c.lower() for kw in ["intent", "label", "prediction", "category", "class", "target"])]
text_candidates = [c for c in all_cols if any(kw in c.lower() for kw in ["conversation", "message", "text", "content", "input", "query", "utterance", "turns"])]

# If conversations are nested (list of messages), we need to flatten them
def flatten_conversation(val):
    """Convert a conversation field to a single string."""
    if isinstance(val, str):
        return val
    if isinstance(val, list):
        parts = []
        for item in val:
            if isinstance(item, dict):
                # Try to extract text from dict
                for key in ["text", "message", "content", "body", "utterance"]:
                    if key in item:
                        sender = item.get("sender", item.get("role", item.get("from", "")))
                        parts.append(f"{sender}: {item[key]}" if sender else str(item[key]))
                        break
                else:
                    parts.append(str(item))
            else:
                parts.append(str(item))
        return " ".join(parts)
    return str(val)

# If no clear text column found, look for columns containing lists or long strings
if not text_candidates:
    for c in all_cols:
        if c in target_candidates:
            continue
        sample_vals = df[c].dropna().head(5)
        for v in sample_vals:
            if isinstance(v, list) or (isinstance(v, str) and len(v) > 50):
                text_candidates.append(c)
                break

# If still no text candidates, try to combine all string columns except target
if not text_candidates:
    str_cols = [c for c in all_cols if df[c].dtype == object and c not in target_candidates]
    if str_cols:
        text_candidates = str_cols

# If no target candidates, try to find a column with limited unique values (categorical)
if not target_candidates: