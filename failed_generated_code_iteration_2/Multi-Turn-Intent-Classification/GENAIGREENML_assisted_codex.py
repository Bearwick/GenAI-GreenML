# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import os
import json
import csv
import random
from typing import List
from transformers import pipeline, set_seed, logging as hf_logging

os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
SEED = 42
os.environ.setdefault("PYTHONHASHSEED", str(SEED))
random.seed(SEED)
set_seed(SEED)
try:
    import numpy as np
    np.random.seed(SEED)
except Exception:
    pass
try:
    import torch
    torch.manual_seed(SEED)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
except Exception:
    pass

hf_logging.set_verbosity_error()

class IntentDetector:
    def __init__(self):
        self.intent_options = [
            "Book Appointment",
            "Product Inquiry",
            "Pricing Negotiation",
            "Support Request",
            "Follow-Up"
        ]
        self.intent_pipeline = pipeline(
            task="zero-shot-classification",
            model="cross-encoder/nli-distilroberta-base",
        )

    def _format_output(self, top_intent: str) -> dict:
        rationale = f"Based on the conversation, the customer is likely interested in '{top_intent.lower()}'."
        return {"predicted_intent": top_intent, "rationale": rationale}

    def classify_intent(self, dialogue: str) -> dict:
        classification = self.intent_pipeline(dialogue, self.intent_options)
        return self._format_output(classification["labels"][0])

    def classify_batch(self, dialogues: List[str]) -> List[dict]:
        if not dialogues:
            return []
        results = self.intent_pipeline(dialogues, self.intent_options)
        if isinstance(results, dict):
            results = [results]
        return [self._format_output(r["labels"][0]) for r in results]

intent_model = IntentDetector()

def create_conversation(messages: List[dict], max_messages: int = None) -> str:
    if max_messages is not None:
        messages = messages[-max_messages:]
    formatted_lines = [
        f"{m.get('sender', '').capitalize()}: {m.get('text', '')}" for m in messages
    ]
    return "\n".join(formatted_lines)

def detect_label_key(conversations):
    if not conversations or not isinstance(conversations[0], dict):
        return None
    keys = conversations[0].keys()
    candidates = ["intent", "label", "true_intent", "ground_truth", "expected_intent", "target"]
    for key in candidates:
        if key in keys:
            return key
    for key in keys:
        if "intent" in key and "predicted" not in key:
            return key
    return None

def predict_intents(input_file: str, json_output: str, csv_output: str, batch_size: int = 8) -> float:
    with open(input_file, "r", encoding="utf-8") as infile:
        conversations = json.load(infile)

    output_data = []
    label_key = detect_label_key(conversations)
    correct = 0
    total = 0

    for start in range(0, len(conversations), batch_size):
        batch = conversations[start:start + batch_size]
        texts = [create_conversation(entry.get("messages", [])) for entry in batch]
        intent_outputs = intent_model.classify_batch(texts)

        for entry, intent_output in zip(batch, intent_outputs):
            output_record = {"conversation_id": entry.get("conversation_id")}
            output_record.update(intent_output)
            output_data.append(output_record)

            if label_key:
                true_label = entry.get(label_key)
                if true_label is not None:
                    total += 1
                    if str(true_label).strip().lower() == str(intent_output["predicted_intent"]).strip().lower():
                        correct += 1

    with open(json_output, "w", encoding="utf-8") as json_file:
        json.dump(output_data, json_file, indent=2)

    with open(csv_output, "w", newline="", encoding="utf-8") as csv_file:
        fieldnames = ["conversation_id", "predicted_intent", "rationale"]
        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(output_data)

    return correct / total if total else 0.0

def main():
    os.makedirs("data/output", exist_ok=True)
    accuracy = predict_intents(
        input_file="data/input.json",
        json_output="data/output/predictions.json",
        csv_output="data/output/predictions.csv"
    )
    print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# Reduced dependencies by removing unused preprocessing utilities.
# Batched inference to lower repeated pipeline overhead and redundant computation.
# Reused output formatting to minimize repeated string construction.
# Added deterministic seeding and limited tokenizer parallelism for stable, efficient runs.
# Computed accuracy in the main pass to avoid extra dataset traversals.