# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# --- Robust CSV Loading ---
DATASET_PATH = "data/AirQualityUCI.csv"

df = None
try:
    df = pd.read_csv(DATASET_PATH)
    # Check if parsing looks wrong (too few columns or single column)
    if df.shape[1] < 3:
        raise ValueError("Too few columns, retry with sep=';'")
except Exception:
    try:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',')
    except Exception:
        df = pd.read_csv(DATASET_PATH, sep=';', decimal=',', encoding='latin-1')

# If first attempt gave many columns but data looks wrong (e.g. semicolon-separated stored as one col), retry
if df.shape[1] < 5:
    df = pd.read_csv(DATASET_PATH, sep=';', decimal=',', encoding='latin-1')

# --- Column Name Normalization ---
df.columns = df.columns.str.strip()
df.columns = [' '.join(c.split()) for c in df.columns]
# Drop unnamed columns
df = df.loc[:, ~df.columns.str.startswith('Unnamed')]
# Drop completely empty columns
df = df.dropna(axis=1, how='all')

# --- Parse numeric columns that may use comma as decimal ---
# The dataset uses comma decimals when loaded with default csv reader
for col in df.columns:
    if df[col].dtype == object and col not in ['Date', 'Time']:
        # Try converting comma-decimal strings
        try:
            converted = df[col].astype(str).str.replace(',', '.', regex=False)
            converted = pd.to_numeric(converted, errors='coerce')
            if converted.notna().sum() > 0.3 * len(df):
                df[col] = converted
        except Exception:
            pass

# --- Coerce all potential numeric columns ---
for col in df.columns:
    if col not in ['Date', 'Time']:
        df[col] = pd.to_numeric(df[col], errors='coerce')

# --- Build Datetime index and resample to daily averages ---
try:
    if 'Date' in df.columns and 'Time' in df.columns:
        # Parse Date: formats like 10/03/2004 and Time: 18.00.00
        df['Datetime'] = pd.to_datetime(
            df['Date'].astype(str) + ' ' + df['Time'].astype(str).str.replace('.', ':', regex=False),
            dayfirst=True,
            errors='coerce'
        )
        df = df.drop(columns=['Date', 'Time'], errors='ignore')
        df = df.set_index('Datetime')
        df = df[df.index.notna()]
        # Resample to daily averages
        df = df.resample('D').mean()
        df = df.dropna(how='all')
except Exception:
    # If datetime parsing fails, just drop Date/Time
    df = df.drop(columns=['Date', 'Time'], errors='ignore')

# --- Drop rows where all values are NaN ---
df = df.dropna(how='all')

# --- Replace -200 sentinel values with NaN (common in this dataset) ---
df = df.replace(-200, np.nan)
df = df.replace(-200.0, np.nan)

# --- Select feature columns per README context ---
desired_features = ['CO(GT)', 'NOx(GT)', 'NO2(GT)', 'C6H6(GT)', 'T', 'RH']
available_features = [f for f in desired_features if f in df.columns]

# If not enough desired features found, use all numeric columns
if len(available_features) < 2: