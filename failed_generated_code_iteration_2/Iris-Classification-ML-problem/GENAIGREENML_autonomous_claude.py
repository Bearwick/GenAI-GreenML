# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score
import os
import glob

# Step 1: Find the actual dataset file
# The provided DATASET_PATH is "requirements.txt" which is not a dataset.
# Based on ML_PROJECT_CONTEXT, this is an Iris Classification problem with a CSV file.
# We search for CSV files in the project directory.

project_dir = os.path.dirname(os.path.abspath(__file__))
csv_files = glob.glob(os.path.join(project_dir, "**", "*.csv"), recursive=True)

dataset_path = None
if csv_files:
    # Prefer a CSV file with 'iris' in the name
    for f in csv_files:
        if 'iris' in os.path.basename(f).lower():
            dataset_path = f
            break
    if dataset_path is None:
        dataset_path = csv_files[0]

# Fallback: try common iris dataset file names in the project directory
if dataset_path is None:
    for candidate in ["iris.csv", "Iris.csv", "IRIS.csv", "iris.data", "data.csv", "dataset.csv"]:
        candidate_path = os.path.join(project_dir, candidate)
        if os.path.exists(candidate_path):
            dataset_path = candidate_path
            break

# If still no CSV found, use sklearn's built-in iris dataset as ultimate fallback
if dataset_path is None:
    from sklearn.datasets import load_iris
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['target'] = iris.target
else:
    # Step 2: Robust CSV parsing
    try:
        df = pd.read_csv(dataset_path)
        # Check if parsing looks wrong (e.g., single column with many semicolons)
        if df.shape[1] <= 1 and df.shape[0] > 0:
            first_val = str(df.iloc[0, 0]) if df.shape[1] == 1 else ""
            if ';' in first_val:
                df = pd.read_csv(dataset_path, sep=';', decimal=',')
    except Exception:
        try:
            df = pd.read_csv(dataset_path, sep=';', decimal=',')
        except Exception:
            # Try with no header (common for iris.data files)
            df = pd.read_csv(dataset_path, header=None)

# Step 3: Normalize column names
df.columns = df.columns.astype(str).str.strip()
df.columns = [' '.join(c.split()) for c in df.columns]
# Drop unnamed columns
df = df[[c for c in df.columns if not c.lower().startswith('unnamed')]]

# If columns are numeric indices (no header), assign standard iris names if shape matches
if df.shape[1] == 5 and all(c.isdigit() for c in df.columns):
    df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']

# Step 4: Identify target and features
# For Iris classification, the target is typically the last column or a column with species/class names
target_col = None
potential_targets = []

for col in df.columns:
    col_lower = col.lower()
    if any(kw in col_lower for kw in ['species', 'class', 'target', 'variety', 'label', 'type']):
        potential_targets.append(col)

if potential_targets:
    target_col = potential_targets[0]
else:
    # If an 'Id' column exists, exclude it; pick last non-Id column as target
    non_id_cols = [c for c in df.columns if c.lower