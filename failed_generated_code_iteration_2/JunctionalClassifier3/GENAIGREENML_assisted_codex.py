# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import os
import pickle
import random
import numpy as np
import pandas as pd
from sklearn import svm, metrics
from sklearn.model_selection import train_test_split

SEED = 42
np.random.seed(SEED)
random.seed(SEED)

DATASET_PATH = "dict.pickle"
INPUT_PATH = "input.csv"
DATASET_HEADERS = None


def _is_number(value):
    try:
        float(str(value))
        return True
    except Exception:
        return False


def read_csv_flexible(path, header="infer"):
    try:
        df = pd.read_csv(path, header=header)
    except Exception:
        return pd.read_csv(path, sep=";", decimal=",", header=header)
    if df.shape[1] == 1 and not df.empty:
        sample = str(df.iloc[0, 0])
        if ";" in sample:
            try:
                df_alt = pd.read_csv(path, sep=";", decimal=",", header=header)
                if df_alt.shape[1] > 1:
                    return df_alt
            except Exception:
                pass
    return df


def maybe_read_headerless(path, df):
    if df is None or df.empty:
        return df
    if all(_is_number(c) for c in df.columns):
        df_no_header = read_csv_flexible(path, header=None)
        if df_no_header.shape[1] >= df.shape[1]:
            return df_no_header
    return df


def align_columns(df):
    if DATASET_HEADERS:
        headers = [h for h in DATASET_HEADERS if h in df.columns]
        if len(headers) == len(DATASET_HEADERS):
            return df[DATASET_HEADERS]
        if headers:
            return df[headers]
    return df


def _looks_like_label(arr):
    arr = np.asarray(arr)
    if arr.ndim != 1 or arr.size == 0:
        return False
    if np.issubdtype(arr.dtype, np.number):
        arr = arr[np.isfinite(arr)]
    if arr.size == 0:
        return False
    unique_vals = np.unique(arr)
    if unique_vals.size <= 5 and np.all(np.isclose(unique_vals, np.round(unique_vals))):
        return True
    return False


def split_array_features_labels(arr, expected_features=None):
    arr = np.asarray(arr)
    if arr.ndim == 1:
        arr = arr.reshape(-1, 1)
    if arr.size == 0:
        return None, None
    if arr.dtype.kind not in "fi":
        arr = arr.astype(np.float64)
    n_cols = arr.shape[1]
    if expected_features is not None:
        if n_cols == expected_features:
            return arr, None
        if n_cols > expected_features:
            X = arr[:, :expected_features]
            y_candidate = arr[:, -1]
            if _looks_like_label(y_candidate):
                return X, y_candidate
            return X, None
    if n_cols > 1 and _looks_like_label(arr[:, -1]):
        return arr[:, :-1], arr[:, -1]
    return arr, None


def split_features_labels(df, expected_features=None):
    df_num = df.apply(pd.to_numeric, errors="coerce")
    df_num = df_num.dropna(axis=1, how="all")
    df_num = df_num.dropna(axis=0, how="any")
    if df_num.empty:
        return None, None
    return split_array_features_labels(df_num.to_numpy(), expected_features)


def clean_X(X):
    if X is None:
        return None
    X = np.asarray(X)
    if X.ndim == 0:
        return np.empty((0, 0))
    if X.ndim == 1:
        X = X.reshape(-1, 1)
    if X.dtype.kind not in "fi":
        X = X.astype(np.float64)
    else:
        X = X.astype(np.float64, copy=False)
    if X.size == 0:
        return X
    if not np.isfinite(X).all():
        mask = np.isfinite(X).all(axis=1)
        X = X[mask]
    return X


def clean_xy(X, y):
    X = clean_X(X)
    if X is None:
        return None, None
    y = np.asarray(y)
    if y.ndim > 1:
        y = y.reshape(-1)
    if y.dtype.kind not in "fi":
        y = y.astype(np.float64)
    else:
        y = y.astype(np.float64, copy=False)
    n = min(X.shape[0], y.shape[0])
    X = X[:n]
    y = y[:n]
    mask = np.isfinite(y)
    if not np.isfinite(X).all():
        mask &= np.isfinite(X).all(axis=1)
    X = X[mask]
    y = y[mask]
    if y.size == 0:
        return X, y
    y = np.sign(y)
    return X, y


def load_csv_data(path, expected_features=None):
    if not os.path.exists(path):
        return None, None
    df = read_csv_flexible(path)
    df = maybe_read_headerless(path, df)
    df = align_columns(df)
    return split_features_labels(df, expected_features)


def is_model(obj):
    return hasattr(obj, "predict") and hasattr(obj, "fit")


def extract_xy_from_dict(d, expected_features=None):
    key_pairs = (("X", "y"), ("x", "y"), ("data", "target"), ("features", "labels"), ("inputs", "outputs"))
    for xk, yk in key_pairs:
        if xk in d and yk in d:
            return np.asarray(d[xk]), np.asarray(d[yk])
    for v in d.values():
        if isinstance(v, pd.DataFrame):
            return split_features_labels(v, expected_features)
        if isinstance(v, np.ndarray) and v.ndim >= 2:
            return split_array_features_labels(v, expected_features)
    arrays = []
    for v in d.values():
        if isinstance(v, (list, tuple, np.ndarray, pd.Series)):
            arrays.append(np.asarray(v))
    if len(arrays) >= 2:
        for arr_y in arrays:
            if arr_y.ndim == 1:
                for arr_x in arrays:
                    if arr_x.ndim >= 2 and arr_x.shape[0] == arr_y.shape[0]:
                        return arr_x, arr_y
    return None, None


def extract_xy(obj, expected_features=None):
    if isinstance(obj, pd.DataFrame):
        return split_features_labels(obj, expected_features)
    if isinstance(obj, np.ndarray):
        return split_array_features_labels(obj, expected_features)
    if isinstance(obj, (list, tuple)) and len(obj) == 2 and not is_model(obj):
        return np.asarray(obj[0]), np.asarray(obj[1])
    return None, None


def parse_pickle_object(obj, expected_features=None):
    model = None
    X = None
    y = None
    if is_model(obj):
        model = obj
        return model, X, y
    if isinstance(obj, dict):
        for v in obj.values():
            if model is None and is_model(v):
                model = v
        X, y = extract_xy_from_dict(obj, expected_features)
        return model, X, y
    X, y = extract_xy(obj, expected_features)
    return model, X, y


def load_dataset_from_path(path):
    model = None
    X = None
    y = None
    if not os.path.exists(path):
        return model, X, y
    try:
        with open(path, "rb") as f:
            obj = pickle.load(f)
        model, X, y = parse_pickle_object(obj)
    except Exception:
        obj = None
    if model is None and X is None and y is None:
        try:
            X, y = load_csv_data(path)
        except Exception:
            pass
    return model, X, y


def create_svc(seed):
    try:
        return svm.SVC(kernel="linear", random_state=seed)
    except TypeError:
        return svm.SVC(kernel="linear")


def train_and_evaluate(X, y, seed):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)
    model = create_svc(seed)
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    accuracy = metrics.accuracy_score(y_test, preds)
    return model, accuracy


def evaluate_model(model, X, y):
    preds = model.predict(X)
    return metrics.accuracy_score(y, preds)


def main():
    model, X, y = load_dataset_from_path(DATASET_PATH)

    expected_features = None
    if model is not None:
        if hasattr(model, "n_features_in_"):
            expected_features = int(model.n_features_in_)
        elif hasattr(model, "support_vectors_"):
            expected_features = model.support_vectors_.shape[1]

    input_X, input_y = load_csv_data(INPUT_PATH, expected_features)

    if X is None and input_X is not None:
        X, y = input_X, input_y

    accuracy = float("nan")
    used_input_for_accuracy = X is input_X and input_y is not None

    if model is None:
        if X is not None and y is not None:
            X_clean, y_clean = clean_xy(X, y)
            if X_clean is not None and X_clean.shape[0] >= 2 and np.unique(y_clean).size >= 2:
                model, accuracy = train_and_evaluate(X_clean, y_clean, SEED)
    else:
        if X is not None and y is not None:
            X_clean, y_clean = clean_xy(X, y)
            if X_clean is not None and X_clean.shape[0] > 0:
                accuracy = evaluate_model(model, X_clean, y_clean)
                used_input_for_accuracy = used_input_for_accuracy or (X is input_X and input_y is not None)

    if model is not None and input_X is not None and not used_input_for_accuracy:
        X_pred = clean_X(input_X)
        if X_pred is not None and X_pred.shape[0] > 0:
            _ = model.predict(X_pred)

    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Replaced manual CSV parsing with vectorized pandas loading and a fallback separator to reduce Python-level loops.
# - Removed redundant model saving and global state to cut unnecessary I/O and memory usage.
# - Consolidated data cleaning and label normalization into NumPy operations to minimize data movement.
# - Reused pre-trained models when available to avoid retraining and reduce compute.
# - Limited predictions to necessary cases and suppressed extraneous outputs to lower runtime overhead.