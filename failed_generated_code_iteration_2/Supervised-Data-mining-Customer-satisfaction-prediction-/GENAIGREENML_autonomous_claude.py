# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Robust CSV loading
df = None
for kwargs in [
    {},
    {"sep": ";"},
    {"sep": ";", "decimal": ","},
]:
    try:
        df = pd.read_csv("EireJet (1).csv", **kwargs)
        if df.shape[1] >= 5:
            break
    except Exception:
        continue

if df is None or df.shape[1] < 2:
    df = pd.read_csv("EireJet (1).csv", sep=None, engine="python")

# Normalize column names
df.columns = df.columns.str.strip().str.replace(r"\s+", " ", regex=True)
df = df[[c for c in df.columns if not c.startswith("Unnamed")]]

# Identify target
target_col = None
if "satisfaction" in df.columns:
    target_col = "satisfaction"
else:
    for c in df.columns:
        if "satisfaction" in c.lower():
            target_col = c
            break

if target_col is None:
    # fallback: pick last column
    target_col = df.columns[-1]

# Drop rows where target is NaN
df = df.dropna(subset=[target_col])

# Encode target as binary classification
y_raw = df[target_col].astype(str).str.strip().str.lower()
unique_labels = y_raw.unique()

if len(unique_labels) < 2:
    # Trivial baseline
    from sklearn.dummy import DummyClassifier
    y = y_raw.astype("category").cat.codes
    X = df.drop(columns=[target_col])
    X_train, X_test, y_train, y_test = train_test_split(X.select_dtypes(include=[np.number]).fillna(0), y, test_size=0.2, random_state=42)
    model = DummyClassifier(strategy="most_frequent")
    model.fit(X_train, y_train)
    accuracy = model.score(X_test, y_test)
    print(f"ACCURACY={accuracy:.6f}")
else:
    # Map to binary: satisfied=1, else=0
    label_map = {}
    for lbl in unique_labels:
        if "satisfied" in lbl and "dissatisfied" not in lbl and "neutral" not in lbl:
            label_map[lbl] = 1
        else:
            label_map[lbl] = 0
    
    # If mapping resulted in single class, do generic encoding
    if len(set(label_map.values())) < 2:
        from sklearn.preprocessing import LabelEncoder
        le = LabelEncoder()
        y = le.fit_transform(y_raw)
    else:
        y = y_raw.map(label_map).values.astype(int)

    feature_cols = [c for c in df.columns if c != target_col]
    X = df[feature_cols].copy()

    # Identify numeric and categorical columns
    num_cols = []
    cat_cols = []
    for c in feature_cols:
        col_data = X[c]
        converted = pd.to_numeric(col_data, errors="coerce")
        non_null_ratio = converted.notna().sum() / len(converted) if len(converted) > 0 else 0
        if non_null_ratio > 0.5:
            X[c] = converted
            num_cols.append(c)
        else:
            X[c] = col_data.astype(str).str.strip()
            cat_cols.append(c)

    # Handle NaN/inf in numeric
    for c in num_cols:
        X[c] =