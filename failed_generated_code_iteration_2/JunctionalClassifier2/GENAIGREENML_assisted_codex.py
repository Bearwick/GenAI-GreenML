# Generated by generate_llm_code.py
# LLM: codex
# Mode: assisted

import os
import pickle
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

SEED = 42
np.random.seed(SEED)
DATASET_PATH = "dict.pickle"


def read_csv_robust(path):
    try:
        df = pd.read_csv(path)
    except Exception:
        return pd.read_csv(path, sep=";", decimal=",")
    if df.shape[1] == 1:
        try:
            df_alt = pd.read_csv(path, sep=";", decimal=",")
            if df_alt.shape[1] > 1:
                df = df_alt
        except Exception:
            pass
    return df


def load_data(path):
    ext = os.path.splitext(path)[1].lower()
    if ext in (".csv", ".txt"):
        return read_csv_robust(path)
    if ext in (".pickle", ".pkl"):
        with open(path, "rb") as f:
            return pickle.load(f)
    try:
        return read_csv_robust(path)
    except Exception:
        with open(path, "rb") as f:
            return pickle.load(f)


def resolve_headers(df):
    headers = None
    dh = globals().get("DATASET_HEADERS")
    if isinstance(dh, str):
        dh = [dh]
    if isinstance(dh, (list, tuple)) and dh:
        headers = [h for h in dh if h in df.columns]
    if not headers:
        headers = list(df.columns)
    return headers


def select_label_column(headers):
    if not headers:
        return None
    lower = [str(h).lower() for h in headers]
    for name in ("label", "labels", "target", "class", "y"):
        if name in lower:
            return headers[lower.index(name)]
    return headers[-1]


def to_numeric_matrix(data):
    if isinstance(data, pd.DataFrame):
        try:
            return data.to_numpy(dtype=np.float64, copy=False)
        except Exception:
            return (
                data.apply(pd.to_numeric, errors="coerce")
                .fillna(0.0)
                .to_numpy(dtype=np.float64)
            )
    arr = np.asarray(data)
    if arr.dtype.kind in "iuf":
        return arr.astype(np.float64, copy=False)
    return (
        pd.DataFrame(arr)
        .apply(pd.to_numeric, errors="coerce")
        .fillna(0.0)
        .to_numpy(dtype=np.float64)
    )


def to_numeric_vector(data):
    if isinstance(data, pd.Series):
        vec = pd.to_numeric(data, errors="coerce").to_numpy()
    else:
        vec = np.asarray(data)
        if vec.dtype.kind not in "iuf":
            vec = pd.to_numeric(pd.Series(vec), errors="coerce").to_numpy()
        else:
            vec = vec.astype(np.float64, copy=False)
    vec = np.nan_to_num(vec, nan=0.0)
    return np.sign(np.ravel(vec)).astype(int)


def prepare_from_df(df):
    if df.shape[1] < 2:
        return None, None
    headers = resolve_headers(df)
    label_col = select_label_column(headers)
    if label_col is None or label_col not in df.columns:
        return None, None
    features = to_numeric_matrix(df.drop(columns=[label_col]))
    labels = to_numeric_vector(df[label_col])
    return features, labels


def extract_xy(obj):
    if isinstance(obj, dict):
        for kx in ("X", "x", "features", "data"):
            for ky in ("y", "labels", "target"):
                if kx in obj and ky in obj:
                    return obj[kx], obj[ky]
    if isinstance(obj, (list, tuple)) and len(obj) == 2:
        return obj[0], obj[1]
    if isinstance(obj, np.ndarray) and obj.ndim == 2 and obj.shape[1] > 1:
        return obj[:, :-1], obj[:, -1]
    return None, None


def ensure_2d(X):
    arr = np.asarray(X)
    if arr.ndim == 1:
        return arr.reshape(-1, 1)
    return arr


def train_and_evaluate(X, y):
    X = ensure_2d(X)
    y = np.ravel(y)
    if X.size == 0 or y.size == 0 or X.shape[1] == 0:
        return None
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=SEED, shuffle=True
    )
    model = KNeighborsClassifier(n_neighbors=4)
    model.fit(X_train, y_train)
    return float(model.score(X_test, y_test))


def get_training_data(model):
    for attr_x, attr_y in (("_fit_X", "_y"), ("X_", "y_"), ("_X", "_y")):
        if hasattr(model, attr_x) and hasattr(model, attr_y):
            return getattr(model, attr_x), getattr(model, attr_y)
    return None, None


def evaluate_estimator(model):
    X, y = get_training_data(model)
    if X is None or y is None:
        return None
    try:
        return float(model.score(X, y))
    except Exception:
        pred = model.predict(X)
        y_arr = np.asarray(y)
        return float(np.mean(pred == y_arr))


def main():
    if not os.path.exists(DATASET_PATH):
        print(f"ACCURACY={0.0:.6f}")
        return
    data = load_data(DATASET_PATH)
    accuracy = None
    if isinstance(data, pd.DataFrame):
        X, y = prepare_from_df(data)
        if X is not None and y is not None:
            accuracy = train_and_evaluate(X, y)
    elif hasattr(data, "predict"):
        accuracy = evaluate_estimator(data)
    else:
        X, y = extract_xy(data)
        if X is not None and y is not None:
            X = to_numeric_matrix(X)
            y = to_numeric_vector(y)
            accuracy = train_and_evaluate(X, y)
    if accuracy is None:
        accuracy = 0.0
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Eliminated unused modules, tests, and file-writing side effects to reduce overhead.
# - Replaced manual CSV parsing with vectorized pandas/numpy conversions and conditional type casting.
# - Added robust CSV loading fallback and flexible header/label resolution to avoid repeated parsing.
# - Minimized data copying via copy=False and early validation of shapes.
# - Ensured deterministic splits with a fixed seed for reproducible accuracy results.