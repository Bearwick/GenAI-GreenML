# Generated by generate_llm_code.py
# LLM: chatgpt
# Mode: assisted

import os
import pickle
from typing import Optional, Tuple

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier


RANDOM_SEED = 42
MODEL_PATH = "dict.pickle"


def _read_csv_robust(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if df.shape[1] <= 1:
        df = pd.read_csv(path, sep=";", decimal=",")
    return df


def _load_model(model_path: str = MODEL_PATH) -> KNeighborsClassifier:
    with open(model_path, "rb") as f:
        model = pickle.load(f)
    if not hasattr(model, "predict"):
        raise TypeError("Loaded object is not a valid scikit-learn estimator.")
    return model


def _load_input_features(input_csv: str = "input.csv") -> np.ndarray:
    df = _read_csv_robust(input_csv)
    x = df.to_numpy(dtype=np.float64, copy=False)
    if x.ndim == 1:
        x = x.reshape(-1, 1)
    return x


def _maybe_load_supervised_data() -> Optional[Tuple[np.ndarray, np.ndarray]]:
    train_csv = "14k.csv"
    if not os.path.exists(train_csv):
        return None

    df = _read_csv_robust(train_csv)
    if df.shape[1] < 2:
        return None

    data = df.to_numpy(dtype=np.float64, copy=False)
    x = data[:, :-1]
    y_raw = data[:, -1]

    y = np.where(y_raw > 0, 1, np.where(y_raw < 0, -1, 0)).astype(np.int64, copy=False)
    return x, y


def _accuracy_eval_if_possible(model: KNeighborsClassifier) -> float:
    supervised = _maybe_load_supervised_data()
    if supervised is None:
        return 0.0

    x, y = supervised
    x_train, x_test, y_train, y_test = train_test_split(
        x, y, test_size=0.3, random_state=RANDOM_SEED, shuffle=True
    )
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    return float(accuracy_score(y_test, y_pred))


def main() -> None:
    model = _load_model(MODEL_PATH)
    _ = model.predict(_load_input_features("input.csv"))
    accuracy = _accuracy_eval_if_possible(model)
    print(f"ACCURACY={accuracy:.6f}")


if __name__ == "__main__":
    main()

# Optimization Summary
# - Replaced manual CSV parsing loops with vectorized pandas->NumPy loading to reduce Python overhead and data movement.
# - Implemented robust CSV parsing fallback (default, then sep=';' and decimal=',') to avoid repeated ad-hoc parsing logic.
# - Eliminated global mutable lists and wipe functions; used local arrays to reduce memory churn and side effects.
# - Avoided unnecessary model re-serialization; only loads the model and runs prediction without saving artifacts.
# - Ensured reproducibility for evaluation by fixing train_test_split random_state.
# - Used NumPy views (copy=False) where possible to minimize extra allocations during preprocessing.