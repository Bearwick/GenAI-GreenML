# Generated by generate_llm_code.py
# LLM: gemini
# Mode: assisted

import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle
import os

def main():
    seed = 42
    dataset_path = 'dict.pickle'
    train_csv = '14k.csv'
    
    path = dataset_path if os.path.exists(dataset_path) else train_csv
    if not os.path.exists(path):
        return

    x_data, y_data = None, None

    if path.endswith('.pickle'):
        try:
            with open(path, 'rb') as f:
                obj = pickle.load(f)
                if isinstance(obj, dict) and 'features' in obj:
                    x_data = np.array(obj['features'], dtype=np.float32)
                    y_data = np.array(obj['labels'], dtype=np.float32)
                elif isinstance(obj, (pd.DataFrame, np.ndarray)):
                    df = pd.DataFrame(obj)
                elif isinstance(obj, KNeighborsClassifier):
                    if os.path.exists(train_csv):
                        df = pd.read_csv(train_csv, sep=None, engine='python', header=0)
                    else:
                        return
                else:
                    df = pd.DataFrame(obj)
        except (pickle.UnpicklingError, EOFError, AttributeError):
            try:
                df = pd.read_csv(path, sep=None, engine='python', header=0)
            except:
                return
    else:
        try:
            df = pd.read_csv(path, sep=None, engine='python', header=0)
        except:
            try:
                df = pd.read_csv(path, sep=',', engine='c', header=0)
            except:
                return

    if x_data is None and 'df' in locals():
        if df.columns[-1].startswith('Unnamed') and df.iloc[:, -1].isnull().all():
            df = df.iloc[:, :-1]
        
        matrix = df.to_numpy(dtype=np.float32)
        x_data = matrix[:, :-1]
        y_data = matrix[:, -1]

    if x_data is not None and y_data is not None:
        y_data = np.sign(y_data)
        
        xt, xv, yt, yv = train_test_split(
            x_data, y_data, test_size=0.3, random_state=seed
        )
        
        clf = KNeighborsClassifier(n_neighbors=4)
        clf.fit(xt, yt)
        
        y_pred = clf.predict(xv)
        accuracy = accuracy_score(yv, y_pred)
        
        print(f"ACCURACY={accuracy:.6f}")

if __name__ == "__main__":
    main()

# Optimization Summary
# 1. Vectorized Label Processing: Replaced manual conditional loops with NumPy's sign function to transform labels, significantly reducing CPU cycles.
# 2. Optimized Data Loading: Substituted inefficient row-by-row csv.reader loops with pandas.read_csv using C-optimized engines for faster I/O.
# 3. Memory Footprint Reduction: Utilized float32 NumPy arrays for feature data instead of Python lists or float64 arrays, cutting memory usage by approximately 50%.
# 4. Redundancy Elimination: Consolidated separate training, loading, and preprocessing functions into a streamlined pipeline, minimizing intermediate data structures.
# 5. Resource Management: Removed artifact generation (pickle saving) and unnecessary console logging to reduce disk usage and energy overhead.
# 6. Benchmarking Stability: Applied a fixed random seed to the train-test split and consolidated schema derivation to ensure reproducibility and stable performance.