# Generated by generate_llm_code.py
# LLM: claude
# Mode: autonomous

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# --- Step 1: Load the dataset with robust fallback ---
dataset_path = "dataset_adult.arff"

def load_arff_as_dataframe(path):
    """Parse ARFF file manually to extract data and column names."""
    columns = []
    data_lines = []
    in_data = False
    with open(path, 'r', encoding='utf-8', errors='replace') as f:
        for line in f:
            stripped = line.strip()
            if stripped.lower().startswith('@attribute'):
                parts = stripped.split()
                col_name = parts[1].strip("'\"")
                columns.append(col_name)
            elif stripped.lower() == '@data':
                in_data = True
                continue
            elif in_data and stripped and not stripped.startswith('%'):
                data_lines.append(stripped)
    
    if not data_lines:
        raise ValueError("No data found in ARFF file")
    
    from io import StringIO
    data_str = "\n".join(data_lines)
    df = pd.read_csv(StringIO(data_str), header=None, na_values=['?', ' ?', '? '], skipinitialspace=True)
    
    if len(columns) == len(df.columns):
        df.columns = columns
    else:
        df.columns = [f"col_{i}" for i in range(len(df.columns))]
    
    return df

try:
    df = load_arff_as_dataframe(dataset_path)
except Exception:
    try:
        df = pd.read_csv(dataset_path, comment='@', header=None, na_values=['?', ' ?'], skipinitialspace=True)
    except Exception:
        df = pd.read_csv(dataset_path, sep=';', decimal=',', na_values=['?', ' ?'], skipinitialspace=True)

# --- Step 2: Clean column names ---
df.columns = [str(c).strip().replace("  ", " ") for c in df.columns]
df = df[[c for c in df.columns if not c.startswith('Unnamed')]]

# Strip whitespace from string columns
for col in df.select_dtypes(include='object').columns:
    df[col] = df[col].astype(str).str.strip()

# --- Step 3: Identify target column ---
# Adult dataset typically has a target column related to income ('>50K' / '<=50K')
target_col = None
candidate_targets = ['class', 'income', 'target', 'label']

# Check last column first (common in ARFF)
last_col = df.columns[-1]
if df[last_col].dtype == 'object':
    unique_vals = df[last_col].nunique()
    if 2 <= unique_vals <= 20:
        target_col = last_col

if target_col is None:
    for cand in candidate_targets:
        for col in df.columns:
            if cand in col.lower():
                target_col = col
                break
        if target_col is not None:
            break

if target_col is None:
    # Fallback: use last column
    target_col = df.columns[-1]

# --- Step 4: Separate features and target ---
feature_cols = [c for c in df.columns if c != target_col]
X = df[feature_cols].copy()
y = df[target_col].copy()

# Clean target - handle string targets for classification
is_classification = True
if y.dtype == 'object':
    y = y.str.strip().str.rstrip('.')
    unique_classes = y.unique()
    if len(